{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3675927f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from analysis import *\n",
    "import argparse\n",
    "from sys import platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e2301c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(12)\n",
    "torch.cuda.manual_seed(12)\n",
    "np.random.seed(12)\n",
    "torch.backends.cudnn.deterministics = True\n",
    "torch.set_num_threads(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7454d60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "0\n",
      "<torch.cuda.device object at 0x7f48dc5b3940>\n",
      "NVIDIA TITAN V\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.current_device())\n",
    "\n",
    "print(torch.cuda.device(0))\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "499dbec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iv: image option\n",
    "length = 512\n",
    "channel = 96\n",
    "min_CNN = 200\n",
    "n_classes = 40\n",
    "classes = range(n_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cef3bc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "if platform == \"linux\" or platform == \"linux2\":\n",
    "    torch_models_dir = r\"/media/titan/AI Research/Data/CVPR2021-02785/CVPR2021-02785/preprocessed/torch_models\"\n",
    "elif platform == \"win32\":\n",
    "    torch_models_dir = r\"D:\\Data\\CVPR2021-02785\\CVPR2021-02785\\preprocessed\\torch_models\"\n",
    "eeg_dataset, splits_path, splits_shuffled_path = os.listdir(torch_models_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37e239e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/titan/AI Research/Data/CVPR2021-02785/CVPR2021-02785/preprocessed/torch_models/imagenet40-1000-1.pth \n",
      " /media/titan/AI Research/Data/CVPR2021-02785/CVPR2021-02785/preprocessed/torch_models/imagenet40-1000-1_splits.pth\n"
     ]
    }
   ],
   "source": [
    "eeg_dataset = os.path.join(torch_models_dir, eeg_dataset)\n",
    "splits_path = os.path.join(torch_models_dir, splits_path)\n",
    "# splits_path = os.path.join(torch_models_dir, splits_shuffled_path)\n",
    "print(eeg_dataset,'\\n', splits_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "009ff0e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image\n"
     ]
    }
   ],
   "source": [
    "opt = {\n",
    "    # Dataset options\n",
    "    \"iv\": \"image\",\n",
    "    \"offset\": None,\n",
    "    \"results_file\": \"results.pkl\",\n",
    "    \"subject\": 0,\n",
    "    \"run\": \"none\",\n",
    "    \"eeg_dataset\": eeg_dataset,\n",
    "    \"splits_path\": splits_path,\n",
    "    \"fold\": 5,\n",
    "    #Training options\n",
    "    \"batch_size\": 16,\n",
    "    \"optim\": \"Adam\",\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"learning_rate_decay_by\": 0.5,\n",
    "    \"learning_rate_decay_every\": 10,\n",
    "    \"epochs\": 100,\n",
    "    \"GPUindex\": 0,\n",
    "    \"kind\":\"incremental\",\n",
    "    #Backend options\n",
    "    \"no_cuda\": False,\n",
    "    \"classifier\": None\n",
    "}\n",
    "opt = argparse.Namespace(**opt)\n",
    "print(opt.iv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c8df9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from torch.utils.data import DataLoader\n",
    "from data_loader import EEGDataset, Splitter, SplitterWithData\n",
    "from EEG_Encoder.LSTM import classifier_LSTM\n",
    "from EEG_Encoder.CNN import classifier_CNN\n",
    "from EEG_Encoder.EEGNet import classifier_EEGNet\n",
    "from EEG_Encoder.SyncNet import classifier_SyncNet\n",
    "from EEG_Encoder.EEGChannelNet import classifier_EEGChannelNet\n",
    "from EEG_Encoder.net_generator import Classifier\n",
    "from EEG_Encoder.net_trainer import net_trainer\n",
    "from p_values import *\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30bd6700",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(iv,\n",
    "             offset,\n",
    "             eeg_dataset,\n",
    "             splits_path,\n",
    "             split_num, # (0-4) - 5 fold cross validation\n",
    "             total,\n",
    "             classes,\n",
    "             classifier,\n",
    "             batch_size,\n",
    "             GPUindex,\n",
    "             length, # 512\n",
    "             channel, # 96\n",
    "             min_CNN,\n",
    "             opt,\n",
    "             kind):        \n",
    "    # Load dataset\n",
    "    dataset = EEGDataset(iv, eeg_dataset, classifier, map_idx = None)\n",
    "    print(\"DONE: LOAD DATASET\")\n",
    "    # Create loaders for LSTM/MLP/CNN/SCNN/EEGNet/SyncNet/EEGChannelNet\n",
    "    if kind==\"from-scratch\":\n",
    "        relabel = False\n",
    "    if kind==\"incremental\":\n",
    "        relabel = False\n",
    "    if kind==\"no-model-file\":\n",
    "        relabel = True\n",
    "    splitter = {split: SplitterWithData(iv,\n",
    "                    dataset,\n",
    "                    splits_path,\n",
    "                    classes,\n",
    "                    split_num,\n",
    "                    split,\n",
    "                    relabel) for split in [\"train\", \"val\", \"test\"]}\n",
    "    loaders = {split: DataLoader(\n",
    "                        splitter[split],\n",
    "                        batch_size = batch_size,\n",
    "                        drop_last = False,\n",
    "                        shuffle = True)\n",
    "                    for split in [\"train\", \"val\", \"test\"]}\n",
    "    channel_idx = None    \n",
    "    print(\"DONE: Create loaders for model\")            \n",
    "    return dataset, loaders, splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aae9c3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EEGNet network\n",
    "opt.classifier = \"EEGNet\"\n",
    "opt.batch_size = 16\n",
    "opt.kind = \"from-scratch\"\n",
    "opt.run = \"imagenet40-1000\"\n",
    "opt.fold = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8455f252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE: LOAD DATASET\n",
      "DONE: Create loaders for model\n"
     ]
    }
   ],
   "source": [
    "dataset, loaders, splitter = load_dataset(opt.iv,\n",
    "                             opt.offset,\n",
    "                             opt.eeg_dataset,\n",
    "                             opt.splits_path,\n",
    "                             0, #split_num\n",
    "                             n_classes,\n",
    "                             classes,\n",
    "                             opt.classifier,\n",
    "                             opt.batch_size,\n",
    "                             opt.GPUindex,\n",
    "                             length,\n",
    "                             channel,\n",
    "                             min_CNN,\n",
    "                             opt,\n",
    "                             opt.kind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8191cbe4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'data_loader.EEGDataset'>\n",
      "<class 'dict'>\n",
      "3 [2000, 250, 250]\n",
      "1: Label val: 0; label train: 0\n",
      "2: Label val: 17; label train: 17\n",
      "3: Label val: 28; label train: 28\n",
      "4: Label val: 7; label train: 7\n",
      "5: Label val: 33; label train: 33\n",
      "6: Label val: 12; label train: 12\n",
      "7: Label val: 21; label train: 21\n",
      "8: Label val: 3; label train: 3\n",
      "9: Label val: 25; label train: 25\n",
      "10: Label val: 36; label train: 36\n",
      "11: Label val: 10; label train: 10\n",
      "12: Label val: 15; label train: 15\n",
      "13: Label val: 19; label train: 19\n",
      "14: Label val: 31; label train: 31\n",
      "15: Label val: 23; label train: 23\n",
      "16: Label val: 5; label train: 5\n",
      "17: Label val: 38; label train: 38\n",
      "18: Label val: 8; label train: 8\n",
      "19: Label val: 1; label train: 1\n",
      "20: Label val: 34; label train: 34\n",
      "21: Label val: 29; label train: 29\n",
      "22: Label val: 26; label train: 26\n",
      "23: Label val: 13; label train: 13\n",
      "24: Label val: 11; label train: 11\n",
      "25: Label val: 22; label train: 22\n",
      "26: Label val: 18; label train: 18\n",
      "27: Label val: 6; label train: 6\n",
      "28: Label val: 16; label train: 16\n",
      "29: Label val: 4; label train: 4\n",
      "30: Label val: 20; label train: 20\n",
      "31: Label val: 32; label train: 32\n",
      "32: Label val: 9; label train: 9\n",
      "33: Label val: 37; label train: 37\n",
      "34: Label val: 24; label train: 24\n",
      "35: Label val: 39; label train: 39\n",
      "36: Label val: 2; label train: 2\n",
      "37: Label val: 35; label train: 35\n",
      "38: Label val: 30; label train: 30\n",
      "39: Label val: 27; label train: 27\n",
      "40: Label val: 14; label train: 14\n"
     ]
    }
   ],
   "source": [
    "# loaders: divide the splits data in each fold with batch_size\n",
    "# Each fold has {train: 32000 idx, val: 4000 idx, test: 4000 idx}\n",
    "# Each loader batch has {train: 2000 idx, val: 250idx, test: 250 idx}\n",
    "print(type(dataset))\n",
    "print(type(loaders))\n",
    "print(len(loaders), [len(loaders[name]) for name in [\"train\", \"val\", \"test\"] ])\n",
    "for i in range(0, 40):\n",
    "    eeg, label_val = splitter[\"val\"][i*100]\n",
    "    eeg, label_train = splitter[\"train\"][i*800]\n",
    "    print(f\"{i+1}: Label val: {label_val}; label train: {label_train}\")\n",
    "# print(splitter[\"val\"].split_idx[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e95cc78d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE: CREATE TORCH CLASSIFIER\n",
      "classifier_EEGNet(\n",
      "  (network): Sequential(\n",
      "    (0): ZeroPad2d((128, 127, 0, 0))\n",
      "    (1): Conv2d(1, 8, kernel_size=(1, 256), stride=(1, 1))\n",
      "    (2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Conv2d(8, 16, kernel_size=(96, 1), stride=(1, 1), groups=8)\n",
      "    (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ELU(alpha=1.0)\n",
      "    (6): AvgPool2d(kernel_size=(1, 4), stride=(1, 4), padding=0)\n",
      "    (7): Dropout(p=0.5, inplace=False)\n",
      "    (8): ZeroPad2d((8, 7, 0, 0))\n",
      "    (9): Conv2d(16, 16, kernel_size=(1, 16), stride=(1, 1), groups=8)\n",
      "    (10): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): ELU(alpha=1.0)\n",
      "    (13): AvgPool2d(kernel_size=(1, 8), stride=(1, 8), padding=0)\n",
      "    (14): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (fc): Linear(in_features=256, out_features=40, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "classifier_EEGNet                        [1, 40]                   --\n",
       "├─Sequential: 1-1                        [1, 16, 1, 16]            --\n",
       "│    └─ZeroPad2d: 2-1                    [1, 1, 96, 767]           --\n",
       "│    └─Conv2d: 2-2                       [1, 8, 96, 512]           2,056\n",
       "│    └─BatchNorm2d: 2-3                  [1, 8, 96, 512]           16\n",
       "│    └─Conv2d: 2-4                       [1, 16, 1, 512]           1,552\n",
       "│    └─BatchNorm2d: 2-5                  [1, 16, 1, 512]           32\n",
       "│    └─ELU: 2-6                          [1, 16, 1, 512]           --\n",
       "│    └─AvgPool2d: 2-7                    [1, 16, 1, 128]           --\n",
       "│    └─Dropout: 2-8                      [1, 16, 1, 128]           --\n",
       "│    └─ZeroPad2d: 2-9                    [1, 16, 1, 143]           --\n",
       "│    └─Conv2d: 2-10                      [1, 16, 1, 128]           528\n",
       "│    └─Conv2d: 2-11                      [1, 16, 1, 128]           272\n",
       "│    └─BatchNorm2d: 2-12                 [1, 16, 1, 128]           32\n",
       "│    └─ELU: 2-13                         [1, 16, 1, 128]           --\n",
       "│    └─AvgPool2d: 2-14                   [1, 16, 1, 16]            --\n",
       "│    └─Dropout: 2-15                     [1, 16, 1, 16]            --\n",
       "├─Linear: 1-2                            [1, 40]                   10,280\n",
       "==========================================================================================\n",
       "Total params: 14,768\n",
       "Trainable params: 14,768\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 101.96\n",
       "==========================================================================================\n",
       "Input size (MB): 0.20\n",
       "Forward/backward pass size (MB): 6.47\n",
       "Params size (MB): 0.06\n",
       "Estimated Total Size (MB): 6.73\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net, nonclasses = Classifier(\n",
    "                 n_classes,\n",
    "                 classes,\n",
    "                 opt.classifier,\n",
    "                 opt.GPUindex,\n",
    "                 length,\n",
    "                 channel,\n",
    "                 min_CNN,\n",
    "                 opt.kind)\n",
    "# print(len(nonclasses))\n",
    "summary(net, input_size=(1,96, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9527792e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image-EEGNet-512-96-0-noshuffle\n"
     ]
    }
   ],
   "source": [
    "model_path = (opt.iv+\n",
    "                  \"-\"+\n",
    "                  opt.classifier+\n",
    "                  \"-\"+\n",
    "                  str(length)+\n",
    "                  \"-\"+\n",
    "                  str(channel)+\n",
    "                  \"-\"+\n",
    "                  str(0)) + \"-noshuffle\"\n",
    "                  \n",
    "channel_idx=None\n",
    "print(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "789e1be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(iv='image', offset=None, results_file='results.pkl', subject=0, run='imagenet40-1000', eeg_dataset='/media/titan/AI Research/Data/CVPR2021-02785/CVPR2021-02785/preprocessed/torch_models/imagenet40-1000-1.pth', splits_path='/media/titan/AI Research/Data/CVPR2021-02785/CVPR2021-02785/preprocessed/torch_models/imagenet40-1000-1_splits.pth', fold=5, batch_size=16, optim='Adam', learning_rate=0.001, learning_rate_decay_by=0.5, learning_rate_decay_every=10, epochs=100, GPUindex=0, kind='from-scratch', no_cuda=False, classifier='EEGNet')\n"
     ]
    }
   ],
   "source": [
    "print(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2d6a7ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.7347614765167236; accuracy=0.027562500908970833\n",
      "Batch 2000: Loss=3.7461633682250977; accuracy=0.02656250074505806\n",
      "Validation accuracy: 0.03425000235438347\n",
      "epoch 2\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.6362812519073486; accuracy=0.036125000566244125\n",
      "Batch 2000: Loss=3.6209020614624023; accuracy=0.037437502294778824\n",
      "Validation accuracy: 0.04375000298023224\n",
      "epoch 3\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.7041988372802734; accuracy=0.04018750041723251\n",
      "Batch 2000: Loss=3.551424264907837; accuracy=0.040687501430511475\n",
      "Validation accuracy: 0.04325000196695328\n",
      "epoch 4\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.7639200687408447; accuracy=0.04775000363588333\n",
      "Batch 2000: Loss=3.7739195823669434; accuracy=0.04568750038743019\n",
      "Validation accuracy: 0.049250002950429916\n",
      "epoch 5\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.8070569038391113; accuracy=0.04893750324845314\n",
      "Batch 2000: Loss=3.652982711791992; accuracy=0.04728125408291817\n",
      "Validation accuracy: 0.05100000277161598\n",
      "epoch 6\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.656320333480835; accuracy=0.05250000208616257\n",
      "Batch 2000: Loss=3.6890792846679688; accuracy=0.05046875402331352\n",
      "Validation accuracy: 0.05275000259280205\n",
      "epoch 7\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.6298325061798096; accuracy=0.05325000360608101\n",
      "Batch 2000: Loss=3.63787841796875; accuracy=0.05225000157952309\n",
      "Validation accuracy: 0.05225000157952309\n",
      "epoch 8\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.704174280166626; accuracy=0.05243750289082527\n",
      "Batch 2000: Loss=3.4883744716644287; accuracy=0.050843752920627594\n",
      "Validation accuracy: 0.05350000411272049\n",
      "epoch 9\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.645904541015625; accuracy=0.05425000190734863\n",
      "Batch 2000: Loss=3.5975446701049805; accuracy=0.05353125184774399\n",
      "Validation accuracy: 0.05025000125169754\n",
      "epoch 10\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.7259507179260254; accuracy=0.05418750271201134\n",
      "Batch 2000: Loss=3.5961804389953613; accuracy=0.05412500351667404\n",
      "Validation accuracy: 0.057500001043081284\n",
      "epoch 11\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.4720733165740967; accuracy=0.06050000339746475\n",
      "Batch 2000: Loss=3.727832794189453; accuracy=0.058906253427267075\n",
      "Validation accuracy: 0.055250003933906555\n",
      "epoch 12\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.7519049644470215; accuracy=0.06231250241398811\n",
      "Batch 2000: Loss=3.7235829830169678; accuracy=0.06043750420212746\n",
      "Validation accuracy: 0.055500004440546036\n",
      "epoch 13\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.4484784603118896; accuracy=0.059562504291534424\n",
      "Batch 2000: Loss=3.4463913440704346; accuracy=0.05762500315904617\n",
      "Validation accuracy: 0.05575000122189522\n",
      "epoch 14\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.5491628646850586; accuracy=0.06012500450015068\n",
      "Batch 2000: Loss=3.634078025817871; accuracy=0.0599062517285347\n",
      "Validation accuracy: 0.05425000190734863\n",
      "epoch 15\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.6706857681274414; accuracy=0.058500003069639206\n",
      "Batch 2000: Loss=3.6731722354888916; accuracy=0.057875003665685654\n",
      "Validation accuracy: 0.051750004291534424\n",
      "epoch 16\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.6197049617767334; accuracy=0.06031250208616257\n",
      "Batch 2000: Loss=3.6761362552642822; accuracy=0.05937500298023224\n",
      "Validation accuracy: 0.058250002562999725\n",
      "epoch 17\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.590547561645508; accuracy=0.05950000137090683\n",
      "Batch 2000: Loss=3.6659176349639893; accuracy=0.060843754559755325\n",
      "Validation accuracy: 0.0560000017285347\n",
      "epoch 18\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.5894620418548584; accuracy=0.06325000524520874\n",
      "Batch 2000: Loss=3.6574435234069824; accuracy=0.06296875327825546\n",
      "Validation accuracy: 0.05625000223517418\n",
      "epoch 19\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.7158868312835693; accuracy=0.06181250140070915\n",
      "Batch 2000: Loss=3.57076096534729; accuracy=0.06171875447034836\n",
      "Validation accuracy: 0.055250003933906555\n",
      "epoch 20\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.6587252616882324; accuracy=0.06081250309944153\n",
      "Batch 2000: Loss=3.5951642990112305; accuracy=0.06181250140070915\n",
      "Validation accuracy: 0.05950000137090683\n",
      "epoch 21\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.5111942291259766; accuracy=0.06275000423192978\n",
      "Batch 2000: Loss=3.715256690979004; accuracy=0.062437504529953\n",
      "Validation accuracy: 0.05675000324845314\n",
      "epoch 22\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.6479249000549316; accuracy=0.06481250375509262\n",
      "Batch 2000: Loss=3.606431007385254; accuracy=0.06456249952316284\n",
      "Validation accuracy: 0.05575000122189522\n",
      "epoch 23\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.521143913269043; accuracy=0.06556250154972076\n",
      "Batch 2000: Loss=3.519179105758667; accuracy=0.0650312528014183\n",
      "Validation accuracy: 0.05650000274181366\n",
      "epoch 24\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.457742214202881; accuracy=0.06562500447034836\n",
      "Batch 2000: Loss=3.74343204498291; accuracy=0.06559375673532486\n",
      "Validation accuracy: 0.05625000223517418\n",
      "epoch 25\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.6776695251464844; accuracy=0.06450000405311584\n",
      "Batch 2000: Loss=3.708491563796997; accuracy=0.06287500262260437\n",
      "Validation accuracy: 0.05650000274181366\n",
      "epoch 26\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.465481996536255; accuracy=0.06456249952316284\n",
      "Batch 2000: Loss=3.6076877117156982; accuracy=0.06421875208616257\n",
      "Validation accuracy: 0.05950000137090683\n",
      "epoch 27\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.729309320449829; accuracy=0.06568749994039536\n",
      "Batch 2000: Loss=3.557487726211548; accuracy=0.06421875208616257\n",
      "Validation accuracy: 0.06050000339746475\n",
      "epoch 28\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.7989277839660645; accuracy=0.06462500244379044\n",
      "Batch 2000: Loss=3.5869247913360596; accuracy=0.06540625542402267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.05975000187754631\n",
      "epoch 29\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.4342727661132812; accuracy=0.06356250494718552\n",
      "Batch 2000: Loss=3.5470194816589355; accuracy=0.06400000303983688\n",
      "Validation accuracy: 0.055000003427267075\n",
      "epoch 30\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.791875123977661; accuracy=0.06850000470876694\n",
      "Batch 2000: Loss=3.3184633255004883; accuracy=0.06534375250339508\n",
      "Validation accuracy: 0.058250002562999725\n",
      "epoch 31\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.580789804458618; accuracy=0.06931250542402267\n",
      "Batch 2000: Loss=3.5937108993530273; accuracy=0.06737500429153442\n",
      "Validation accuracy: 0.05900000408291817\n",
      "epoch 32\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.7675716876983643; accuracy=0.06431250274181366\n",
      "Batch 2000: Loss=3.6637394428253174; accuracy=0.06559375673532486\n",
      "Validation accuracy: 0.06000000238418579\n",
      "epoch 33\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.5521349906921387; accuracy=0.06568749994039536\n",
      "Batch 2000: Loss=3.6273345947265625; accuracy=0.06562500447034836\n",
      "Validation accuracy: 0.05950000137090683\n",
      "epoch 34\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.5216290950775146; accuracy=0.06575000286102295\n",
      "Batch 2000: Loss=3.3505938053131104; accuracy=0.06650000065565109\n",
      "Validation accuracy: 0.057750001549720764\n",
      "epoch 35\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.6443519592285156; accuracy=0.06731250137090683\n",
      "Batch 2000: Loss=3.9606001377105713; accuracy=0.0650312528014183\n",
      "Validation accuracy: 0.06075000390410423\n",
      "epoch 36\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.5942254066467285; accuracy=0.06712500005960464\n",
      "Batch 2000: Loss=3.5330259799957275; accuracy=0.06496874988079071\n",
      "Validation accuracy: 0.06200000271201134\n",
      "epoch 37\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.5179648399353027; accuracy=0.06731250137090683\n",
      "Batch 2000: Loss=3.437180280685425; accuracy=0.06709375232458115\n",
      "Validation accuracy: 0.05950000137090683\n",
      "epoch 38\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.4370129108428955; accuracy=0.06856250017881393\n",
      "Batch 2000: Loss=3.4900360107421875; accuracy=0.06709375232458115\n",
      "Validation accuracy: 0.058500003069639206\n",
      "epoch 39\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.514827251434326; accuracy=0.0690625011920929\n",
      "Batch 2000: Loss=3.5621931552886963; accuracy=0.06650000065565109\n",
      "Validation accuracy: 0.06025000289082527\n",
      "epoch 40\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.39132022857666; accuracy=0.0664375051856041\n",
      "Batch 2000: Loss=3.3706252574920654; accuracy=0.06521875411272049\n",
      "Validation accuracy: 0.06225000321865082\n",
      "epoch 41\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.6235463619232178; accuracy=0.06837500631809235\n",
      "Batch 2000: Loss=3.6982643604278564; accuracy=0.06696875393390656\n",
      "Validation accuracy: 0.05925000458955765\n",
      "epoch 42\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.349998712539673; accuracy=0.06825000047683716\n",
      "Batch 2000: Loss=3.5157272815704346; accuracy=0.0664687529206276\n",
      "Validation accuracy: 0.05900000408291817\n",
      "epoch 43\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.569514036178589; accuracy=0.0690625011920929\n",
      "Batch 2000: Loss=3.598752021789551; accuracy=0.06859375536441803\n",
      "Validation accuracy: 0.058500003069639206\n",
      "epoch 44\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.560814380645752; accuracy=0.0651250034570694\n",
      "Batch 2000: Loss=3.5468249320983887; accuracy=0.06578125059604645\n",
      "Validation accuracy: 0.058000002056360245\n",
      "epoch 45\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.283949613571167; accuracy=0.06681250035762787\n",
      "Batch 2000: Loss=3.482856273651123; accuracy=0.06706250458955765\n",
      "Validation accuracy: 0.05700000375509262\n",
      "epoch 46\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.4965357780456543; accuracy=0.06612500548362732\n",
      "Batch 2000: Loss=3.7163448333740234; accuracy=0.06550000607967377\n",
      "Validation accuracy: 0.06025000289082527\n",
      "epoch 47\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.6307318210601807; accuracy=0.06987500190734863\n",
      "Batch 2000: Loss=3.41510272026062; accuracy=0.06628125160932541\n",
      "Validation accuracy: 0.057500001043081284\n",
      "epoch 48\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.587279796600342; accuracy=0.06612500548362732\n",
      "Batch 2000: Loss=3.756621837615967; accuracy=0.06609375029802322\n",
      "Validation accuracy: 0.05950000137090683\n",
      "epoch 49\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.380981206893921; accuracy=0.06731250137090683\n",
      "Batch 2000: Loss=3.651369094848633; accuracy=0.06650000065565109\n",
      "Validation accuracy: 0.06200000271201134\n",
      "epoch 50\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.5226974487304688; accuracy=0.06806250661611557\n",
      "Batch 2000: Loss=3.576063871383667; accuracy=0.06653125584125519\n",
      "Validation accuracy: 0.06424999982118607\n",
      "epoch 51\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.634755849838257; accuracy=0.06737500429153442\n",
      "Batch 2000: Loss=3.4207019805908203; accuracy=0.06934375315904617\n",
      "Validation accuracy: 0.05925000458955765\n",
      "epoch 52\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.4287354946136475; accuracy=0.06606250256299973\n",
      "Batch 2000: Loss=3.5715489387512207; accuracy=0.06593750417232513\n",
      "Validation accuracy: 0.05575000122189522\n",
      "epoch 53\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.538184404373169; accuracy=0.06881250441074371\n",
      "Batch 2000: Loss=3.439399003982544; accuracy=0.06678125262260437\n",
      "Validation accuracy: 0.06100000441074371\n",
      "epoch 54\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.366805076599121; accuracy=0.0677500069141388\n",
      "Batch 2000: Loss=3.5313024520874023; accuracy=0.06837500631809235\n",
      "Validation accuracy: 0.06175000220537186\n",
      "epoch 55\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.6969385147094727; accuracy=0.06856250017881393\n",
      "Batch 2000: Loss=3.6008682250976562; accuracy=0.0689375028014183\n",
      "Validation accuracy: 0.058750003576278687\n",
      "epoch 56\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.363356590270996; accuracy=0.0716250017285347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2000: Loss=3.3608157634735107; accuracy=0.06843750178813934\n",
      "Validation accuracy: 0.06050000339746475\n",
      "epoch 57\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.6988608837127686; accuracy=0.06931250542402267\n",
      "Batch 2000: Loss=3.3499255180358887; accuracy=0.06800000369548798\n",
      "Validation accuracy: 0.0625\n",
      "epoch 58\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.666477680206299; accuracy=0.07150000333786011\n",
      "Batch 2000: Loss=3.6666533946990967; accuracy=0.07009375095367432\n",
      "Validation accuracy: 0.058000002056360245\n",
      "epoch 59\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.748046636581421; accuracy=0.06781250238418579\n",
      "Batch 2000: Loss=3.741029739379883; accuracy=0.06665625423192978\n",
      "Validation accuracy: 0.05450000241398811\n",
      "epoch 60\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.4488542079925537; accuracy=0.06737500429153442\n",
      "Batch 2000: Loss=3.679008722305298; accuracy=0.06671874970197678\n",
      "Validation accuracy: 0.058250002562999725\n",
      "epoch 61\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.6648237705230713; accuracy=0.06787500530481339\n",
      "Batch 2000: Loss=3.676307201385498; accuracy=0.06715625524520874\n",
      "Validation accuracy: 0.06025000289082527\n",
      "epoch 62\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.5265755653381348; accuracy=0.06918749958276749\n",
      "Batch 2000: Loss=3.4930849075317383; accuracy=0.06668750196695328\n",
      "Validation accuracy: 0.05975000187754631\n",
      "epoch 63\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.626985788345337; accuracy=0.06881250441074371\n",
      "Batch 2000: Loss=3.539794683456421; accuracy=0.06843750178813934\n",
      "Validation accuracy: 0.05925000458955765\n",
      "epoch 64\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.6133265495300293; accuracy=0.06806250661611557\n",
      "Batch 2000: Loss=3.769963264465332; accuracy=0.06837500631809235\n",
      "Validation accuracy: 0.058250002562999725\n",
      "epoch 65\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.333446502685547; accuracy=0.07168750464916229\n",
      "Batch 2000: Loss=3.57621693611145; accuracy=0.06990624964237213\n",
      "Validation accuracy: 0.05975000187754631\n",
      "epoch 66\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.350053310394287; accuracy=0.06831250339746475\n",
      "Batch 2000: Loss=3.512861490249634; accuracy=0.06709375232458115\n",
      "Validation accuracy: 0.06350000202655792\n",
      "epoch 67\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.610948324203491; accuracy=0.06962500512599945\n",
      "Batch 2000: Loss=3.8953659534454346; accuracy=0.06746875494718552\n",
      "Validation accuracy: 0.05950000137090683\n",
      "epoch 68\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.6606407165527344; accuracy=0.0690625011920929\n",
      "Batch 2000: Loss=3.506511688232422; accuracy=0.06846875697374344\n",
      "Validation accuracy: 0.06000000238418579\n",
      "epoch 69\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.480963945388794; accuracy=0.06781250238418579\n",
      "Batch 2000: Loss=3.6269214153289795; accuracy=0.06975000351667404\n",
      "Validation accuracy: 0.06075000390410423\n",
      "epoch 70\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.492100238800049; accuracy=0.0689375028014183\n",
      "Batch 2000: Loss=3.509549140930176; accuracy=0.07059375196695328\n",
      "Validation accuracy: 0.06000000238418579\n",
      "epoch 71\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.405754327774048; accuracy=0.070250004529953\n",
      "Batch 2000: Loss=3.4908881187438965; accuracy=0.07059375196695328\n",
      "Validation accuracy: 0.06050000339746475\n",
      "epoch 72\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.4352500438690186; accuracy=0.07193750143051147\n",
      "Batch 2000: Loss=3.4949867725372314; accuracy=0.06987500190734863\n",
      "Validation accuracy: 0.0625\n",
      "epoch 73\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.3223838806152344; accuracy=0.07225000113248825\n",
      "Batch 2000: Loss=3.567110061645508; accuracy=0.07071875035762787\n",
      "Validation accuracy: 0.06050000339746475\n",
      "epoch 74\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.5661559104919434; accuracy=0.07100000232458115\n",
      "Batch 2000: Loss=3.3744304180145264; accuracy=0.07090625166893005\n",
      "Validation accuracy: 0.055000003427267075\n",
      "epoch 75\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.8316946029663086; accuracy=0.07050000131130219\n",
      "Batch 2000: Loss=3.4455173015594482; accuracy=0.06915625184774399\n",
      "Validation accuracy: 0.05400000140070915\n",
      "epoch 76\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.6004748344421387; accuracy=0.07043750584125519\n",
      "Batch 2000: Loss=3.3089089393615723; accuracy=0.06946875154972076\n",
      "Validation accuracy: 0.05975000187754631\n",
      "epoch 77\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.490570545196533; accuracy=0.06975000351667404\n",
      "Batch 2000: Loss=3.74646258354187; accuracy=0.06990624964237213\n",
      "Validation accuracy: 0.05925000458955765\n",
      "epoch 78\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.5505714416503906; accuracy=0.06862500309944153\n",
      "Batch 2000: Loss=3.844658851623535; accuracy=0.06712500005960464\n",
      "Validation accuracy: 0.057750001549720764\n",
      "epoch 79\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.6403965950012207; accuracy=0.07250000536441803\n",
      "Batch 2000: Loss=3.7203586101531982; accuracy=0.06934375315904617\n",
      "Validation accuracy: 0.06275000423192978\n",
      "epoch 80\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.4231784343719482; accuracy=0.07100000232458115\n",
      "Batch 2000: Loss=3.6941027641296387; accuracy=0.0689375028014183\n",
      "Validation accuracy: 0.06025000289082527\n",
      "epoch 81\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.3772196769714355; accuracy=0.07050000131130219\n",
      "Batch 2000: Loss=3.1703479290008545; accuracy=0.06984375417232513\n",
      "Validation accuracy: 0.06400000303983688\n",
      "epoch 82\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.7290101051330566; accuracy=0.07231250405311584\n",
      "Batch 2000: Loss=3.4982218742370605; accuracy=0.07059375196695328\n",
      "Validation accuracy: 0.06350000202655792\n",
      "epoch 83\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.6342434883117676; accuracy=0.07050000131130219\n",
      "Batch 2000: Loss=3.5137829780578613; accuracy=0.07062499970197678\n",
      "Validation accuracy: 0.06300000101327896\n",
      "epoch 84\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.549362897872925; accuracy=0.06862500309944153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2000: Loss=3.702512741088867; accuracy=0.06921875476837158\n",
      "Validation accuracy: 0.061250001192092896\n",
      "epoch 85\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.5404927730560303; accuracy=0.07331250607967377\n",
      "Batch 2000: Loss=3.6607563495635986; accuracy=0.07040625065565109\n",
      "Validation accuracy: 0.057500001043081284\n",
      "epoch 86\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.4906582832336426; accuracy=0.0715625062584877\n",
      "Batch 2000: Loss=3.4337708950042725; accuracy=0.07046875357627869\n",
      "Validation accuracy: 0.058000002056360245\n",
      "epoch 87\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.5095365047454834; accuracy=0.07218750566244125\n",
      "Batch 2000: Loss=3.62040114402771; accuracy=0.07100000232458115\n",
      "Validation accuracy: 0.05975000187754631\n",
      "epoch 88\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.3681063652038574; accuracy=0.07300000637769699\n",
      "Batch 2000: Loss=3.610258102416992; accuracy=0.07059375196695328\n",
      "Validation accuracy: 0.05900000408291817\n",
      "epoch 89\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.380037307739258; accuracy=0.07206249982118607\n",
      "Batch 2000: Loss=3.5717501640319824; accuracy=0.07103125005960464\n",
      "Validation accuracy: 0.05975000187754631\n",
      "epoch 90\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.6545541286468506; accuracy=0.07437500357627869\n",
      "Batch 2000: Loss=3.4403579235076904; accuracy=0.07140625268220901\n",
      "Validation accuracy: 0.055000003427267075\n",
      "epoch 91\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.366177797317505; accuracy=0.06950000673532486\n",
      "Batch 2000: Loss=3.624300479888916; accuracy=0.06984375417232513\n",
      "Validation accuracy: 0.06075000390410423\n",
      "epoch 92\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.5318121910095215; accuracy=0.07125000655651093\n",
      "Batch 2000: Loss=3.4825668334960938; accuracy=0.06918749958276749\n",
      "Validation accuracy: 0.06050000339746475\n",
      "epoch 93\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.6484901905059814; accuracy=0.07187500596046448\n",
      "Batch 2000: Loss=3.6113717555999756; accuracy=0.0689687505364418\n",
      "Validation accuracy: 0.055250003933906555\n",
      "epoch 94\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.772264242172241; accuracy=0.07112500071525574\n",
      "Batch 2000: Loss=3.4778871536254883; accuracy=0.07065625488758087\n",
      "Validation accuracy: 0.06225000321865082\n",
      "epoch 95\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.7975239753723145; accuracy=0.06856250017881393\n",
      "Batch 2000: Loss=3.768954277038574; accuracy=0.07068750262260437\n",
      "Validation accuracy: 0.06175000220537186\n",
      "epoch 96\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.524247407913208; accuracy=0.07375000417232513\n",
      "Batch 2000: Loss=3.5163772106170654; accuracy=0.06987500190734863\n",
      "Validation accuracy: 0.058500003069639206\n",
      "epoch 97\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.5742099285125732; accuracy=0.0703125\n",
      "Batch 2000: Loss=3.5778300762176514; accuracy=0.06950000673532486\n",
      "Validation accuracy: 0.05400000140070915\n",
      "epoch 98\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.53294038772583; accuracy=0.07312500476837158\n",
      "Batch 2000: Loss=3.527693033218384; accuracy=0.06987500190734863\n",
      "Validation accuracy: 0.05925000458955765\n",
      "epoch 99\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.767435073852539; accuracy=0.07275000214576721\n",
      "Batch 2000: Loss=3.7977492809295654; accuracy=0.0703125\n",
      "Validation accuracy: 0.05950000137090683\n",
      "epoch 100\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.816592216491699; accuracy=0.07012500613927841\n",
      "Batch 2000: Loss=3.449317455291748; accuracy=0.07090625166893005\n",
      "Validation accuracy: 0.0572500042617321\n"
     ]
    }
   ],
   "source": [
    "if opt.kind==\"from-scratch\":\n",
    "    loss_history, accuracy_val, accuracy_test = net_trainer(\n",
    "            net,\n",
    "            loaders,\n",
    "            opt,\n",
    "            channel_idx,\n",
    "            nonclasses,\n",
    "            None,\n",
    "            True,\n",
    "            model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52ac79d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy:  0.0572500042617321\n",
      "Test accuracy:  0\n"
     ]
    }
   ],
   "source": [
    "val =accuracy_val\n",
    "test = accuracy_test\n",
    "\n",
    "print(\"Validation accuracy: \", val)\n",
    "print(\"Test accuracy: \", test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0931fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfe0373",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c3beab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab45327",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2179d69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ed6c4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2060d560",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb54c13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6467f813",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d16c15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45955f5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52331151",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca94e7f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfe619b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a58f0c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8236ccbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44249203",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f168b18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edd8a18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63556efb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6b09c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9eb88b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
