{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3675927f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from analysis import *\n",
    "import argparse\n",
    "from sys import platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e2301c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(12)\n",
    "torch.cuda.manual_seed(12)\n",
    "np.random.seed(12)\n",
    "torch.backends.cudnn.deterministics = True\n",
    "torch.set_num_threads(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7454d60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "0\n",
      "<torch.cuda.device object at 0x7fbfd06f49d0>\n",
      "NVIDIA TITAN V\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.current_device())\n",
    "\n",
    "print(torch.cuda.device(0))\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "499dbec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iv: image option\n",
    "length = 512\n",
    "channel = 96\n",
    "min_CNN = 200\n",
    "n_classes = 40\n",
    "classes = range(n_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cef3bc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "if platform == \"linux\" or platform == \"linux2\":\n",
    "    torch_models_dir = r\"/media/titan/AI Research/Data/CVPR2021-02785/CVPR2021-02785/preprocessed/torch_models\"\n",
    "elif platform == \"win32\":\n",
    "    torch_models_dir = r\"D:\\Data\\CVPR2021-02785\\CVPR2021-02785\\preprocessed\\torch_models\"\n",
    "eeg_dataset, splits_path, splits_shuffled_path = os.listdir(torch_models_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37e239e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/titan/AI Research/Data/CVPR2021-02785/CVPR2021-02785/preprocessed/torch_models/imagenet40-1000-1.pth \n",
      " /media/titan/AI Research/Data/CVPR2021-02785/CVPR2021-02785/preprocessed/torch_models/imagenet40-1000-1_splits.pth\n"
     ]
    }
   ],
   "source": [
    "eeg_dataset = os.path.join(torch_models_dir, eeg_dataset)\n",
    "splits_path = os.path.join(torch_models_dir, splits_path)\n",
    "# splits_path = os.path.join(torch_models_dir, splits_shuffled_path)\n",
    "print(eeg_dataset,'\\n', splits_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "009ff0e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image\n"
     ]
    }
   ],
   "source": [
    "opt = {\n",
    "    # Dataset options\n",
    "    \"iv\": \"image\",\n",
    "    \"offset\": None,\n",
    "    \"results_file\": \"results.pkl\",\n",
    "    \"subject\": 0,\n",
    "    \"run\": \"none\",\n",
    "    \"eeg_dataset\": eeg_dataset,\n",
    "    \"splits_path\": splits_path,\n",
    "    \"fold\": 5,\n",
    "    #Training options\n",
    "    \"batch_size\": 16,\n",
    "    \"optim\": \"Adam\",\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"learning_rate_decay_by\": 0.5,\n",
    "    \"learning_rate_decay_every\": 10,\n",
    "    \"epochs\": 100,\n",
    "    \"GPUindex\": 0,\n",
    "    \"kind\":\"incremental\",\n",
    "    #Backend options\n",
    "    \"no_cuda\": False,\n",
    "    \"classifier\": None\n",
    "}\n",
    "opt = argparse.Namespace(**opt)\n",
    "print(opt.iv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c8df9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from torch.utils.data import DataLoader\n",
    "from data_loader import EEGDataset, Splitter, SplitterWithData\n",
    "from EEG_Encoder.LSTM import classifier_LSTM\n",
    "from EEG_Encoder.CNN import classifier_CNN\n",
    "from EEG_Encoder.EEGNet import classifier_EEGNet\n",
    "from EEG_Encoder.SyncNet import classifier_SyncNet\n",
    "from EEG_Encoder.EEGChannelNet import classifier_EEGChannelNet\n",
    "from EEG_Encoder.net_generator import Classifier\n",
    "from EEG_Encoder.net_trainer import net_trainer\n",
    "from p_values import *\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30bd6700",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(iv,\n",
    "             offset,\n",
    "             eeg_dataset,\n",
    "             splits_path,\n",
    "             split_num, # (0-4) - 5 fold cross validation\n",
    "             total,\n",
    "             classes,\n",
    "             classifier,\n",
    "             batch_size,\n",
    "             GPUindex,\n",
    "             length, # 512\n",
    "             channel, # 96\n",
    "             min_CNN,\n",
    "             opt,\n",
    "             kind):        \n",
    "    # Load dataset\n",
    "    dataset = EEGDataset(iv, eeg_dataset, classifier, map_idx = None)\n",
    "    print(\"DONE: LOAD DATASET\")\n",
    "    # Create loaders for LSTM/MLP/CNN/SCNN/EEGNet/SyncNet/EEGChannelNet\n",
    "    if kind==\"from-scratch\":\n",
    "        relabel = False\n",
    "    if kind==\"incremental\":\n",
    "        relabel = False\n",
    "    if kind==\"no-model-file\":\n",
    "        relabel = True\n",
    "    splitter = {split: SplitterWithData(iv,\n",
    "                    dataset,\n",
    "                    splits_path,\n",
    "                    classes,\n",
    "                    split_num,\n",
    "                    split,\n",
    "                    relabel) for split in [\"train\", \"val\", \"test\"]}\n",
    "    loaders = {split: DataLoader(\n",
    "                        splitter[split],\n",
    "                        batch_size = batch_size,\n",
    "                        drop_last = False,\n",
    "                        shuffle = True)\n",
    "                    for split in [\"train\", \"val\", \"test\"]}\n",
    "    channel_idx = None    \n",
    "    print(\"DONE: Create loaders for model\")            \n",
    "    return dataset, loaders, splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aae9c3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EEGNet network\n",
    "opt.classifier = \"EEGNet\"\n",
    "opt.batch_size = 16\n",
    "opt.kind = \"from-scratch\"\n",
    "opt.run = \"imagenet40-1000\"\n",
    "opt.fold = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8455f252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE: LOAD DATASET\n",
      "DONE: Create loaders for model\n"
     ]
    }
   ],
   "source": [
    "dataset, loaders, splitter = load_dataset(opt.iv,\n",
    "                             opt.offset,\n",
    "                             opt.eeg_dataset,\n",
    "                             opt.splits_path,\n",
    "                             0, #split_num\n",
    "                             n_classes,\n",
    "                             classes,\n",
    "                             opt.classifier,\n",
    "                             opt.batch_size,\n",
    "                             opt.GPUindex,\n",
    "                             length,\n",
    "                             channel,\n",
    "                             min_CNN,\n",
    "                             opt,\n",
    "                             opt.kind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8191cbe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'data_loader.EEGDataset'>\n",
      "<class 'dict'>\n",
      "3 [2000, 250, 250]\n",
      "1: Label val: 0; label train: 0\n",
      "2: Label val: 17; label train: 17\n",
      "3: Label val: 28; label train: 28\n",
      "4: Label val: 7; label train: 7\n",
      "5: Label val: 33; label train: 33\n",
      "6: Label val: 12; label train: 12\n",
      "7: Label val: 21; label train: 21\n",
      "8: Label val: 3; label train: 3\n",
      "9: Label val: 25; label train: 25\n",
      "10: Label val: 36; label train: 36\n",
      "11: Label val: 10; label train: 10\n",
      "12: Label val: 15; label train: 15\n",
      "13: Label val: 19; label train: 19\n",
      "14: Label val: 31; label train: 31\n",
      "15: Label val: 23; label train: 23\n",
      "16: Label val: 5; label train: 5\n",
      "17: Label val: 38; label train: 38\n",
      "18: Label val: 8; label train: 8\n",
      "19: Label val: 1; label train: 1\n",
      "20: Label val: 34; label train: 34\n",
      "21: Label val: 29; label train: 29\n",
      "22: Label val: 26; label train: 26\n",
      "23: Label val: 13; label train: 13\n",
      "24: Label val: 11; label train: 11\n",
      "25: Label val: 22; label train: 22\n",
      "26: Label val: 18; label train: 18\n",
      "27: Label val: 6; label train: 6\n",
      "28: Label val: 16; label train: 16\n",
      "29: Label val: 4; label train: 4\n",
      "30: Label val: 20; label train: 20\n",
      "31: Label val: 32; label train: 32\n",
      "32: Label val: 9; label train: 9\n",
      "33: Label val: 37; label train: 37\n",
      "34: Label val: 24; label train: 24\n",
      "35: Label val: 39; label train: 39\n",
      "36: Label val: 2; label train: 2\n",
      "37: Label val: 35; label train: 35\n",
      "38: Label val: 30; label train: 30\n",
      "39: Label val: 27; label train: 27\n",
      "40: Label val: 14; label train: 14\n"
     ]
    }
   ],
   "source": [
    "# loaders: divide the splits data in each fold with batch_size\n",
    "# Each fold has {train: 32000 idx, val: 4000 idx, test: 4000 idx}\n",
    "# Each loader batch has {train: 2000 idx, val: 250idx, test: 250 idx}\n",
    "print(type(dataset))\n",
    "print(type(loaders))\n",
    "print(len(loaders), [len(loaders[name]) for name in [\"train\", \"val\", \"test\"] ])\n",
    "for i in range(0, 40):\n",
    "    eeg, label_val = splitter[\"val\"][i*100]\n",
    "    eeg, label_train = splitter[\"train\"][i*800]\n",
    "    print(f\"{i+1}: Label val: {label_val}; label train: {label_train}\")\n",
    "# print(splitter[\"val\"].split_idx[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e95cc78d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE: CREATE TORCH CLASSIFIER\n",
      "classifier_EEGNet(\n",
      "  (network): Sequential(\n",
      "    (0): ZeroPad2d((128, 127, 0, 0))\n",
      "    (1): Conv2d(1, 8, kernel_size=(1, 256), stride=(1, 1))\n",
      "    (2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Conv2d(8, 8, kernel_size=(96, 1), stride=(1, 1), groups=8)\n",
      "    (4): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ELU(alpha=1.0)\n",
      "    (7): AvgPool2d(kernel_size=(1, 4), stride=(1, 4), padding=0)\n",
      "    (8): Dropout(p=0.5, inplace=False)\n",
      "    (9): ZeroPad2d((8, 7, 0, 0))\n",
      "    (10): Conv2d(16, 16, kernel_size=(1, 16), stride=(1, 1), groups=8)\n",
      "    (11): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (12): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (13): ELU(alpha=1.0)\n",
      "    (14): AvgPool2d(kernel_size=(1, 8), stride=(1, 8), padding=0)\n",
      "    (15): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (fc): Linear(in_features=256, out_features=40, bias=True)\n",
      ")\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to run torchinfo. See above stack traces for more details. Executed layers up to: [Sequential: 1, ZeroPad2d: 2, Conv2d: 2, BatchNorm2d: 2, Conv2d: 2, Conv2d: 2, BatchNorm2d: 2, ELU: 2, AvgPool2d: 2, Dropout: 2, ZeroPad2d: 2, Conv2d: 2, Conv2d: 2, BatchNorm2d: 2, ELU: 2, AvgPool2d: 2, Dropout: 2]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/GithubClonedRepo/EEG-Research/.env/lib/python3.9/site-packages/torchinfo/torchinfo.py:287\u001b[0m, in \u001b[0;36mforward_pass\u001b[0;34m(model, x, batch_dim, cache_forward_pass, device, mode, **kwargs)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m--> 287\u001b[0m     _ \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):\n",
      "File \u001b[0;32m~/GithubClonedRepo/EEG-Research/.env/lib/python3.9/site-packages/torch/nn/modules/module.py:1208\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1206\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m-> 1208\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n",
      "File \u001b[0;32m~/GithubClonedRepo/EEG-Research/Experiment/EEG_Encoder/EEGNet.py:58\u001b[0m, in \u001b[0;36mclassifier_EEGNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     57\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(x\u001b[38;5;241m.\u001b[39msize()[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 58\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/GithubClonedRepo/EEG-Research/.env/lib/python3.9/site-packages/torch/nn/modules/module.py:1208\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1206\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m-> 1208\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n",
      "File \u001b[0;32m~/GithubClonedRepo/EEG-Research/.env/lib/python3.9/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x20016 and 256x40)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 11\u001b[0m\n\u001b[1;32m      1\u001b[0m net, nonclasses \u001b[38;5;241m=\u001b[39m Classifier(\n\u001b[1;32m      2\u001b[0m                  n_classes,\n\u001b[1;32m      3\u001b[0m                  classes,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m                  min_CNN,\n\u001b[1;32m      9\u001b[0m                  opt\u001b[38;5;241m.\u001b[39mkind)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# print(len(nonclasses))\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[43msummary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m96\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/GithubClonedRepo/EEG-Research/.env/lib/python3.9/site-packages/torchinfo/torchinfo.py:217\u001b[0m, in \u001b[0;36msummary\u001b[0;34m(model, input_size, input_data, batch_dim, cache_forward_pass, col_names, col_width, depth, device, dtypes, mode, row_settings, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m validate_user_params(\n\u001b[1;32m    211\u001b[0m     input_data, input_size, columns, col_width, device, dtypes, verbose\n\u001b[1;32m    212\u001b[0m )\n\u001b[1;32m    214\u001b[0m x, correct_input_size \u001b[38;5;241m=\u001b[39m process_input(\n\u001b[1;32m    215\u001b[0m     input_data, input_size, batch_dim, device, dtypes\n\u001b[1;32m    216\u001b[0m )\n\u001b[0;32m--> 217\u001b[0m summary_list \u001b[38;5;241m=\u001b[39m \u001b[43mforward_pass\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_forward_pass\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m formatting \u001b[38;5;241m=\u001b[39m FormattingOptions(depth, verbose, columns, col_width, rows)\n\u001b[1;32m    221\u001b[0m results \u001b[38;5;241m=\u001b[39m ModelStatistics(\n\u001b[1;32m    222\u001b[0m     summary_list, correct_input_size, get_total_memory_used(x), formatting\n\u001b[1;32m    223\u001b[0m )\n",
      "File \u001b[0;32m~/GithubClonedRepo/EEG-Research/.env/lib/python3.9/site-packages/torchinfo/torchinfo.py:296\u001b[0m, in \u001b[0;36mforward_pass\u001b[0;34m(model, x, batch_dim, cache_forward_pass, device, mode, **kwargs)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    295\u001b[0m     executed_layers \u001b[38;5;241m=\u001b[39m [layer \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m summary_list \u001b[38;5;28;01mif\u001b[39;00m layer\u001b[38;5;241m.\u001b[39mexecuted]\n\u001b[0;32m--> 296\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    297\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to run torchinfo. See above stack traces for more details. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    298\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecuted layers up to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexecuted_layers\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    299\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hooks:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to run torchinfo. See above stack traces for more details. Executed layers up to: [Sequential: 1, ZeroPad2d: 2, Conv2d: 2, BatchNorm2d: 2, Conv2d: 2, Conv2d: 2, BatchNorm2d: 2, ELU: 2, AvgPool2d: 2, Dropout: 2, ZeroPad2d: 2, Conv2d: 2, Conv2d: 2, BatchNorm2d: 2, ELU: 2, AvgPool2d: 2, Dropout: 2]"
     ]
    }
   ],
   "source": [
    "net, nonclasses = Classifier(\n",
    "                 n_classes,\n",
    "                 classes,\n",
    "                 opt.classifier,\n",
    "                 opt.GPUindex,\n",
    "                 length,\n",
    "                 channel,\n",
    "                 min_CNN,\n",
    "                 opt.kind)\n",
    "# print(len(nonclasses))\n",
    "summary(net, input_size=(1, 96, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9527792e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image-LSTM4-512-96-0-noshuffle\n"
     ]
    }
   ],
   "source": [
    "model_path = (opt.iv+\n",
    "                  \"-\"+\n",
    "                  opt.classifier+\n",
    "                  \"-\"+\n",
    "                  str(length)+\n",
    "                  \"-\"+\n",
    "                  str(channel)+\n",
    "                  \"-\"+\n",
    "                  str(0)) + \"-noshuffle\"\n",
    "                  \n",
    "channel_idx=None\n",
    "print(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "789e1be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(iv='image', offset=None, results_file='results.pkl', subject=0, run='imagenet40-1000', eeg_dataset='/media/titan/AI Research/Data/CVPR2021-02785/CVPR2021-02785/preprocessed/torch_models/imagenet40-1000-1.pth', splits_path='/media/titan/AI Research/Data/CVPR2021-02785/CVPR2021-02785/preprocessed/torch_models/imagenet40-1000-1_splits.pth', fold=5, batch_size=16, optim='Adam', learning_rate=0.001, learning_rate_decay_by=0.5, learning_rate_decay_every=10, epochs=100, GPUindex=0, kind='from-scratch', no_cuda=False, classifier='LSTM4')\n"
     ]
    }
   ],
   "source": [
    "print(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2d6a7ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "Batch 1000: Loss=3.69807767868042; accuracy=0.024312501773238182\n",
      "Batch 2000: Loss=3.682100772857666; accuracy=0.02328125201165676\n",
      "Validation accuracy: 0.024500001221895218\n",
      "epoch 2\n",
      "Batch 1000: Loss=3.6951308250427246; accuracy=0.026625001803040504\n",
      "Batch 2000: Loss=3.694836139678955; accuracy=0.02565625123679638\n",
      "Validation accuracy: 0.026500001549720764\n",
      "epoch 3\n",
      "Batch 1000: Loss=3.639098644256592; accuracy=0.027500001713633537\n",
      "Batch 2000: Loss=3.7039482593536377; accuracy=0.02721875160932541\n",
      "Validation accuracy: 0.023750001564621925\n",
      "epoch 4\n",
      "Batch 1000: Loss=3.6887049674987793; accuracy=0.02981250174343586\n",
      "Batch 2000: Loss=3.7389333248138428; accuracy=0.028937501832842827\n",
      "Validation accuracy: 0.029750000685453415\n",
      "epoch 5\n",
      "Batch 1000: Loss=3.659647226333618; accuracy=0.03825000301003456\n",
      "Batch 2000: Loss=3.6892478466033936; accuracy=0.037312500178813934\n",
      "Validation accuracy: 0.027750002220273018\n",
      "epoch 6\n",
      "Batch 1000: Loss=3.7015676498413086; accuracy=0.04675000160932541\n",
      "Batch 2000: Loss=3.67842435836792; accuracy=0.04518750309944153\n",
      "Validation accuracy: 0.0247500017285347\n",
      "epoch 7\n",
      "Batch 1000: Loss=3.6060163974761963; accuracy=0.05650000274181366\n",
      "Batch 2000: Loss=3.6776177883148193; accuracy=0.05540625378489494\n",
      "Validation accuracy: 0.023750001564621925\n",
      "epoch 8\n",
      "Batch 1000: Loss=3.253727912902832; accuracy=0.07187500596046448\n",
      "Batch 2000: Loss=3.4542453289031982; accuracy=0.06946875154972076\n",
      "Validation accuracy: 0.027500001713633537\n",
      "epoch 9\n",
      "Batch 1000: Loss=3.621086597442627; accuracy=0.09606250375509262\n",
      "Batch 2000: Loss=3.5378260612487793; accuracy=0.09275000542402267\n",
      "Validation accuracy: 0.026750002056360245\n",
      "epoch 10\n",
      "Batch 1000: Loss=3.3696069717407227; accuracy=0.12031250447034836\n",
      "Batch 2000: Loss=3.449979066848755; accuracy=0.11609375476837158\n",
      "Validation accuracy: 0.027000000700354576\n",
      "epoch 11\n",
      "Batch 1000: Loss=3.4187867641448975; accuracy=0.14737500250339508\n",
      "Batch 2000: Loss=2.6784870624542236; accuracy=0.1417500078678131\n",
      "Validation accuracy: 0.027000000700354576\n",
      "epoch 12\n",
      "Batch 1000: Loss=2.963153600692749; accuracy=0.17525000870227814\n",
      "Batch 2000: Loss=3.3885791301727295; accuracy=0.16556251049041748\n",
      "Validation accuracy: 0.02525000087916851\n",
      "epoch 13\n",
      "Batch 1000: Loss=2.2288520336151123; accuracy=0.20150001347064972\n",
      "Batch 2000: Loss=3.1817755699157715; accuracy=0.1915625035762787\n",
      "Validation accuracy: 0.026000000536441803\n",
      "epoch 14\n",
      "Batch 1000: Loss=2.5694327354431152; accuracy=0.22437500953674316\n",
      "Batch 2000: Loss=3.189119338989258; accuracy=0.21525001525878906\n",
      "Validation accuracy: 0.02525000087916851\n",
      "epoch 15\n",
      "Batch 1000: Loss=2.5901124477386475; accuracy=0.2594375014305115\n",
      "Batch 2000: Loss=2.909879207611084; accuracy=0.2445937544107437\n",
      "Validation accuracy: 0.026750002056360245\n",
      "epoch 16\n",
      "Batch 1000: Loss=3.0624399185180664; accuracy=0.2836250066757202\n",
      "Batch 2000: Loss=2.9670071601867676; accuracy=0.26856252551078796\n",
      "Validation accuracy: 0.02175000123679638\n",
      "epoch 17\n",
      "Batch 1000: Loss=2.346048593521118; accuracy=0.3087500035762787\n",
      "Batch 2000: Loss=2.924311399459839; accuracy=0.29090625047683716\n",
      "Validation accuracy: 0.023000001907348633\n",
      "epoch 18\n",
      "Batch 1000: Loss=2.6316535472869873; accuracy=0.3294375240802765\n",
      "Batch 2000: Loss=2.734726905822754; accuracy=0.31418752670288086\n",
      "Validation accuracy: 0.026250001043081284\n",
      "epoch 19\n",
      "Batch 1000: Loss=2.164891242980957; accuracy=0.35350000858306885\n",
      "Batch 2000: Loss=2.7247869968414307; accuracy=0.3356562554836273\n",
      "Validation accuracy: 0.024250000715255737\n",
      "epoch 20\n",
      "Batch 1000: Loss=1.9449515342712402; accuracy=0.37318751215934753\n",
      "Batch 2000: Loss=2.4785521030426025; accuracy=0.35456252098083496\n",
      "Validation accuracy: 0.022750001400709152\n",
      "epoch 21\n",
      "Batch 1000: Loss=2.56422758102417; accuracy=0.3954375088214874\n",
      "Batch 2000: Loss=2.359189033508301; accuracy=0.3724687695503235\n",
      "Validation accuracy: 0.02175000123679638\n",
      "epoch 22\n",
      "Batch 1000: Loss=1.7518141269683838; accuracy=0.4111250340938568\n",
      "Batch 2000: Loss=2.105459451675415; accuracy=0.38865625858306885\n",
      "Validation accuracy: 0.024000000208616257\n",
      "epoch 23\n",
      "Batch 1000: Loss=2.274237632751465; accuracy=0.4283750057220459\n",
      "Batch 2000: Loss=2.224717140197754; accuracy=0.4075937569141388\n",
      "Validation accuracy: 0.02575000189244747\n",
      "epoch 24\n",
      "Batch 1000: Loss=1.7812715768814087; accuracy=0.4442500174045563\n",
      "Batch 2000: Loss=2.131157636642456; accuracy=0.42265626788139343\n",
      "Validation accuracy: 0.023750001564621925\n",
      "epoch 25\n",
      "Batch 1000: Loss=1.5132553577423096; accuracy=0.46143752336502075\n",
      "Batch 2000: Loss=2.770139694213867; accuracy=0.4390312731266022\n",
      "Validation accuracy: 0.027250001206994057\n",
      "epoch 26\n",
      "Batch 1000: Loss=1.9490994215011597; accuracy=0.47175002098083496\n",
      "Batch 2000: Loss=2.409879446029663; accuracy=0.4506875276565552\n",
      "Validation accuracy: 0.026500001549720764\n",
      "epoch 27\n",
      "Batch 1000: Loss=1.8524364233016968; accuracy=0.4895000159740448\n",
      "Batch 2000: Loss=1.5879416465759277; accuracy=0.46415627002716064\n",
      "Validation accuracy: 0.021250000223517418\n",
      "epoch 28\n",
      "Batch 1000: Loss=1.8951040506362915; accuracy=0.5000625252723694\n",
      "Batch 2000: Loss=1.5045742988586426; accuracy=0.47587502002716064\n",
      "Validation accuracy: 0.02500000037252903\n",
      "epoch 29\n",
      "Batch 1000: Loss=1.5478942394256592; accuracy=0.5120000243186951\n",
      "Batch 2000: Loss=2.0915188789367676; accuracy=0.49028128385543823\n",
      "Validation accuracy: 0.024250000715255737\n",
      "epoch 30\n",
      "Batch 1000: Loss=2.154583692550659; accuracy=0.5243124961853027\n",
      "Batch 2000: Loss=1.7155007123947144; accuracy=0.503656268119812\n",
      "Validation accuracy: 0.024500001221895218\n",
      "epoch 31\n",
      "Batch 1000: Loss=1.3977384567260742; accuracy=0.5297500491142273\n",
      "Batch 2000: Loss=1.4404045343399048; accuracy=0.5056563019752502\n",
      "Validation accuracy: 0.02175000123679638\n",
      "epoch 32\n",
      "Batch 1000: Loss=1.137287974357605; accuracy=0.5447500348091125\n",
      "Batch 2000: Loss=2.060091495513916; accuracy=0.5164687633514404\n",
      "Validation accuracy: 0.02525000087916851\n",
      "epoch 33\n",
      "Batch 1000: Loss=1.992319941520691; accuracy=0.5493125319480896\n",
      "Batch 2000: Loss=1.85992431640625; accuracy=0.526062548160553\n",
      "Validation accuracy: 0.02575000189244747\n",
      "epoch 34\n",
      "Batch 1000: Loss=1.7441813945770264; accuracy=0.5661875009536743\n",
      "Batch 2000: Loss=2.322870969772339; accuracy=0.5388437509536743\n",
      "Validation accuracy: 0.02575000189244747\n",
      "epoch 35\n",
      "Batch 1000: Loss=1.6703721284866333; accuracy=0.5546875\n",
      "Batch 2000: Loss=2.0996127128601074; accuracy=0.5385000109672546\n",
      "Validation accuracy: 0.024250000715255737\n",
      "epoch 36\n",
      "Batch 1000: Loss=1.279471755027771; accuracy=0.5737500190734863\n",
      "Batch 2000: Loss=2.14935564994812; accuracy=0.5498125553131104\n",
      "Validation accuracy: 0.024250000715255737\n",
      "epoch 37\n",
      "Batch 1000: Loss=1.5067577362060547; accuracy=0.573312520980835\n",
      "Batch 2000: Loss=1.332184076309204; accuracy=0.5565625429153442\n",
      "Validation accuracy: 0.027000000700354576\n",
      "epoch 38\n",
      "Batch 1000: Loss=1.5039125680923462; accuracy=0.5841250419616699\n",
      "Batch 2000: Loss=1.8323959112167358; accuracy=0.5608749985694885\n",
      "Validation accuracy: 0.02550000138580799\n",
      "epoch 39\n",
      "Batch 1000: Loss=1.1665215492248535; accuracy=0.5909375548362732\n",
      "Batch 2000: Loss=1.639227271080017; accuracy=0.5706562995910645\n",
      "Validation accuracy: 0.0215000007301569\n",
      "epoch 40\n",
      "Batch 1000: Loss=1.2319632768630981; accuracy=0.6055000424385071\n",
      "Batch 2000: Loss=1.1672052145004272; accuracy=0.5769062638282776\n",
      "Validation accuracy: 0.02250000089406967\n",
      "epoch 41\n",
      "Batch 1000: Loss=1.626591682434082; accuracy=0.6052500009536743\n",
      "Batch 2000: Loss=1.9319391250610352; accuracy=0.5810625553131104\n",
      "Validation accuracy: 0.022750001400709152\n",
      "epoch 42\n",
      "Batch 1000: Loss=2.027149200439453; accuracy=0.6054375171661377\n",
      "Batch 2000: Loss=1.3775163888931274; accuracy=0.58531254529953\n",
      "Validation accuracy: 0.02525000087916851\n",
      "epoch 43\n",
      "Batch 1000: Loss=1.2011486291885376; accuracy=0.6063125133514404\n",
      "Batch 2000: Loss=2.5660932064056396; accuracy=0.5568437576293945\n",
      "Validation accuracy: 0.026750002056360245\n",
      "epoch 44\n",
      "Batch 1000: Loss=2.934058427810669; accuracy=0.24393750727176666\n",
      "Batch 2000: Loss=2.804523229598999; accuracy=0.2604375183582306\n",
      "Validation accuracy: 0.024000000208616257\n",
      "epoch 45\n",
      "Batch 1000: Loss=2.4085168838500977; accuracy=0.3344375193119049\n",
      "Batch 2000: Loss=1.916590690612793; accuracy=0.34584376215934753\n",
      "Validation accuracy: 0.023500001057982445\n",
      "epoch 46\n",
      "Batch 1000: Loss=1.765213966369629; accuracy=0.4306875169277191\n",
      "Batch 2000: Loss=2.305807590484619; accuracy=0.43540626764297485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.02500000037252903\n",
      "epoch 47\n",
      "Batch 1000: Loss=1.9441933631896973; accuracy=0.5194375514984131\n",
      "Batch 2000: Loss=1.7073335647583008; accuracy=0.5194375514984131\n",
      "Validation accuracy: 0.02250000089406967\n",
      "epoch 48\n",
      "Batch 1000: Loss=1.6344726085662842; accuracy=0.5908750295639038\n",
      "Batch 2000: Loss=1.9735945463180542; accuracy=0.581000030040741\n",
      "Validation accuracy: 0.02500000037252903\n",
      "epoch 49\n",
      "Batch 1000: Loss=1.0613901615142822; accuracy=0.6303125023841858\n",
      "Batch 2000: Loss=1.744102954864502; accuracy=0.6117812991142273\n",
      "Validation accuracy: 0.022750001400709152\n",
      "epoch 50\n",
      "Batch 1000: Loss=1.51731276512146; accuracy=0.6423125267028809\n",
      "Batch 2000: Loss=1.951135277748108; accuracy=0.6145000457763672\n",
      "Validation accuracy: 0.027000000700354576\n",
      "epoch 51\n",
      "Batch 1000: Loss=1.0764812231063843; accuracy=0.6425625085830688\n",
      "Batch 2000: Loss=1.255126714706421; accuracy=0.6198750138282776\n",
      "Validation accuracy: 0.023500001057982445\n",
      "epoch 52\n",
      "Batch 1000: Loss=0.9836709499359131; accuracy=0.6391875147819519\n",
      "Batch 2000: Loss=1.4945107698440552; accuracy=0.6194688081741333\n",
      "Validation accuracy: 0.024250000715255737\n",
      "epoch 53\n",
      "Batch 1000: Loss=0.6161552667617798; accuracy=0.6329375505447388\n",
      "Batch 2000: Loss=0.7959479093551636; accuracy=0.6090312600135803\n",
      "Validation accuracy: 0.02175000123679638\n",
      "epoch 54\n",
      "Batch 1000: Loss=1.3171396255493164; accuracy=0.6315625309944153\n",
      "Batch 2000: Loss=1.0401465892791748; accuracy=0.6105937957763672\n",
      "Validation accuracy: 0.024500001221895218\n",
      "epoch 55\n",
      "Batch 1000: Loss=1.686568021774292; accuracy=0.6496250033378601\n",
      "Batch 2000: Loss=1.44264817237854; accuracy=0.6205312609672546\n",
      "Validation accuracy: 0.027250001206994057\n",
      "epoch 56\n",
      "Batch 1000: Loss=3.5654714107513428; accuracy=0.2645625174045563\n",
      "Batch 2000: Loss=3.9508461952209473; accuracy=0.2501562535762787\n",
      "Validation accuracy: 0.026500001549720764\n",
      "epoch 57\n",
      "Batch 1000: Loss=2.821812868118286; accuracy=0.265500009059906\n",
      "Batch 2000: Loss=3.950666904449463; accuracy=0.2590000033378601\n",
      "Validation accuracy: 0.02575000189244747\n",
      "epoch 58\n",
      "Batch 1000: Loss=1.7535855770111084; accuracy=0.2826875150203705\n",
      "Batch 2000: Loss=2.5141303539276123; accuracy=0.27137500047683716\n",
      "Validation accuracy: 0.02825000137090683\n",
      "epoch 59\n",
      "Batch 1000: Loss=2.842402935028076; accuracy=0.28600001335144043\n",
      "Batch 2000: Loss=2.6096267700195312; accuracy=0.2782187759876251\n",
      "Validation accuracy: 0.02550000138580799\n",
      "epoch 60\n",
      "Batch 1000: Loss=2.7756412029266357; accuracy=0.29737502336502075\n",
      "Batch 2000: Loss=2.5631651878356934; accuracy=0.288875013589859\n",
      "Validation accuracy: 0.026000000536441803\n",
      "epoch 61\n",
      "Batch 1000: Loss=2.4734437465667725; accuracy=0.30525001883506775\n",
      "Batch 2000: Loss=2.165936231613159; accuracy=0.2970625162124634\n",
      "Validation accuracy: 0.026250001043081284\n",
      "epoch 62\n",
      "Batch 1000: Loss=2.5101587772369385; accuracy=0.31037500500679016\n",
      "Batch 2000: Loss=2.8585338592529297; accuracy=0.30028125643730164\n",
      "Validation accuracy: 0.027500001713633537\n",
      "epoch 63\n",
      "Batch 1000: Loss=2.1074609756469727; accuracy=0.3160000145435333\n",
      "Batch 2000: Loss=2.306748867034912; accuracy=0.30421876907348633\n",
      "Validation accuracy: 0.026500001549720764\n",
      "epoch 64\n",
      "Batch 1000: Loss=2.507633686065674; accuracy=0.3216875195503235\n",
      "Batch 2000: Loss=3.2127678394317627; accuracy=0.30806252360343933\n",
      "Validation accuracy: 0.02575000189244747\n",
      "epoch 65\n",
      "Batch 1000: Loss=2.265725612640381; accuracy=0.31725001335144043\n",
      "Batch 2000: Loss=3.2117748260498047; accuracy=0.3097187578678131\n",
      "Validation accuracy: 0.027500001713633537\n",
      "epoch 66\n",
      "Batch 1000: Loss=2.09020733833313; accuracy=0.3255000114440918\n",
      "Batch 2000: Loss=2.5841474533081055; accuracy=0.31415626406669617\n",
      "Validation accuracy: 0.02850000187754631\n",
      "epoch 67\n",
      "Batch 1000: Loss=2.500664472579956; accuracy=0.3215625286102295\n",
      "Batch 2000: Loss=2.5443742275238037; accuracy=0.3135312795639038\n",
      "Validation accuracy: 0.026250001043081284\n",
      "epoch 68\n",
      "Batch 1000: Loss=2.750943660736084; accuracy=0.33225002884864807\n",
      "Batch 2000: Loss=2.1055963039398193; accuracy=0.3176562786102295\n",
      "Validation accuracy: 0.02825000137090683\n",
      "epoch 69\n",
      "Batch 1000: Loss=1.9937314987182617; accuracy=0.33243751525878906\n",
      "Batch 2000: Loss=2.028801202774048; accuracy=0.3191875219345093\n",
      "Validation accuracy: 0.027000000700354576\n",
      "epoch 70\n",
      "Batch 1000: Loss=2.410536050796509; accuracy=0.33275002241134644\n",
      "Batch 2000: Loss=2.6678528785705566; accuracy=0.3204375207424164\n",
      "Validation accuracy: 0.02800000086426735\n",
      "epoch 71\n",
      "Batch 1000: Loss=2.485039710998535; accuracy=0.34275001287460327\n",
      "Batch 2000: Loss=1.9050166606903076; accuracy=0.32625001668930054\n",
      "Validation accuracy: 0.026250001043081284\n",
      "epoch 72\n",
      "Batch 1000: Loss=2.0249557495117188; accuracy=0.33412501215934753\n",
      "Batch 2000: Loss=2.805586814880371; accuracy=0.3238750100135803\n",
      "Validation accuracy: 0.026500001549720764\n",
      "epoch 73\n",
      "Batch 1000: Loss=3.0687670707702637; accuracy=0.3384375274181366\n",
      "Batch 2000: Loss=2.378033399581909; accuracy=0.3257812559604645\n",
      "Validation accuracy: 0.02575000189244747\n",
      "epoch 74\n",
      "Batch 1000: Loss=2.606621503829956; accuracy=0.34675002098083496\n",
      "Batch 2000: Loss=2.9022669792175293; accuracy=0.3292812705039978\n",
      "Validation accuracy: 0.024500001221895218\n",
      "epoch 75\n",
      "Batch 1000: Loss=3.3886191844940186; accuracy=0.3423125147819519\n",
      "Batch 2000: Loss=2.6183762550354004; accuracy=0.32862502336502075\n",
      "Validation accuracy: 0.02550000138580799\n",
      "epoch 76\n",
      "Batch 1000: Loss=2.8758139610290527; accuracy=0.34693750739097595\n",
      "Batch 2000: Loss=2.4927642345428467; accuracy=0.3309375047683716\n",
      "Validation accuracy: 0.026000000536441803\n",
      "epoch 77\n",
      "Batch 1000: Loss=2.0553338527679443; accuracy=0.34300002455711365\n",
      "Batch 2000: Loss=2.466294050216675; accuracy=0.33015626668930054\n",
      "Validation accuracy: 0.02575000189244747\n",
      "epoch 78\n",
      "Batch 1000: Loss=2.1068613529205322; accuracy=0.34412500262260437\n",
      "Batch 2000: Loss=2.3861875534057617; accuracy=0.33262500166893005\n",
      "Validation accuracy: 0.024500001221895218\n",
      "epoch 79\n",
      "Batch 1000: Loss=2.566757917404175; accuracy=0.3501250147819519\n",
      "Batch 2000: Loss=2.145801544189453; accuracy=0.33662500977516174\n",
      "Validation accuracy: 0.024500001221895218\n",
      "epoch 80\n",
      "Batch 1000: Loss=2.192782402038574; accuracy=0.35575002431869507\n",
      "Batch 2000: Loss=2.1961421966552734; accuracy=0.3410625159740448\n",
      "Validation accuracy: 0.02500000037252903\n",
      "epoch 81\n",
      "Batch 1000: Loss=2.1057090759277344; accuracy=0.35737502574920654\n",
      "Batch 2000: Loss=2.035985231399536; accuracy=0.34571877121925354\n",
      "Validation accuracy: 0.0247500017285347\n",
      "epoch 82\n",
      "Batch 1000: Loss=2.40097713470459; accuracy=0.3616875112056732\n",
      "Batch 2000: Loss=1.9575510025024414; accuracy=0.35081252455711365\n",
      "Validation accuracy: 0.024250000715255737\n",
      "epoch 83\n",
      "Batch 1000: Loss=1.5703725814819336; accuracy=0.3788750171661377\n",
      "Batch 2000: Loss=2.379373073577881; accuracy=0.36543750762939453\n",
      "Validation accuracy: 0.02525000087916851\n",
      "epoch 84\n",
      "Batch 1000: Loss=2.0520663261413574; accuracy=0.3921250104904175\n",
      "Batch 2000: Loss=2.443770408630371; accuracy=0.3817500174045563\n",
      "Validation accuracy: 0.026750002056360245\n",
      "epoch 85\n",
      "Batch 1000: Loss=3.1217525005340576; accuracy=0.40175002813339233\n",
      "Batch 2000: Loss=1.897271990776062; accuracy=0.37018752098083496\n",
      "Validation accuracy: 0.026000000536441803\n",
      "epoch 86\n",
      "Batch 1000: Loss=2.121497392654419; accuracy=0.4346250295639038\n",
      "Batch 2000: Loss=2.6342766284942627; accuracy=0.4425000250339508\n",
      "Validation accuracy: 0.023500001057982445\n",
      "epoch 87\n",
      "Batch 1000: Loss=1.8318978548049927; accuracy=0.5090625286102295\n",
      "Batch 2000: Loss=1.5039981603622437; accuracy=0.500656247138977\n",
      "Validation accuracy: 0.02850000187754631\n",
      "epoch 88\n",
      "Batch 1000: Loss=1.3913487195968628; accuracy=0.5551875233650208\n",
      "Batch 2000: Loss=1.4430936574935913; accuracy=0.5401250123977661\n",
      "Validation accuracy: 0.027250001206994057\n",
      "epoch 89\n",
      "Batch 1000: Loss=1.2705897092819214; accuracy=0.5762500166893005\n",
      "Batch 2000: Loss=1.2601773738861084; accuracy=0.5663750171661377\n",
      "Validation accuracy: 0.024250000715255737\n",
      "epoch 90\n",
      "Batch 1000: Loss=1.3275549411773682; accuracy=0.6046250462532043\n",
      "Batch 2000: Loss=2.069387197494507; accuracy=0.5790000557899475\n",
      "Validation accuracy: 0.026250001043081284\n",
      "epoch 91\n",
      "Batch 1000: Loss=1.8553632497787476; accuracy=0.6221875548362732\n",
      "Batch 2000: Loss=1.2900925874710083; accuracy=0.6008437871932983\n",
      "Validation accuracy: 0.030250001698732376\n",
      "epoch 92\n",
      "Batch 1000: Loss=1.390419602394104; accuracy=0.6305000185966492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2000: Loss=1.7979828119277954; accuracy=0.6000937819480896\n",
      "Validation accuracy: 0.029500002041459084\n",
      "epoch 93\n",
      "Batch 1000: Loss=1.581403374671936; accuracy=0.6298125386238098\n",
      "Batch 2000: Loss=1.6837737560272217; accuracy=0.6071875095367432\n",
      "Validation accuracy: 0.03100000135600567\n",
      "epoch 94\n",
      "Batch 1000: Loss=1.532840371131897; accuracy=0.6361875534057617\n",
      "Batch 2000: Loss=0.9621148109436035; accuracy=0.6163437962532043\n",
      "Validation accuracy: 0.024500001221895218\n",
      "epoch 95\n",
      "Batch 1000: Loss=1.4502562284469604; accuracy=0.635312557220459\n",
      "Batch 2000: Loss=0.8107191920280457; accuracy=0.6136875152587891\n",
      "Validation accuracy: 0.029750000685453415\n",
      "epoch 96\n",
      "Batch 1000: Loss=1.2584518194198608; accuracy=0.6483750343322754\n",
      "Batch 2000: Loss=1.524570107460022; accuracy=0.6280625462532043\n",
      "Validation accuracy: 0.02500000037252903\n",
      "epoch 97\n",
      "Batch 1000: Loss=1.462662696838379; accuracy=0.6506250500679016\n",
      "Batch 2000: Loss=0.8765491843223572; accuracy=0.6337187886238098\n",
      "Validation accuracy: 0.02500000037252903\n",
      "epoch 98\n",
      "Batch 1000: Loss=1.9157570600509644; accuracy=0.6583125591278076\n",
      "Batch 2000: Loss=1.5937732458114624; accuracy=0.6375312805175781\n",
      "Validation accuracy: 0.026750002056360245\n",
      "epoch 99\n",
      "Batch 1000: Loss=0.7997154593467712; accuracy=0.6488125324249268\n",
      "Batch 2000: Loss=1.592903971672058; accuracy=0.6339687705039978\n",
      "Validation accuracy: 0.030500002205371857\n",
      "epoch 100\n",
      "Batch 1000: Loss=1.8459258079528809; accuracy=0.6194375157356262\n",
      "Batch 2000: Loss=2.112316846847534; accuracy=0.6175625324249268\n",
      "Validation accuracy: 0.02850000187754631\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'test'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m opt\u001b[38;5;241m.\u001b[39mkind\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom-scratch\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m----> 2\u001b[0m     loss_history, accuracy_val, accuracy_test, counts_val, counts_test \u001b[38;5;241m=\u001b[39m \u001b[43mnet_trainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m            \u001b[49m\u001b[43mloaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m            \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m            \u001b[49m\u001b[43mchannel_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnonclasses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/GithubClonedRepo/EEG-Research/Experiment/EEG_Encoder/net_trainer.py:138\u001b[0m, in \u001b[0;36mnet_trainer\u001b[0;34m(net, loaders, opt, channel_idx, nonclasses, pretrain, train, save)\u001b[0m\n\u001b[1;32m    132\u001b[0m     val_accuracy \u001b[38;5;241m=\u001b[39m (corrects[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m/\u001b[39mcounts[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m    133\u001b[0m     test_accuracy \u001b[38;5;241m=\u001b[39m (corrects[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m/\u001b[39mcounts[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (loss_history, \n\u001b[1;32m    135\u001b[0m         val_accuracy,\n\u001b[1;32m    136\u001b[0m         test_accuracy,\n\u001b[1;32m    137\u001b[0m         \u001b[38;5;28mint\u001b[39m(counts[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m]),\n\u001b[0;32m--> 138\u001b[0m         \u001b[38;5;28mint\u001b[39m(\u001b[43mcounts\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m))\n",
      "\u001b[0;31mKeyError\u001b[0m: 'test'"
     ]
    }
   ],
   "source": [
    "if opt.kind==\"from-scratch\":\n",
    "    loss_history, accuracy_val, accuracy_test = net_trainer(\n",
    "            net,\n",
    "            loaders,\n",
    "            opt,\n",
    "            channel_idx,\n",
    "            nonclasses,\n",
    "            None,\n",
    "            True,\n",
    "            model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "52ac79d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy:  0.02525000087916851\n",
      "Test accuracy:  0.026000000536441803\n",
      "Accuracy:  0.025625000707805157\n",
      "Samples:  8000\n"
     ]
    }
   ],
   "source": [
    "val =accuracy_val\n",
    "test = accuracy_test\n",
    "\n",
    "print(\"Validation accuracy: \", val)\n",
    "print(\"Test accuracy: \", test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0931fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfe0373",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c3beab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab45327",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2179d69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ed6c4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2060d560",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb54c13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6467f813",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d16c15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45955f5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52331151",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca94e7f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfe619b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a58f0c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8236ccbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44249203",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f168b18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edd8a18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63556efb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6b09c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9eb88b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
