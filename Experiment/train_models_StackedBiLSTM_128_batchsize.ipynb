{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad0189f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from analysis import *\n",
    "import argparse\n",
    "from sys import platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bdf82d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(12)\n",
    "torch.cuda.manual_seed(12)\n",
    "np.random.seed(12)\n",
    "torch.backends.cudnn.deterministics = True\n",
    "torch.set_num_threads(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5209e6e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "0\n",
      "<torch.cuda.device object at 0x7f9c441e1a30>\n",
      "NVIDIA TITAN V\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.current_device())\n",
    "\n",
    "print(torch.cuda.device(0))\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "409beaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iv: image option\n",
    "length = 512\n",
    "channel = 96\n",
    "min_CNN = 200\n",
    "n_classes = 40\n",
    "classes = range(n_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e9a4177",
   "metadata": {},
   "outputs": [],
   "source": [
    "if platform == \"linux\" or platform == \"linux2\":\n",
    "    torch_models_dir = r\"/media/titan/AI Research/Data/CVPR2021-02785/CVPR2021-02785/preprocessed/torch_models\"\n",
    "elif platform == \"win32\":\n",
    "    torch_models_dir = r\"D:\\Data\\CVPR2021-02785\\CVPR2021-02785\\preprocessed\\torch_models\"\n",
    "eeg_dataset, splits_path, splits_60, splits_shuffled_path = os.listdir(torch_models_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0eb48a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/titan/AI Research/Data/CVPR2021-02785/CVPR2021-02785/preprocessed/torch_models/imagenet40-1000-1.pth \n",
      " /media/titan/AI Research/Data/CVPR2021-02785/CVPR2021-02785/preprocessed/torch_models/imagenet40-1000-1_splits.pth\n"
     ]
    }
   ],
   "source": [
    "eeg_dataset = os.path.join(torch_models_dir, eeg_dataset)\n",
    "splits_path = os.path.join(torch_models_dir, splits_path)\n",
    "# splits_path = os.path.join(torch_models_dir, splits_shuffled_path)\n",
    "print(eeg_dataset,'\\n', splits_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e5ba93a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image\n"
     ]
    }
   ],
   "source": [
    "opt = {\n",
    "    # Dataset options\n",
    "    \"iv\": \"image\",\n",
    "    \"offset\": None,\n",
    "    \"results_file\": \"results.pkl\",\n",
    "    \"subject\": 0,\n",
    "    \"run\": \"none\",\n",
    "    \"eeg_dataset\": eeg_dataset,\n",
    "    \"splits_path\": splits_path,\n",
    "    \"fold\": 5,\n",
    "    #Training options\n",
    "    \"batch_size\": 128, #change batch size from 16 to 128\n",
    "    \"optim\": \"Adam\",\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"learning_rate_decay_by\": 0.5,\n",
    "    \"learning_rate_decay_every\": 10,\n",
    "    \"epochs\": 100,\n",
    "    \"GPUindex\": 0,\n",
    "    \"kind\":\"incremental\",\n",
    "    #Backend options\n",
    "    \"no_cuda\": False,\n",
    "    \"classifier\": None\n",
    "}\n",
    "opt = argparse.Namespace(**opt)\n",
    "print(opt.iv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0bdbaca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from torch.utils.data import DataLoader\n",
    "from data_loader import EEGDataset, Splitter, SplitterWithData\n",
    "from EEG_Encoder.LSTM import classifier_LSTM\n",
    "from EEG_Encoder.CNN import classifier_CNN\n",
    "from EEG_Encoder.EEGNet import classifier_EEGNet\n",
    "from EEG_Encoder.SyncNet import classifier_SyncNet\n",
    "from EEG_Encoder.EEGChannelNet import classifier_EEGChannelNet\n",
    "from EEG_Encoder.net_generator import Classifier\n",
    "from EEG_Encoder.net_trainer import net_trainer\n",
    "from p_values import *\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b760c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(iv,\n",
    "             offset,\n",
    "             eeg_dataset,\n",
    "             splits_path,\n",
    "             split_num, # (0-4) - 5 fold cross validation\n",
    "             total,\n",
    "             classes,\n",
    "             classifier,\n",
    "             batch_size,\n",
    "             GPUindex,\n",
    "             length, # 512\n",
    "             channel, # 96\n",
    "             min_CNN,\n",
    "             opt,\n",
    "             kind):        \n",
    "    # Load dataset\n",
    "    dataset = EEGDataset(iv, eeg_dataset, classifier, map_idx = None)\n",
    "    print(\"DONE: LOAD DATASET\")\n",
    "    # Create loaders for LSTM/MLP/CNN/SCNN/EEGNet/SyncNet/EEGChannelNet\n",
    "    if kind==\"from-scratch\":\n",
    "        relabel = False\n",
    "    if kind==\"incremental\":\n",
    "        relabel = False\n",
    "    if kind==\"no-model-file\":\n",
    "        relabel = True\n",
    "    splitter = {split: SplitterWithData(iv,\n",
    "                    dataset,\n",
    "                    splits_path,\n",
    "                    classes,\n",
    "                    split_num,\n",
    "                    split,\n",
    "                    relabel) for split in [\"train\", \"val\", \"test\"]}\n",
    "    loaders = {split: DataLoader(\n",
    "                        splitter[split],\n",
    "                        batch_size = batch_size,\n",
    "                        drop_last = False,\n",
    "                        shuffle = True)\n",
    "                    for split in [\"train\", \"val\", \"test\"]}\n",
    "    channel_idx = None    \n",
    "    print(\"DONE: Create loaders for model\")            \n",
    "    return dataset, loaders, splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "660e8b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacked BiLSTM network\n",
    "opt.classifier = \"Stacked_BiLSTM\"\n",
    "opt.batch_size = 128 # change batch size from 16 to 128\n",
    "opt.kind = \"from-scratch\"\n",
    "opt.run = \"imagenet40-1000\"\n",
    "opt.fold = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55857ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE: LOAD DATASET\n",
      "DONE: Create loaders for model\n"
     ]
    }
   ],
   "source": [
    "dataset, loaders, splitter = load_dataset(opt.iv,\n",
    "                             opt.offset,\n",
    "                             opt.eeg_dataset,\n",
    "                             opt.splits_path,\n",
    "                             0, #split_num\n",
    "                             n_classes,\n",
    "                             classes,\n",
    "                             opt.classifier,\n",
    "                             opt.batch_size,\n",
    "                             opt.GPUindex,\n",
    "                             length,\n",
    "                             channel,\n",
    "                             min_CNN,\n",
    "                             opt,\n",
    "                             opt.kind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6731bcae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'data_loader.EEGDataset'>\n",
      "<class 'dict'>\n",
      "3 [250, 32, 32]\n",
      "1: Label val: 0; label train: 0\n",
      "2: Label val: 17; label train: 17\n",
      "3: Label val: 28; label train: 28\n",
      "4: Label val: 7; label train: 7\n",
      "5: Label val: 33; label train: 33\n",
      "6: Label val: 12; label train: 12\n",
      "7: Label val: 21; label train: 21\n",
      "8: Label val: 3; label train: 3\n",
      "9: Label val: 25; label train: 25\n",
      "10: Label val: 36; label train: 36\n",
      "11: Label val: 10; label train: 10\n",
      "12: Label val: 15; label train: 15\n",
      "13: Label val: 19; label train: 19\n",
      "14: Label val: 31; label train: 31\n",
      "15: Label val: 23; label train: 23\n",
      "16: Label val: 5; label train: 5\n",
      "17: Label val: 38; label train: 38\n",
      "18: Label val: 8; label train: 8\n",
      "19: Label val: 1; label train: 1\n",
      "20: Label val: 34; label train: 34\n",
      "21: Label val: 29; label train: 29\n",
      "22: Label val: 26; label train: 26\n",
      "23: Label val: 13; label train: 13\n",
      "24: Label val: 11; label train: 11\n",
      "25: Label val: 22; label train: 22\n",
      "26: Label val: 18; label train: 18\n",
      "27: Label val: 6; label train: 6\n",
      "28: Label val: 16; label train: 16\n",
      "29: Label val: 4; label train: 4\n",
      "30: Label val: 20; label train: 20\n",
      "31: Label val: 32; label train: 32\n",
      "32: Label val: 9; label train: 9\n",
      "33: Label val: 37; label train: 37\n",
      "34: Label val: 24; label train: 24\n",
      "35: Label val: 39; label train: 39\n",
      "36: Label val: 2; label train: 2\n",
      "37: Label val: 35; label train: 35\n",
      "38: Label val: 30; label train: 30\n",
      "39: Label val: 27; label train: 27\n",
      "40: Label val: 14; label train: 14\n"
     ]
    }
   ],
   "source": [
    "# loaders: divide the splits data in each fold with batch_size\n",
    "# Each fold has {train: 32000 idx, val: 4000 idx, test: 4000 idx}\n",
    "# Each loader batch has {train: 2000 idx, val: 250idx, test: 250 idx}\n",
    "print(type(dataset))\n",
    "print(type(loaders))\n",
    "print(len(loaders), [len(loaders[name]) for name in [\"train\", \"val\", \"test\"] ])\n",
    "for i in range(0, 40):\n",
    "    eeg, label_val = splitter[\"val\"][i*100]\n",
    "    eeg, label_train = splitter[\"train\"][i*800]\n",
    "    print(f\"{i+1}: Label val: {label_val}; label train: {label_train}\")\n",
    "# print(splitter[\"val\"].split_idx[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9ed072b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE: CREATE TORCH CLASSIFIER\n",
      "classifier_Stacked_BiLSTM(\n",
      "  (stacked_bilstm): LSTM(96, 128, num_layers=4, batch_first=True, bidirectional=True)\n",
      "  (output1): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (output2): Linear(in_features=128, out_features=40, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "classifier_Stacked_BiLSTM                [1, 40]                   --\n",
       "├─LSTM: 1-1                              [1, 512, 256]             1,417,216\n",
       "├─Linear: 1-2                            [1, 128]                  32,896\n",
       "├─ReLU: 1-3                              [1, 128]                  --\n",
       "├─Linear: 1-4                            [1, 40]                   5,160\n",
       "==========================================================================================\n",
       "Total params: 1,455,272\n",
       "Trainable params: 1,455,272\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 725.65\n",
       "==========================================================================================\n",
       "Input size (MB): 0.20\n",
       "Forward/backward pass size (MB): 1.05\n",
       "Params size (MB): 5.82\n",
       "Estimated Total Size (MB): 7.07\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net, nonclasses = Classifier(\n",
    "                 n_classes,\n",
    "                 classes,\n",
    "                 opt.classifier,\n",
    "                 opt.GPUindex,\n",
    "                 length,\n",
    "                 channel,\n",
    "                 min_CNN,\n",
    "                 opt.kind)\n",
    "# print(len(nonclasses))\n",
    "summary(net, input_size=(1,96, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0745b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image-Stacked_BiLSTM-512-96-0-batchsize_128\n"
     ]
    }
   ],
   "source": [
    "model_path = (opt.iv+\n",
    "                  \"-\"+\n",
    "                  opt.classifier+\n",
    "                  \"-\"+\n",
    "                  str(length)+\n",
    "                  \"-\"+\n",
    "                  str(channel)+\n",
    "                  \"-\"+\n",
    "                  str(0)) + \"-batchsize_128\"\n",
    "                  \n",
    "channel_idx=None\n",
    "print(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "43a7ccdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(iv='image', offset=None, results_file='results.pkl', subject=0, run='imagenet40-1000', eeg_dataset='/media/titan/AI Research/Data/CVPR2021-02785/CVPR2021-02785/preprocessed/torch_models/imagenet40-1000-1.pth', splits_path='/media/titan/AI Research/Data/CVPR2021-02785/CVPR2021-02785/preprocessed/torch_models/imagenet40-1000-1_splits.pth', fold=5, batch_size=128, optim='Adam', learning_rate=0.001, learning_rate_decay_by=0.5, learning_rate_decay_every=10, epochs=100, GPUindex=0, kind='from-scratch', no_cuda=False, classifier='Stacked_BiLSTM')\n"
     ]
    }
   ],
   "source": [
    "print(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "087e1b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=3.691070556640625; accuracy=0.025624999776482582\n",
      "Batch 200: Loss=3.6891801357269287; accuracy=0.025273436680436134\n",
      "Validation accuracy: 0.024250000715255737\n",
      "epoch 2\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=3.6926348209381104; accuracy=0.027109375223517418\n",
      "Batch 200: Loss=3.6937155723571777; accuracy=0.026679687201976776\n",
      "Validation accuracy: 0.026750002056360245\n",
      "epoch 3\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=3.681079626083374; accuracy=0.029921874403953552\n",
      "Batch 200: Loss=3.6818535327911377; accuracy=0.02812499925494194\n",
      "Validation accuracy: 0.026750002056360245\n",
      "epoch 4\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=3.698911428451538; accuracy=0.02812499925494194\n",
      "Batch 200: Loss=3.6888837814331055; accuracy=0.02632812410593033\n",
      "Validation accuracy: 0.023250000551342964\n",
      "epoch 5\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=3.671428680419922; accuracy=0.029453124850988388\n",
      "Batch 200: Loss=3.684767961502075; accuracy=0.027812499552965164\n",
      "Validation accuracy: 0.024250000715255737\n",
      "epoch 6\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=3.6868066787719727; accuracy=0.0286718737334013\n",
      "Batch 200: Loss=3.6811606884002686; accuracy=0.029726561158895493\n",
      "Validation accuracy: 0.027000000700354576\n",
      "epoch 7\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=3.680093765258789; accuracy=0.03125\n",
      "Batch 200: Loss=3.67246150970459; accuracy=0.029765624552965164\n",
      "Validation accuracy: 0.02250000089406967\n",
      "epoch 8\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=3.6939940452575684; accuracy=0.033671874552965164\n",
      "Batch 200: Loss=3.6640472412109375; accuracy=0.03378906100988388\n",
      "Validation accuracy: 0.0247500017285347\n",
      "epoch 9\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=3.580742597579956; accuracy=0.03648437559604645\n",
      "Batch 200: Loss=3.624027967453003; accuracy=0.03656249865889549\n",
      "Validation accuracy: 0.030500002205371857\n",
      "epoch 10\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=3.6284356117248535; accuracy=0.04257812350988388\n",
      "Batch 200: Loss=3.627173662185669; accuracy=0.04046874865889549\n",
      "Validation accuracy: 0.026000000536441803\n",
      "epoch 11\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=3.6713359355926514; accuracy=0.04726562276482582\n",
      "Batch 200: Loss=3.6404099464416504; accuracy=0.04574218764901161\n",
      "Validation accuracy: 0.0247500017285347\n",
      "epoch 12\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=3.4976134300231934; accuracy=0.053984373807907104\n",
      "Batch 200: Loss=3.575658082962036; accuracy=0.053828123956918716\n",
      "Validation accuracy: 0.021250000223517418\n",
      "epoch 13\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=3.468553304672241; accuracy=0.06335937231779099\n",
      "Batch 200: Loss=3.421893358230591; accuracy=0.06234375014901161\n",
      "Validation accuracy: 0.02850000187754631\n",
      "epoch 14\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=3.5491554737091064; accuracy=0.07593749463558197\n",
      "Batch 200: Loss=3.432640552520752; accuracy=0.07507812231779099\n",
      "Validation accuracy: 0.0247500017285347\n",
      "epoch 15\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=3.3486337661743164; accuracy=0.09273437410593033\n",
      "Batch 200: Loss=3.453059196472168; accuracy=0.09269531071186066\n",
      "Validation accuracy: 0.027250001206994057\n",
      "epoch 16\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=3.2462360858917236; accuracy=0.11562499403953552\n",
      "Batch 200: Loss=3.353987216949463; accuracy=0.11011718213558197\n",
      "Validation accuracy: 0.026250001043081284\n",
      "epoch 17\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=3.290811777114868; accuracy=0.13710936903953552\n",
      "Batch 200: Loss=3.138946294784546; accuracy=0.1319921910762787\n",
      "Validation accuracy: 0.027500001713633537\n",
      "epoch 18\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=2.957231283187866; accuracy=0.1672656238079071\n",
      "Batch 200: Loss=3.03580641746521; accuracy=0.1615625023841858\n",
      "Validation accuracy: 0.0247500017285347\n",
      "epoch 19\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=2.832498073577881; accuracy=0.19703124463558197\n",
      "Batch 200: Loss=2.8704025745391846; accuracy=0.19566406309604645\n",
      "Validation accuracy: 0.023750001564621925\n",
      "epoch 20\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=2.7950732707977295; accuracy=0.2331250011920929\n",
      "Batch 200: Loss=2.8906638622283936; accuracy=0.22371093928813934\n",
      "Validation accuracy: 0.02525000087916851\n",
      "epoch 21\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=2.285158157348633; accuracy=0.26851561665534973\n",
      "Batch 200: Loss=2.712808847427368; accuracy=0.26292967796325684\n",
      "Validation accuracy: 0.027000000700354576\n",
      "epoch 22\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=2.523391008377075; accuracy=0.3071874976158142\n",
      "Batch 200: Loss=2.577300786972046; accuracy=0.3003906309604645\n",
      "Validation accuracy: 0.024250000715255737\n",
      "epoch 23\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=2.4207868576049805; accuracy=0.34882810711860657\n",
      "Batch 200: Loss=2.5839052200317383; accuracy=0.3370312452316284\n",
      "Validation accuracy: 0.023500001057982445\n",
      "epoch 24\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=2.000650405883789; accuracy=0.3892187476158142\n",
      "Batch 200: Loss=2.1597867012023926; accuracy=0.37621092796325684\n",
      "Validation accuracy: 0.02550000138580799\n",
      "epoch 25\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=2.0542612075805664; accuracy=0.4203124940395355\n",
      "Batch 200: Loss=2.140531063079834; accuracy=0.4121484160423279\n",
      "Validation accuracy: 0.02200000174343586\n",
      "epoch 26\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=1.9082804918289185; accuracy=0.455078125\n",
      "Batch 200: Loss=1.8829677104949951; accuracy=0.44636717438697815\n",
      "Validation accuracy: 0.02550000138580799\n",
      "epoch 27\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=1.7522045373916626; accuracy=0.49070310592651367\n",
      "Batch 200: Loss=1.7635982036590576; accuracy=0.47691404819488525\n",
      "Validation accuracy: 0.02500000037252903\n",
      "epoch 28\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=1.7232179641723633; accuracy=0.5254687666893005\n",
      "Batch 200: Loss=1.8887805938720703; accuracy=0.5139843821525574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.024250000715255737\n",
      "epoch 29\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=1.2758233547210693; accuracy=0.5600780844688416\n",
      "Batch 200: Loss=1.3522653579711914; accuracy=0.5475780963897705\n",
      "Validation accuracy: 0.024000000208616257\n",
      "epoch 30\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=1.4837334156036377; accuracy=0.5702343583106995\n",
      "Batch 200: Loss=1.4488565921783447; accuracy=0.5702343583106995\n",
      "Validation accuracy: 0.02525000087916851\n",
      "epoch 31\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=1.3108755350112915; accuracy=0.6219531297683716\n",
      "Batch 200: Loss=1.3154041767120361; accuracy=0.6087109446525574\n",
      "Validation accuracy: 0.02800000086426735\n",
      "epoch 32\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=1.2781544923782349; accuracy=0.6282030940055847\n",
      "Batch 200: Loss=1.3876137733459473; accuracy=0.6246093511581421\n",
      "Validation accuracy: 0.02500000037252903\n",
      "epoch 33\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=1.0794416666030884; accuracy=0.6659374833106995\n",
      "Batch 200: Loss=1.2635544538497925; accuracy=0.6487109065055847\n",
      "Validation accuracy: 0.030750000849366188\n",
      "epoch 34\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=0.9048065543174744; accuracy=0.6832031011581421\n",
      "Batch 200: Loss=0.9378194212913513; accuracy=0.679492175579071\n",
      "Validation accuracy: 0.024000000208616257\n",
      "epoch 35\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=0.9192992448806763; accuracy=0.702343761920929\n",
      "Batch 200: Loss=1.034065842628479; accuracy=0.6961327791213989\n",
      "Validation accuracy: 0.027750002220273018\n",
      "epoch 36\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=0.8625187873840332; accuracy=0.7274999618530273\n",
      "Batch 200: Loss=1.1865639686584473; accuracy=0.7165625095367432\n",
      "Validation accuracy: 0.027250001206994057\n",
      "epoch 37\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=0.9953777194023132; accuracy=0.7412499785423279\n",
      "Batch 200: Loss=1.0109833478927612; accuracy=0.7338281273841858\n",
      "Validation accuracy: 0.027250001206994057\n",
      "epoch 38\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=0.8268263936042786; accuracy=0.751171886920929\n",
      "Batch 200: Loss=0.8348345756530762; accuracy=0.74867182970047\n",
      "Validation accuracy: 0.02525000087916851\n",
      "epoch 39\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=0.7833400964736938; accuracy=0.7786718606948853\n",
      "Batch 200: Loss=0.8464362025260925; accuracy=0.7663280963897705\n",
      "Validation accuracy: 0.030500002205371857\n",
      "epoch 40\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=0.6489124894142151; accuracy=0.7876562476158142\n",
      "Batch 200: Loss=0.8319225311279297; accuracy=0.7776562571525574\n",
      "Validation accuracy: 0.023500001057982445\n",
      "epoch 41\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=0.5295175909996033; accuracy=0.7923437356948853\n",
      "Batch 200: Loss=0.6302425265312195; accuracy=0.7880468368530273\n",
      "Validation accuracy: 0.026750002056360245\n",
      "epoch 42\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=0.7071952223777771; accuracy=0.8149999976158142\n",
      "Batch 200: Loss=0.8595072627067566; accuracy=0.8056249618530273\n",
      "Validation accuracy: 0.02800000086426735\n",
      "epoch 43\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=0.5172359943389893; accuracy=0.8178125023841858\n",
      "Batch 200: Loss=0.6245154142379761; accuracy=0.8151953220367432\n",
      "Validation accuracy: 0.024250000715255737\n",
      "epoch 44\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=0.592290997505188; accuracy=0.8278124928474426\n",
      "Batch 200: Loss=0.49987342953681946; accuracy=0.8219531178474426\n",
      "Validation accuracy: 0.02525000087916851\n",
      "epoch 45\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=0.5318782925605774; accuracy=0.8453906178474426\n",
      "Batch 200: Loss=0.5050980448722839; accuracy=0.8326953053474426\n",
      "Validation accuracy: 0.022750001400709152\n",
      "epoch 46\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=0.4785156846046448; accuracy=0.8389062285423279\n",
      "Batch 200: Loss=0.40393006801605225; accuracy=0.8378515243530273\n",
      "Validation accuracy: 0.029000001028180122\n",
      "epoch 47\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=0.7293151617050171; accuracy=0.8526562452316284\n",
      "Batch 200: Loss=0.5200896859169006; accuracy=0.8474999666213989\n",
      "Validation accuracy: 0.024250000715255737\n",
      "epoch 48\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=0.5636219382286072; accuracy=0.8627343773841858\n",
      "Batch 200: Loss=0.5121277570724487; accuracy=0.8523827791213989\n",
      "Validation accuracy: 0.02525000087916851\n",
      "epoch 49\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=0.31505540013313293; accuracy=0.8625780940055847\n",
      "Batch 200: Loss=0.6162731051445007; accuracy=0.8604687452316284\n",
      "Validation accuracy: 0.02800000086426735\n",
      "epoch 50\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=0.30138835310935974; accuracy=0.8792187571525574\n",
      "Batch 200: Loss=0.4714429974555969; accuracy=0.87074214220047\n",
      "Validation accuracy: 0.030750000849366188\n",
      "epoch 51\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=0.5915216207504272; accuracy=0.879687488079071\n",
      "Batch 200: Loss=0.3977231979370117; accuracy=0.8788671493530273\n",
      "Validation accuracy: 0.027500001713633537\n",
      "epoch 52\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=0.49857577681541443; accuracy=0.8825781345367432\n",
      "Batch 200: Loss=0.4306664764881134; accuracy=0.8728125095367432\n",
      "Validation accuracy: 0.027000000700354576\n",
      "epoch 53\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=0.37285059690475464; accuracy=0.8913280963897705\n",
      "Batch 200: Loss=0.4595057964324951; accuracy=0.8782421946525574\n",
      "Validation accuracy: 0.02500000037252903\n",
      "epoch 54\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=0.30448290705680847; accuracy=0.8838281035423279\n",
      "Batch 200: Loss=0.389425665140152; accuracy=0.8784765601158142\n",
      "Validation accuracy: 0.02500000037252903\n",
      "epoch 55\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=0.3082192540168762; accuracy=0.8985937237739563\n",
      "Batch 200: Loss=0.3114608824253082; accuracy=0.8930078148841858\n",
      "Validation accuracy: 0.027000000700354576\n",
      "epoch 56\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=0.30290958285331726; accuracy=0.8952343463897705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 200: Loss=0.2763209044933319; accuracy=0.8930078148841858\n",
      "Validation accuracy: 0.02550000138580799\n",
      "epoch 57\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=0.37799519300460815; accuracy=0.89453125\n",
      "Batch 200: Loss=0.4284789264202118; accuracy=0.89124995470047\n",
      "Validation accuracy: 0.02550000138580799\n",
      "epoch 58\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=0.3315412998199463; accuracy=0.9056249856948853\n",
      "Batch 200: Loss=0.4709083139896393; accuracy=0.8986718654632568\n",
      "Validation accuracy: 0.02850000187754631\n",
      "epoch 59\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=0.25665083527565; accuracy=0.9154687523841858\n",
      "Batch 200: Loss=0.441143661737442; accuracy=0.9080859422683716\n",
      "Validation accuracy: 0.026500001549720764\n",
      "epoch 60\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=0.2970258593559265; accuracy=0.9095312356948853\n",
      "Batch 200: Loss=0.5378419756889343; accuracy=0.8994531035423279\n",
      "Validation accuracy: 0.024500001221895218\n",
      "epoch 61\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=0.3382796049118042; accuracy=0.9046093821525574\n",
      "Batch 200: Loss=0.5901733636856079; accuracy=0.9014452695846558\n",
      "Validation accuracy: 0.027000000700354576\n",
      "epoch 62\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=0.21712380647659302; accuracy=0.9171093702316284\n",
      "Batch 200: Loss=0.2126007378101349; accuracy=0.9132812023162842\n",
      "Validation accuracy: 0.026750002056360245\n",
      "epoch 63\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=0.2644839882850647; accuracy=0.92445307970047\n",
      "Batch 200: Loss=0.28065288066864014; accuracy=0.9178124666213989\n",
      "Validation accuracy: 0.02525000087916851\n",
      "epoch 64\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=0.3727659285068512; accuracy=0.9125781059265137\n",
      "Batch 200: Loss=0.22143436968326569; accuracy=0.9091405868530273\n",
      "Validation accuracy: 0.026250001043081284\n",
      "epoch 65\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=0.20909541845321655; accuracy=0.91468745470047\n",
      "Batch 200: Loss=0.33796629309654236; accuracy=0.9077343344688416\n",
      "Validation accuracy: 0.02850000187754631\n",
      "epoch 66\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=0.32968032360076904; accuracy=0.908203125\n",
      "Batch 200: Loss=0.20304608345031738; accuracy=0.9042187333106995\n",
      "Validation accuracy: 0.02575000189244747\n",
      "epoch 67\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=0.2257782518863678; accuracy=0.9239843487739563\n",
      "Batch 200: Loss=0.3406985104084015; accuracy=0.9185546636581421\n",
      "Validation accuracy: 0.024500001221895218\n",
      "epoch 68\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=0.20760291814804077; accuracy=0.9249218702316284\n",
      "Batch 200: Loss=0.35684069991111755; accuracy=0.9233593344688416\n",
      "Validation accuracy: 0.02575000189244747\n",
      "epoch 69\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=0.44163113832473755; accuracy=0.9253906011581421\n",
      "Batch 200: Loss=0.44918292760849; accuracy=0.9214453101158142\n",
      "Validation accuracy: 0.027250001206994057\n",
      "epoch 70\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=0.2691603899002075; accuracy=0.9208593368530273\n",
      "Batch 200: Loss=0.3106149435043335; accuracy=0.9171484112739563\n",
      "Validation accuracy: 0.0247500017285347\n",
      "epoch 71\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=0.2077980488538742; accuracy=0.9151562452316284\n",
      "Batch 200: Loss=0.34100010991096497; accuracy=0.9189453125\n",
      "Validation accuracy: 0.024500001221895218\n",
      "epoch 72\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=0.23297734558582306; accuracy=0.9333593249320984\n",
      "Batch 200: Loss=0.3040596544742584; accuracy=0.9271875023841858\n",
      "Validation accuracy: 0.026500001549720764\n",
      "epoch 73\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=0.3581508994102478; accuracy=0.9267968535423279\n",
      "Batch 200: Loss=0.15172706544399261; accuracy=0.9266796708106995\n",
      "Validation accuracy: 0.027000000700354576\n",
      "epoch 74\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=0.22005096077919006; accuracy=0.9302343726158142\n",
      "Batch 200: Loss=0.3535182774066925; accuracy=0.9264453053474426\n",
      "Validation accuracy: 0.026000000536441803\n",
      "epoch 75\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=0.38649222254753113; accuracy=0.9271093606948853\n",
      "Batch 200: Loss=0.1752375215291977; accuracy=0.9260937571525574\n",
      "Validation accuracy: 0.023000001907348633\n",
      "epoch 76\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=0.28611522912979126; accuracy=0.9254687428474426\n",
      "Batch 200: Loss=0.3429475724697113; accuracy=0.921679675579071\n",
      "Validation accuracy: 0.026500001549720764\n",
      "epoch 77\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=0.3079705834388733; accuracy=0.9300000071525574\n",
      "Batch 200: Loss=0.2085091918706894; accuracy=0.9208202958106995\n",
      "Validation accuracy: 0.026500001549720764\n",
      "epoch 78\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=0.38502222299575806; accuracy=0.9317187070846558\n",
      "Batch 200: Loss=0.19149643182754517; accuracy=0.9273437261581421\n",
      "Validation accuracy: 0.02525000087916851\n",
      "epoch 79\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=0.22889485955238342; accuracy=0.9325000047683716\n",
      "Batch 200: Loss=0.23574933409690857; accuracy=0.9301952719688416\n",
      "Validation accuracy: 0.028750000521540642\n",
      "epoch 80\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=0.2122388780117035; accuracy=0.9337499737739563\n",
      "Batch 200: Loss=0.19122537970542908; accuracy=0.9333202838897705\n",
      "Validation accuracy: 0.029000001028180122\n",
      "epoch 81\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=0.14806590974330902; accuracy=0.9359374642372131\n",
      "Batch 200: Loss=0.22815647721290588; accuracy=0.9343358874320984\n",
      "Validation accuracy: 0.029750000685453415\n",
      "epoch 82\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=0.33291390538215637; accuracy=0.9451562166213989\n",
      "Batch 200: Loss=0.24618421494960785; accuracy=0.9439452886581421\n",
      "Validation accuracy: 0.029500002041459084\n",
      "epoch 83\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=0.28574299812316895; accuracy=0.9325000047683716\n",
      "Batch 200: Loss=0.2474696934223175; accuracy=0.9252734184265137\n",
      "Validation accuracy: 0.029500002041459084\n",
      "epoch 84\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 100: Loss=0.16077712178230286; accuracy=0.9222655892372131\n",
      "Batch 200: Loss=0.33668431639671326; accuracy=0.9206249713897705\n",
      "Validation accuracy: 0.030750000849366188\n",
      "epoch 85\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=0.22672297060489655; accuracy=0.9313281178474426\n",
      "Batch 200: Loss=0.3294481337070465; accuracy=0.9296483993530273\n",
      "Validation accuracy: 0.02575000189244747\n",
      "epoch 86\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=0.15627188980579376; accuracy=0.9307812452316284\n",
      "Batch 200: Loss=0.1843087077140808; accuracy=0.9342578053474426\n",
      "Validation accuracy: 0.027250001206994057\n",
      "epoch 87\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=0.15738339722156525; accuracy=0.943359375\n",
      "Batch 200: Loss=0.21475546061992645; accuracy=0.9396874904632568\n",
      "Validation accuracy: 0.027250001206994057\n",
      "epoch 88\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=0.19563470780849457; accuracy=0.9386718273162842\n",
      "Batch 200: Loss=0.24261049926280975; accuracy=0.9385546445846558\n",
      "Validation accuracy: 0.027250001206994057\n",
      "epoch 89\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=0.18537777662277222; accuracy=0.9446093440055847\n",
      "Batch 200: Loss=0.2545302212238312; accuracy=0.93910151720047\n",
      "Validation accuracy: 0.02800000086426735\n",
      "epoch 90\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=0.18435996770858765; accuracy=0.9416406154632568\n",
      "Batch 200: Loss=0.19160199165344238; accuracy=0.93910151720047\n",
      "Validation accuracy: 0.027250001206994057\n",
      "epoch 91\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=0.2681562304496765; accuracy=0.9425780773162842\n",
      "Batch 200: Loss=0.23431332409381866; accuracy=0.9375\n",
      "Validation accuracy: 0.030250001698732376\n",
      "epoch 92\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=0.14066578447818756; accuracy=0.93031245470047\n",
      "Batch 200: Loss=0.254495769739151; accuracy=0.9264453053474426\n",
      "Validation accuracy: 0.027750002220273018\n",
      "epoch 93\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=0.25192365050315857; accuracy=0.9378905892372131\n",
      "Batch 200: Loss=0.3038531243801117; accuracy=0.93226557970047\n",
      "Validation accuracy: 0.026250001043081284\n",
      "epoch 94\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=0.23196882009506226; accuracy=0.9339062571525574\n",
      "Batch 200: Loss=0.1900835484266281; accuracy=0.935351550579071\n",
      "Validation accuracy: 0.030250001698732376\n",
      "epoch 95\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=0.203545480966568; accuracy=0.9452343583106995\n",
      "Batch 200: Loss=0.21761079132556915; accuracy=0.9410156011581421\n",
      "Validation accuracy: 0.026000000536441803\n",
      "epoch 96\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=0.16251669824123383; accuracy=0.9432030916213989\n",
      "Batch 200: Loss=0.28369802236557007; accuracy=0.9362890124320984\n",
      "Validation accuracy: 0.026500001549720764\n",
      "epoch 97\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=0.15816056728363037; accuracy=0.9403905868530273\n",
      "Batch 200: Loss=0.29153552651405334; accuracy=0.9406640529632568\n",
      "Validation accuracy: 0.02500000037252903\n",
      "epoch 98\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=0.23816333711147308; accuracy=0.9354687333106995\n",
      "Batch 200: Loss=0.37990808486938477; accuracy=0.9347655773162842\n",
      "Validation accuracy: 0.027250001206994057\n",
      "epoch 99\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=0.2140973061323166; accuracy=0.94398432970047\n",
      "Batch 200: Loss=0.26605814695358276; accuracy=0.9437109231948853\n",
      "Validation accuracy: 0.023750001564621925\n",
      "epoch 100\n",
      "Size of input:  torch.Size([128, 96, 512])\n",
      "Size of target:  torch.Size([128])\n",
      "Size of output:  torch.Size([128, 40])\n",
      "Batch 100: Loss=0.16120502352714539; accuracy=0.9445312023162842\n",
      "Batch 200: Loss=0.1473548263311386; accuracy=0.9408202767372131\n",
      "Validation accuracy: 0.026500001549720764\n"
     ]
    }
   ],
   "source": [
    "if opt.kind==\"from-scratch\":\n",
    "    loss_history, accuracy_val, accuracy_test = net_trainer(\n",
    "            net,\n",
    "            loaders,\n",
    "            opt,\n",
    "            channel_idx,\n",
    "            nonclasses,\n",
    "            None,\n",
    "            True,\n",
    "            model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b2187309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy:  0.024000000208616257\n",
      "Test accuracy:  0\n"
     ]
    }
   ],
   "source": [
    "val =accuracy_val\n",
    "test = accuracy_test\n",
    "\n",
    "print(\"Validation accuracy: \", val)\n",
    "print(\"Test accuracy: \", test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0120c2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
