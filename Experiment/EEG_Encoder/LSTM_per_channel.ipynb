{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "from torchinfo import summary\n",
    "\n",
    "class classifier_LSTM_per_channel(nn.Module):\n",
    "    def __init__(self, channels_num):\n",
    "        super(classifier_LSTM_per_channel, self).__init__()\n",
    "        self.lstm_size0 = 1\n",
    "        self.channels_num = channels_num\n",
    "        self.lstm_per_channel = nn.LSTM(1, hidden_size=self.lstm_size0, batch_first=True)\n",
    "        self.lstm_full1 = nn.LSTM(channels_num, hidden_size=128, batch_first=True)\n",
    "        self.lstm_full2 = nn.LSTM(channels_num, hidden_size=64, batch_first=True)\n",
    "        self.linear = nn.Linear(64, out_features=6)\n",
    "        self.softmax = nn.Softmax()\n",
    "    def forward(self, X):\n",
    "        #X: (batch_size, channels_num, sequence_len)\n",
    "        print(X.size())\n",
    "        batch_size = len(X)\n",
    "        lstm_init = (torch.zeros(1, batch_size, self.lstm_size0),\n",
    "                     torch.zeros(1, batch_size, self.lstm_size0))\n",
    "        # if x.is_cuda:\n",
    "        #     lstm_init = (lstm_init[0].cuda(self.GPUindex),\n",
    "        #                  lstm_init[0].cuda(self.GPUindex))\n",
    "        lstm_init = (Variable(lstm_init[0]), Variable(lstm_init[1]))\n",
    "        first_layer_inputs = []\n",
    "        second_layer_inputs = [] #(32, timesteps)\n",
    "        for i in range(self.channels_num): \n",
    "            x_in = torch.tensor(X[:, i, :]) # x_in: (batch_size, 1, timesteps)\n",
    "            x_in = torch.squeeze(x_in, 1) #x_in: (batch_size, timesteps)\n",
    "            x_in = torch.unsqueeze(x_in, -1) #x_in: (batch_size, timesteps, input_size=1)\n",
    "            first_layer_inputs.append(x_in)\n",
    "            x_out = self.lstm_per_channel(x_in, lstm_init)[0] # x_out: (batch_size, timesteps, 1)\n",
    "            second_layer_inputs.append(x_out)\n",
    "\n",
    "        X = torch.cat(second_layer_inputs, -1) #X: (batch_size, timesteps, 32)\n",
    "        print(\"X after concat: \", X.size())\n",
    "        X = self.lstm_full1(X)\n",
    "        X = self.lstm_full2(X)\n",
    "        X = self.linear(X)\n",
    "        X = self.softmax(X)\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 15360])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_22224\\4222463860.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x_in = torch.tensor(X[:, i, :]) # x_in: (batch_size, 1, timesteps)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X after concat:  torch.Size([1, 15360, 32])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to run torchinfo. See above stack traces for more details. Executed layers up to: [LSTM: 1, LSTM: 1, LSTM: 1, LSTM: 1, LSTM: 1, LSTM: 1, LSTM: 1, LSTM: 1, LSTM: 1, LSTM: 1, LSTM: 1, LSTM: 1, LSTM: 1, LSTM: 1, LSTM: 1, LSTM: 1, LSTM: 1, LSTM: 1, LSTM: 1, LSTM: 1, LSTM: 1, LSTM: 1, LSTM: 1, LSTM: 1, LSTM: 1, LSTM: 1, LSTM: 1, LSTM: 1, LSTM: 1, LSTM: 1, LSTM: 1, LSTM: 1, LSTM: 1]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32md:\\github\\eeg-research\\envir\\lib\\site-packages\\torchinfo\\torchinfo.py:287\u001b[0m, in \u001b[0;36mforward_pass\u001b[1;34m(model, x, batch_dim, cache_forward_pass, device, mode, **kwargs)\u001b[0m\n\u001b[0;32m    286\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m--> 287\u001b[0m     _ \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto(device)(\u001b[38;5;241m*\u001b[39mx, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):\n",
      "File \u001b[1;32md:\\github\\eeg-research\\envir\\lib\\site-packages\\torch\\nn\\modules\\module.py:1208\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1206\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m-> 1208\u001b[0m result \u001b[38;5;241m=\u001b[39m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n",
      "Cell \u001b[1;32mIn [18], line 41\u001b[0m, in \u001b[0;36mclassifier_LSTM_per_channel.forward\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     40\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlstm_full1(X)\n\u001b[1;32m---> 41\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm_full2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear(X)\n",
      "File \u001b[1;32md:\\github\\eeg-research\\envir\\lib\\site-packages\\torch\\nn\\modules\\module.py:1208\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1206\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m-> 1208\u001b[0m result \u001b[38;5;241m=\u001b[39m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n",
      "File \u001b[1;32md:\\github\\eeg-research\\envir\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:736\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    735\u001b[0m batch_sizes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 736\u001b[0m is_batched \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdim\u001b[49m() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[0;32m    737\u001b[0m batch_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'dim'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [19], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m classifier_LSTM_per_channel(channels_num\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43msummary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m15360\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\github\\eeg-research\\envir\\lib\\site-packages\\torchinfo\\torchinfo.py:217\u001b[0m, in \u001b[0;36msummary\u001b[1;34m(model, input_size, input_data, batch_dim, cache_forward_pass, col_names, col_width, depth, device, dtypes, mode, row_settings, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m validate_user_params(\n\u001b[0;32m    211\u001b[0m     input_data, input_size, columns, col_width, device, dtypes, verbose\n\u001b[0;32m    212\u001b[0m )\n\u001b[0;32m    214\u001b[0m x, correct_input_size \u001b[38;5;241m=\u001b[39m process_input(\n\u001b[0;32m    215\u001b[0m     input_data, input_size, batch_dim, device, dtypes\n\u001b[0;32m    216\u001b[0m )\n\u001b[1;32m--> 217\u001b[0m summary_list \u001b[38;5;241m=\u001b[39m forward_pass(\n\u001b[0;32m    218\u001b[0m     model, x, batch_dim, cache_forward_pass, device, model_mode, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    219\u001b[0m )\n\u001b[0;32m    220\u001b[0m formatting \u001b[38;5;241m=\u001b[39m FormattingOptions(depth, verbose, columns, col_width, rows)\n\u001b[0;32m    221\u001b[0m results \u001b[38;5;241m=\u001b[39m ModelStatistics(\n\u001b[0;32m    222\u001b[0m     summary_list, correct_input_size, get_total_memory_used(x), formatting\n\u001b[0;32m    223\u001b[0m )\n",
      "File \u001b[1;32md:\\github\\eeg-research\\envir\\lib\\site-packages\\torchinfo\\torchinfo.py:296\u001b[0m, in \u001b[0;36mforward_pass\u001b[1;34m(model, x, batch_dim, cache_forward_pass, device, mode, **kwargs)\u001b[0m\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    295\u001b[0m     executed_layers \u001b[38;5;241m=\u001b[39m [layer \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m summary_list \u001b[38;5;28;01mif\u001b[39;00m layer\u001b[38;5;241m.\u001b[39mexecuted]\n\u001b[1;32m--> 296\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    297\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to run torchinfo. See above stack traces for more details. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    298\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecuted layers up to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexecuted_layers\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    299\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    300\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    301\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hooks:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Failed to run torchinfo. See above stack traces for more details. Executed layers up to: [LSTM: 1, LSTM: 1, LSTM: 1, LSTM: 1, LSTM: 1, LSTM: 1, LSTM: 1, LSTM: 1, LSTM: 1, LSTM: 1, LSTM: 1, LSTM: 1, LSTM: 1, LSTM: 1, LSTM: 1, LSTM: 1, LSTM: 1, LSTM: 1, LSTM: 1, LSTM: 1, LSTM: 1, LSTM: 1, LSTM: 1, LSTM: 1, LSTM: 1, LSTM: 1, LSTM: 1, LSTM: 1, LSTM: 1, LSTM: 1, LSTM: 1, LSTM: 1, LSTM: 1]"
     ]
    }
   ],
   "source": [
    "model = classifier_LSTM_per_channel(channels_num=32)\n",
    "summary(model, input_size=(1, 32, 15360))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "f2ccb58c476f33ba3e3aee7ac07234ef6b8217ef24ad64d2a7d4fed1a57c1cd2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
