2023-05-22 20:40:10.693 | INFO     | __main__:run_triplet:49 - Namespace(dataset='CVPR2017', eeg_path='/media/exx/HDD1/LanxHuyen/CVPR2017/eeg_55_95_std.pth', time_low=20, time_high=460, img_path='/media/exx/HDD1/LanxHuyen/CVPR2017/imagenet_augmented', splits_path='/media/exx/HDD1/LanxHuyen/CVPR2017/block_splits_by_image_all.pth', log_path='/home/exx/GithubClonedRepo/EEG-Research/Experiment/ContrastiveLearning', info='tripletnet_with_dataset_augmented', img_encoder='inception_v3', eeg_encoder='EEGChannelNet', batch_size=128, lr=0.005, wd=0.0001, optim='SGD', max_epoch=50, log_interval=10, num_workers=2, gpu=1, gamma=200, arch='train', save_ckpt='checkpoints/', lr_step='40', pretrain=False, momen=0.9, nesterov=False, num_classes=40, device=device(type='cuda', index=1))
2023-05-22 20:41:06.922 | INFO     | trainer_plot:train_epoch:125 - Train: [0/7970 (0%)]	Loss: 0.006737
2023-05-22 20:41:17.147 | INFO     | trainer_plot:train_epoch:125 - Train: [640/7970 (8%)]	Loss: 0.006547
2023-05-22 20:41:27.099 | INFO     | trainer_plot:train_epoch:125 - Train: [1280/7970 (16%)]	Loss: 0.003477
2023-05-22 20:41:37.075 | INFO     | trainer_plot:train_epoch:125 - Train: [1920/7970 (24%)]	Loss: 0.001942
2023-05-22 20:41:47.068 | INFO     | trainer_plot:train_epoch:125 - Train: [2560/7970 (32%)]	Loss: 0.000816
2023-05-22 20:41:57.069 | INFO     | trainer_plot:train_epoch:125 - Train: [3200/7970 (40%)]	Loss: 0.000955
2023-05-22 20:42:07.080 | INFO     | trainer_plot:train_epoch:125 - Train: [3840/7970 (48%)]	Loss: 0.000485
2023-05-22 20:42:17.106 | INFO     | trainer_plot:train_epoch:125 - Train: [4480/7970 (56%)]	Loss: 0.000362
2023-05-22 20:42:27.146 | INFO     | trainer_plot:train_epoch:125 - Train: [5120/7970 (65%)]	Loss: 0.000926
2023-05-22 20:42:37.193 | INFO     | trainer_plot:train_epoch:125 - Train: [5760/7970 (73%)]	Loss: 0.000636
2023-05-22 20:42:47.243 | INFO     | trainer_plot:train_epoch:125 - Train: [6400/7970 (81%)]	Loss: 0.001003
2023-05-22 20:42:57.300 | INFO     | trainer_plot:train_epoch:125 - Train: [7040/7970 (89%)]	Loss: 0.001143
2023-05-22 20:43:07.346 | INFO     | trainer_plot:train_epoch:125 - Train: [7680/7970 (97%)]	Loss: 0.002104
2023-05-22 20:43:10.455 | INFO     | trainer_plot:fit:33 - Epoch: 1/50. Train set: Average loss: 0.001873
2023-05-22 20:43:20.205 | INFO     | trainer_plot:fit:43 - Epoch: 1/50. Validation set: Average loss: 0.015052
2023-05-22 20:43:21.565 | INFO     | trainer_plot:train_epoch:125 - Train: [0/7970 (0%)]	Loss: 0.000958
2023-05-22 20:43:31.585 | INFO     | trainer_plot:train_epoch:125 - Train: [640/7970 (8%)]	Loss: 0.000987
2023-05-22 20:43:41.612 | INFO     | trainer_plot:train_epoch:125 - Train: [1280/7970 (16%)]	Loss: 0.001825
2023-05-22 20:43:51.701 | INFO     | trainer_plot:train_epoch:125 - Train: [1920/7970 (24%)]	Loss: 0.001014
2023-05-22 20:44:01.740 | INFO     | trainer_plot:train_epoch:125 - Train: [2560/7970 (32%)]	Loss: 0.000998
2023-05-22 20:44:11.781 | INFO     | trainer_plot:train_epoch:125 - Train: [3200/7970 (40%)]	Loss: 0.001008
2023-05-22 20:44:21.823 | INFO     | trainer_plot:train_epoch:125 - Train: [3840/7970 (48%)]	Loss: 0.001408
2023-05-22 20:44:31.876 | INFO     | trainer_plot:train_epoch:125 - Train: [4480/7970 (56%)]	Loss: 0.001095
2023-05-22 20:44:41.913 | INFO     | trainer_plot:train_epoch:125 - Train: [5120/7970 (65%)]	Loss: 0.002276
2023-05-22 20:44:51.955 | INFO     | trainer_plot:train_epoch:125 - Train: [5760/7970 (73%)]	Loss: 0.001904
2023-05-22 20:45:02.013 | INFO     | trainer_plot:train_epoch:125 - Train: [6400/7970 (81%)]	Loss: 0.002394
2023-05-22 20:45:12.049 | INFO     | trainer_plot:train_epoch:125 - Train: [7040/7970 (89%)]	Loss: 0.012648
2023-05-22 20:45:22.091 | INFO     | trainer_plot:train_epoch:125 - Train: [7680/7970 (97%)]	Loss: 0.003841
2023-05-22 20:45:25.215 | INFO     | trainer_plot:fit:33 - Epoch: 2/50. Train set: Average loss: 0.002630
2023-05-22 20:45:34.982 | INFO     | trainer_plot:fit:43 - Epoch: 2/50. Validation set: Average loss: 0.032608
2023-05-22 20:45:36.337 | INFO     | trainer_plot:train_epoch:125 - Train: [0/7970 (0%)]	Loss: 0.002141
2023-05-22 20:45:46.344 | INFO     | trainer_plot:train_epoch:125 - Train: [640/7970 (8%)]	Loss: 0.004567
2023-05-22 20:45:56.345 | INFO     | trainer_plot:train_epoch:125 - Train: [1280/7970 (16%)]	Loss: 0.001617
2023-05-22 20:46:06.368 | INFO     | trainer_plot:train_epoch:125 - Train: [1920/7970 (24%)]	Loss: 0.001599
2023-05-22 20:46:16.391 | INFO     | trainer_plot:train_epoch:125 - Train: [2560/7970 (32%)]	Loss: 0.001659
2023-05-22 20:46:26.416 | INFO     | trainer_plot:train_epoch:125 - Train: [3200/7970 (40%)]	Loss: 0.000724
2023-05-22 20:46:36.451 | INFO     | trainer_plot:train_epoch:125 - Train: [3840/7970 (48%)]	Loss: 0.001095
2023-05-22 20:46:46.479 | INFO     | trainer_plot:train_epoch:125 - Train: [4480/7970 (56%)]	Loss: 0.001872
2023-05-22 20:46:56.502 | INFO     | trainer_plot:train_epoch:125 - Train: [5120/7970 (65%)]	Loss: 0.001493
2023-05-22 20:47:06.525 | INFO     | trainer_plot:train_epoch:125 - Train: [5760/7970 (73%)]	Loss: 0.000978
2023-05-22 20:47:16.539 | INFO     | trainer_plot:train_epoch:125 - Train: [6400/7970 (81%)]	Loss: 0.000759
2023-05-22 20:47:26.549 | INFO     | trainer_plot:train_epoch:125 - Train: [7040/7970 (89%)]	Loss: 0.000452
2023-05-22 20:47:36.549 | INFO     | trainer_plot:train_epoch:125 - Train: [7680/7970 (97%)]	Loss: 0.000327
2023-05-22 20:47:39.673 | INFO     | trainer_plot:fit:33 - Epoch: 3/50. Train set: Average loss: 0.001421
2023-05-22 20:47:49.382 | INFO     | trainer_plot:fit:43 - Epoch: 3/50. Validation set: Average loss: 0.000112
2023-05-22 20:47:50.739 | INFO     | trainer_plot:train_epoch:125 - Train: [0/7970 (0%)]	Loss: 0.000003
2023-05-22 20:48:00.720 | INFO     | trainer_plot:train_epoch:125 - Train: [640/7970 (8%)]	Loss: 0.000309
2023-05-22 20:48:10.718 | INFO     | trainer_plot:train_epoch:125 - Train: [1280/7970 (16%)]	Loss: 0.000394
2023-05-22 20:48:20.711 | INFO     | trainer_plot:train_epoch:125 - Train: [1920/7970 (24%)]	Loss: 0.000548
2023-05-22 20:48:30.712 | INFO     | trainer_plot:train_epoch:125 - Train: [2560/7970 (32%)]	Loss: 0.000222
2023-05-22 20:48:40.712 | INFO     | trainer_plot:train_epoch:125 - Train: [3200/7970 (40%)]	Loss: 0.002498
2023-05-22 20:48:50.709 | INFO     | trainer_plot:train_epoch:125 - Train: [3840/7970 (48%)]	Loss: 0.002247
2023-05-22 20:49:00.708 | INFO     | trainer_plot:train_epoch:125 - Train: [4480/7970 (56%)]	Loss: 0.001033
2023-05-22 20:49:10.699 | INFO     | trainer_plot:train_epoch:125 - Train: [5120/7970 (65%)]	Loss: 0.001723
2023-05-22 20:49:20.701 | INFO     | trainer_plot:train_epoch:125 - Train: [5760/7970 (73%)]	Loss: 0.001501
2023-05-22 20:49:30.699 | INFO     | trainer_plot:train_epoch:125 - Train: [6400/7970 (81%)]	Loss: 0.000714
2023-05-22 20:49:40.693 | INFO     | trainer_plot:train_epoch:125 - Train: [7040/7970 (89%)]	Loss: 0.001082
2023-05-22 20:49:50.688 | INFO     | trainer_plot:train_epoch:125 - Train: [7680/7970 (97%)]	Loss: 0.000928
2023-05-22 20:49:53.797 | INFO     | trainer_plot:fit:33 - Epoch: 4/50. Train set: Average loss: 0.001076
2023-05-22 20:50:03.507 | INFO     | trainer_plot:fit:43 - Epoch: 4/50. Validation set: Average loss: 0.001022
2023-05-22 20:50:04.868 | INFO     | trainer_plot:train_epoch:125 - Train: [0/7970 (0%)]	Loss: 0.000755
2023-05-22 20:50:14.849 | INFO     | trainer_plot:train_epoch:125 - Train: [640/7970 (8%)]	Loss: 0.001356
2023-05-22 20:50:24.829 | INFO     | trainer_plot:train_epoch:125 - Train: [1280/7970 (16%)]	Loss: 0.001093
2023-05-22 20:50:34.813 | INFO     | trainer_plot:train_epoch:125 - Train: [1920/7970 (24%)]	Loss: 0.000538
2023-05-22 20:50:44.811 | INFO     | trainer_plot:train_epoch:125 - Train: [2560/7970 (32%)]	Loss: 0.007383
2023-05-22 20:50:54.819 | INFO     | trainer_plot:train_epoch:125 - Train: [3200/7970 (40%)]	Loss: 0.002002
2023-05-22 20:51:04.821 | INFO     | trainer_plot:train_epoch:125 - Train: [3840/7970 (48%)]	Loss: 0.001956
2023-05-22 20:51:14.821 | INFO     | trainer_plot:train_epoch:125 - Train: [4480/7970 (56%)]	Loss: 0.000959
2023-05-22 20:51:24.821 | INFO     | trainer_plot:train_epoch:125 - Train: [5120/7970 (65%)]	Loss: 0.000884
2023-05-22 20:51:34.824 | INFO     | trainer_plot:train_epoch:125 - Train: [5760/7970 (73%)]	Loss: 0.000609
2023-05-22 20:51:44.815 | INFO     | trainer_plot:train_epoch:125 - Train: [6400/7970 (81%)]	Loss: 0.002538
2023-05-22 20:51:54.813 | INFO     | trainer_plot:train_epoch:125 - Train: [7040/7970 (89%)]	Loss: 0.002695
2023-05-22 20:52:04.829 | INFO     | trainer_plot:train_epoch:125 - Train: [7680/7970 (97%)]	Loss: 0.000493
2023-05-22 20:52:07.937 | INFO     | trainer_plot:fit:33 - Epoch: 5/50. Train set: Average loss: 0.001884
2023-05-22 20:52:17.646 | INFO     | trainer_plot:fit:43 - Epoch: 5/50. Validation set: Average loss: 0.016990
2023-05-22 20:52:19.021 | INFO     | trainer_plot:train_epoch:125 - Train: [0/7970 (0%)]	Loss: 0.000829
2023-05-22 20:52:29.008 | INFO     | trainer_plot:train_epoch:125 - Train: [640/7970 (8%)]	Loss: 0.000941
2023-05-22 20:52:38.988 | INFO     | trainer_plot:train_epoch:125 - Train: [1280/7970 (16%)]	Loss: 0.000344
2023-05-22 20:52:48.977 | INFO     | trainer_plot:train_epoch:125 - Train: [1920/7970 (24%)]	Loss: 0.000803
2023-05-22 20:52:58.972 | INFO     | trainer_plot:train_epoch:125 - Train: [2560/7970 (32%)]	Loss: 0.001032
2023-05-22 20:53:08.961 | INFO     | trainer_plot:train_epoch:125 - Train: [3200/7970 (40%)]	Loss: 0.000715
2023-05-22 20:53:18.956 | INFO     | trainer_plot:train_epoch:125 - Train: [3840/7970 (48%)]	Loss: 0.000442
2023-05-22 20:53:28.947 | INFO     | trainer_plot:train_epoch:125 - Train: [4480/7970 (56%)]	Loss: 0.002319
2023-05-22 20:53:39.001 | INFO     | trainer_plot:train_epoch:125 - Train: [5120/7970 (65%)]	Loss: 0.001628
2023-05-22 20:53:48.995 | INFO     | trainer_plot:train_epoch:125 - Train: [5760/7970 (73%)]	Loss: 0.001622
2023-05-22 20:53:58.985 | INFO     | trainer_plot:train_epoch:125 - Train: [6400/7970 (81%)]	Loss: 0.001737
2023-05-22 20:54:08.970 | INFO     | trainer_plot:train_epoch:125 - Train: [7040/7970 (89%)]	Loss: 0.001925
2023-05-22 20:54:18.969 | INFO     | trainer_plot:train_epoch:125 - Train: [7680/7970 (97%)]	Loss: 0.003719
2023-05-22 20:54:22.086 | INFO     | trainer_plot:fit:33 - Epoch: 6/50. Train set: Average loss: 0.001414
2023-05-22 20:54:31.837 | INFO     | trainer_plot:fit:43 - Epoch: 6/50. Validation set: Average loss: 0.018225
2023-05-22 20:54:33.203 | INFO     | trainer_plot:train_epoch:125 - Train: [0/7970 (0%)]	Loss: 0.000700
2023-05-22 20:54:43.181 | INFO     | trainer_plot:train_epoch:125 - Train: [640/7970 (8%)]	Loss: 0.002154
2023-05-22 20:54:53.170 | INFO     | trainer_plot:train_epoch:125 - Train: [1280/7970 (16%)]	Loss: 0.000687
2023-05-22 20:55:03.155 | INFO     | trainer_plot:train_epoch:125 - Train: [1920/7970 (24%)]	Loss: 0.000562
2023-05-22 20:55:13.144 | INFO     | trainer_plot:train_epoch:125 - Train: [2560/7970 (32%)]	Loss: 0.001048
2023-05-22 20:55:23.137 | INFO     | trainer_plot:train_epoch:125 - Train: [3200/7970 (40%)]	Loss: 0.000265
2023-05-22 20:55:33.133 | INFO     | trainer_plot:train_epoch:125 - Train: [3840/7970 (48%)]	Loss: 0.000238
2023-05-22 20:55:43.137 | INFO     | trainer_plot:train_epoch:125 - Train: [4480/7970 (56%)]	Loss: 0.001606
2023-05-22 20:55:53.133 | INFO     | trainer_plot:train_epoch:125 - Train: [5120/7970 (65%)]	Loss: 0.000922
2023-05-22 20:56:03.144 | INFO     | trainer_plot:train_epoch:125 - Train: [5760/7970 (73%)]	Loss: 0.000508
2023-05-22 20:56:13.143 | INFO     | trainer_plot:train_epoch:125 - Train: [6400/7970 (81%)]	Loss: 0.001448
2023-05-22 20:56:23.143 | INFO     | trainer_plot:train_epoch:125 - Train: [7040/7970 (89%)]	Loss: 0.001025
2023-05-22 20:56:33.139 | INFO     | trainer_plot:train_epoch:125 - Train: [7680/7970 (97%)]	Loss: 0.000285
2023-05-22 20:56:36.257 | INFO     | trainer_plot:fit:33 - Epoch: 7/50. Train set: Average loss: 0.000876
2023-05-22 20:56:45.996 | INFO     | trainer_plot:fit:43 - Epoch: 7/50. Validation set: Average loss: 0.032968
2023-05-22 20:56:47.362 | INFO     | trainer_plot:train_epoch:125 - Train: [0/7970 (0%)]	Loss: 0.002634
2023-05-22 20:56:57.337 | INFO     | trainer_plot:train_epoch:125 - Train: [640/7970 (8%)]	Loss: 0.000714
2023-05-22 20:57:07.324 | INFO     | trainer_plot:train_epoch:125 - Train: [1280/7970 (16%)]	Loss: 0.000402
2023-05-22 20:57:17.299 | INFO     | trainer_plot:train_epoch:125 - Train: [1920/7970 (24%)]	Loss: 0.000674
2023-05-22 20:57:27.297 | INFO     | trainer_plot:train_epoch:125 - Train: [2560/7970 (32%)]	Loss: 0.001284
2023-05-22 20:57:37.286 | INFO     | trainer_plot:train_epoch:125 - Train: [3200/7970 (40%)]	Loss: 0.002794
2023-05-22 20:57:47.281 | INFO     | trainer_plot:train_epoch:125 - Train: [3840/7970 (48%)]	Loss: 0.000679
2023-05-22 20:57:57.280 | INFO     | trainer_plot:train_epoch:125 - Train: [4480/7970 (56%)]	Loss: 0.000796
2023-05-22 20:58:07.289 | INFO     | trainer_plot:train_epoch:125 - Train: [5120/7970 (65%)]	Loss: 0.001662
2023-05-22 20:58:17.275 | INFO     | trainer_plot:train_epoch:125 - Train: [5760/7970 (73%)]	Loss: 0.000687
2023-05-22 20:58:27.272 | INFO     | trainer_plot:train_epoch:125 - Train: [6400/7970 (81%)]	Loss: 0.000656
2023-05-22 20:58:37.269 | INFO     | trainer_plot:train_epoch:125 - Train: [7040/7970 (89%)]	Loss: 0.001652
2023-05-22 20:58:47.326 | INFO     | trainer_plot:train_epoch:125 - Train: [7680/7970 (97%)]	Loss: 0.001186
2023-05-22 20:58:50.440 | INFO     | trainer_plot:fit:33 - Epoch: 8/50. Train set: Average loss: 0.001140
2023-05-22 20:59:00.187 | INFO     | trainer_plot:fit:43 - Epoch: 8/50. Validation set: Average loss: 0.003033
2023-05-22 20:59:01.559 | INFO     | trainer_plot:train_epoch:125 - Train: [0/7970 (0%)]	Loss: 0.001373
2023-05-22 20:59:11.523 | INFO     | trainer_plot:train_epoch:125 - Train: [640/7970 (8%)]	Loss: 0.001453
2023-05-22 20:59:21.498 | INFO     | trainer_plot:train_epoch:125 - Train: [1280/7970 (16%)]	Loss: 0.001278
2023-05-22 20:59:31.468 | INFO     | trainer_plot:train_epoch:125 - Train: [1920/7970 (24%)]	Loss: 0.001812
2023-05-22 20:59:41.452 | INFO     | trainer_plot:train_epoch:125 - Train: [2560/7970 (32%)]	Loss: 0.001204
2023-05-22 20:59:51.429 | INFO     | trainer_plot:train_epoch:125 - Train: [3200/7970 (40%)]	Loss: 0.001049
2023-05-22 21:00:01.420 | INFO     | trainer_plot:train_epoch:125 - Train: [3840/7970 (48%)]	Loss: 0.000956
2023-05-22 21:00:11.403 | INFO     | trainer_plot:train_epoch:125 - Train: [4480/7970 (56%)]	Loss: 0.001459
2023-05-22 21:00:21.400 | INFO     | trainer_plot:train_epoch:125 - Train: [5120/7970 (65%)]	Loss: 0.001199
2023-05-22 21:00:31.391 | INFO     | trainer_plot:train_epoch:125 - Train: [5760/7970 (73%)]	Loss: 0.001310
2023-05-22 21:00:41.387 | INFO     | trainer_plot:train_epoch:125 - Train: [6400/7970 (81%)]	Loss: 0.000984
2023-05-22 21:00:51.375 | INFO     | trainer_plot:train_epoch:125 - Train: [7040/7970 (89%)]	Loss: 0.000978
2023-05-22 21:01:01.363 | INFO     | trainer_plot:train_epoch:125 - Train: [7680/7970 (97%)]	Loss: 0.000854
2023-05-22 21:01:04.469 | INFO     | trainer_plot:fit:33 - Epoch: 9/50. Train set: Average loss: 0.001207
2023-05-22 21:01:14.238 | INFO     | trainer_plot:fit:43 - Epoch: 9/50. Validation set: Average loss: 0.000301
2023-05-22 21:01:15.601 | INFO     | trainer_plot:train_epoch:125 - Train: [0/7970 (0%)]	Loss: 0.000500
2023-05-22 21:01:25.559 | INFO     | trainer_plot:train_epoch:125 - Train: [640/7970 (8%)]	Loss: 0.001015
2023-05-22 21:01:35.530 | INFO     | trainer_plot:train_epoch:125 - Train: [1280/7970 (16%)]	Loss: 0.000873
2023-05-22 21:01:45.503 | INFO     | trainer_plot:train_epoch:125 - Train: [1920/7970 (24%)]	Loss: 0.001082
2023-05-22 21:01:55.475 | INFO     | trainer_plot:train_epoch:125 - Train: [2560/7970 (32%)]	Loss: 0.000750
2023-05-22 21:02:05.452 | INFO     | trainer_plot:train_epoch:125 - Train: [3200/7970 (40%)]	Loss: 0.001155
2023-05-22 21:02:15.440 | INFO     | trainer_plot:train_epoch:125 - Train: [3840/7970 (48%)]	Loss: 0.000954
2023-05-22 21:02:25.415 | INFO     | trainer_plot:train_epoch:125 - Train: [4480/7970 (56%)]	Loss: 0.001117
2023-05-22 21:02:35.392 | INFO     | trainer_plot:train_epoch:125 - Train: [5120/7970 (65%)]	Loss: 0.001029
2023-05-22 21:02:45.364 | INFO     | trainer_plot:train_epoch:125 - Train: [5760/7970 (73%)]	Loss: 0.000959
2023-05-22 21:02:55.359 | INFO     | trainer_plot:train_epoch:125 - Train: [6400/7970 (81%)]	Loss: 0.000823
2023-05-22 21:03:05.327 | INFO     | trainer_plot:train_epoch:125 - Train: [7040/7970 (89%)]	Loss: 0.000977
2023-05-22 21:03:15.320 | INFO     | trainer_plot:train_epoch:125 - Train: [7680/7970 (97%)]	Loss: 0.000725
2023-05-22 21:03:18.421 | INFO     | trainer_plot:fit:33 - Epoch: 10/50. Train set: Average loss: 0.000953
2023-05-22 21:03:28.174 | INFO     | trainer_plot:fit:43 - Epoch: 10/50. Validation set: Average loss: 0.000563
2023-05-22 21:03:29.848 | INFO     | trainer_plot:train_epoch:125 - Train: [0/7970 (0%)]	Loss: 0.001658
2023-05-22 21:03:39.816 | INFO     | trainer_plot:train_epoch:125 - Train: [640/7970 (8%)]	Loss: 0.000854
2023-05-22 21:03:49.787 | INFO     | trainer_plot:train_epoch:125 - Train: [1280/7970 (16%)]	Loss: 0.000805
2023-05-22 21:03:59.761 | INFO     | trainer_plot:train_epoch:125 - Train: [1920/7970 (24%)]	Loss: 0.000895
2023-05-22 21:04:09.744 | INFO     | trainer_plot:train_epoch:125 - Train: [2560/7970 (32%)]	Loss: 0.000890
2023-05-22 21:04:19.728 | INFO     | trainer_plot:train_epoch:125 - Train: [3200/7970 (40%)]	Loss: 0.001023
2023-05-22 21:04:29.733 | INFO     | trainer_plot:train_epoch:125 - Train: [3840/7970 (48%)]	Loss: 0.000714
2023-05-22 21:04:39.716 | INFO     | trainer_plot:train_epoch:125 - Train: [4480/7970 (56%)]	Loss: 0.000841
2023-05-22 21:04:49.712 | INFO     | trainer_plot:train_epoch:125 - Train: [5120/7970 (65%)]	Loss: 0.000618
2023-05-22 21:04:59.694 | INFO     | trainer_plot:train_epoch:125 - Train: [5760/7970 (73%)]	Loss: 0.000764
2023-05-22 21:05:09.671 | INFO     | trainer_plot:train_epoch:125 - Train: [6400/7970 (81%)]	Loss: 0.000706
2023-05-22 21:05:19.668 | INFO     | trainer_plot:train_epoch:125 - Train: [7040/7970 (89%)]	Loss: 0.000682
2023-05-22 21:05:29.656 | INFO     | trainer_plot:train_epoch:125 - Train: [7680/7970 (97%)]	Loss: 0.000732
2023-05-22 21:05:32.761 | INFO     | trainer_plot:fit:33 - Epoch: 11/50. Train set: Average loss: 0.000804
2023-05-22 21:05:42.527 | INFO     | trainer_plot:fit:43 - Epoch: 11/50. Validation set: Average loss: 0.000024
2023-05-22 21:05:43.897 | INFO     | trainer_plot:train_epoch:125 - Train: [0/7970 (0%)]	Loss: 0.000340
2023-05-22 21:05:53.867 | INFO     | trainer_plot:train_epoch:125 - Train: [640/7970 (8%)]	Loss: 0.000809
2023-05-22 21:06:03.845 | INFO     | trainer_plot:train_epoch:125 - Train: [1280/7970 (16%)]	Loss: 0.000768
2023-05-22 21:06:13.812 | INFO     | trainer_plot:train_epoch:125 - Train: [1920/7970 (24%)]	Loss: 0.000521
2023-05-22 21:06:23.784 | INFO     | trainer_plot:train_epoch:125 - Train: [2560/7970 (32%)]	Loss: 0.000642
2023-05-22 21:06:33.767 | INFO     | trainer_plot:train_epoch:125 - Train: [3200/7970 (40%)]	Loss: 0.000463
2023-05-22 21:06:43.758 | INFO     | trainer_plot:train_epoch:125 - Train: [3840/7970 (48%)]	Loss: 0.000517
2023-05-22 21:06:53.735 | INFO     | trainer_plot:train_epoch:125 - Train: [4480/7970 (56%)]	Loss: 0.000972
2023-05-22 21:07:03.715 | INFO     | trainer_plot:train_epoch:125 - Train: [5120/7970 (65%)]	Loss: 0.000725
2023-05-22 21:07:13.711 | INFO     | trainer_plot:train_epoch:125 - Train: [5760/7970 (73%)]	Loss: 0.000449
2023-05-22 21:07:23.699 | INFO     | trainer_plot:train_epoch:125 - Train: [6400/7970 (81%)]	Loss: 0.000695
2023-05-22 21:07:33.744 | INFO     | trainer_plot:train_epoch:125 - Train: [7040/7970 (89%)]	Loss: 0.000733
2023-05-22 21:07:43.730 | INFO     | trainer_plot:train_epoch:125 - Train: [7680/7970 (97%)]	Loss: 0.000445
2023-05-22 21:07:46.839 | INFO     | trainer_plot:fit:33 - Epoch: 12/50. Train set: Average loss: 0.000635
2023-05-22 21:07:56.573 | INFO     | trainer_plot:fit:43 - Epoch: 12/50. Validation set: Average loss: 0.000039
2023-05-22 21:07:57.940 | INFO     | trainer_plot:train_epoch:125 - Train: [0/7970 (0%)]	Loss: 0.000179
2023-05-22 21:08:07.912 | INFO     | trainer_plot:train_epoch:125 - Train: [640/7970 (8%)]	Loss: 0.000476
2023-05-22 21:08:17.881 | INFO     | trainer_plot:train_epoch:125 - Train: [1280/7970 (16%)]	Loss: 0.000441
2023-05-22 21:08:27.864 | INFO     | trainer_plot:train_epoch:125 - Train: [1920/7970 (24%)]	Loss: 0.000658
2023-05-22 21:08:37.839 | INFO     | trainer_plot:train_epoch:125 - Train: [2560/7970 (32%)]	Loss: 0.000348
2023-05-22 21:08:47.820 | INFO     | trainer_plot:train_epoch:125 - Train: [3200/7970 (40%)]	Loss: 0.000522
2023-05-22 21:08:57.797 | INFO     | trainer_plot:train_epoch:125 - Train: [3840/7970 (48%)]	Loss: 0.000332
2023-05-22 21:09:07.792 | INFO     | trainer_plot:train_epoch:125 - Train: [4480/7970 (56%)]	Loss: 0.000488
2023-05-22 21:09:17.779 | INFO     | trainer_plot:train_epoch:125 - Train: [5120/7970 (65%)]	Loss: 0.000381
2023-05-22 21:09:27.761 | INFO     | trainer_plot:train_epoch:125 - Train: [5760/7970 (73%)]	Loss: 0.000208
2023-05-22 21:09:37.746 | INFO     | trainer_plot:train_epoch:125 - Train: [6400/7970 (81%)]	Loss: 0.000494
2023-05-22 21:09:47.740 | INFO     | trainer_plot:train_epoch:125 - Train: [7040/7970 (89%)]	Loss: 0.000217
2023-05-22 21:09:57.736 | INFO     | trainer_plot:train_epoch:125 - Train: [7680/7970 (97%)]	Loss: 0.000323
2023-05-22 21:10:00.849 | INFO     | trainer_plot:fit:33 - Epoch: 13/50. Train set: Average loss: 0.000401
2023-05-22 21:10:10.620 | INFO     | trainer_plot:fit:43 - Epoch: 13/50. Validation set: Average loss: 0.000305
2023-05-22 21:10:12.016 | INFO     | trainer_plot:train_epoch:125 - Train: [0/7970 (0%)]	Loss: 0.000345
2023-05-22 21:10:21.993 | INFO     | trainer_plot:train_epoch:125 - Train: [640/7970 (8%)]	Loss: 0.000388
2023-05-22 21:10:31.984 | INFO     | trainer_plot:train_epoch:125 - Train: [1280/7970 (16%)]	Loss: 0.000307
2023-05-22 21:10:41.973 | INFO     | trainer_plot:train_epoch:125 - Train: [1920/7970 (24%)]	Loss: 0.000285
2023-05-22 21:10:51.957 | INFO     | trainer_plot:train_epoch:125 - Train: [2560/7970 (32%)]	Loss: 0.000274
2023-05-22 21:11:01.938 | INFO     | trainer_plot:train_epoch:125 - Train: [3200/7970 (40%)]	Loss: 0.000105
2023-05-22 21:11:11.921 | INFO     | trainer_plot:train_epoch:125 - Train: [3840/7970 (48%)]	Loss: 0.000475
2023-05-22 21:11:21.904 | INFO     | trainer_plot:train_epoch:125 - Train: [4480/7970 (56%)]	Loss: 0.000126
2023-05-22 21:11:31.893 | INFO     | trainer_plot:train_epoch:125 - Train: [5120/7970 (65%)]	Loss: 0.000547
2023-05-22 21:11:41.876 | INFO     | trainer_plot:train_epoch:125 - Train: [5760/7970 (73%)]	Loss: 0.001032
2023-05-22 21:11:51.863 | INFO     | trainer_plot:train_epoch:125 - Train: [6400/7970 (81%)]	Loss: 0.000891
2023-05-22 21:12:01.848 | INFO     | trainer_plot:train_epoch:125 - Train: [7040/7970 (89%)]	Loss: 0.000903
2023-05-22 21:12:11.829 | INFO     | trainer_plot:train_epoch:125 - Train: [7680/7970 (97%)]	Loss: 0.000503
2023-05-22 21:12:14.930 | INFO     | trainer_plot:fit:33 - Epoch: 14/50. Train set: Average loss: 0.000497
2023-05-22 21:12:24.666 | INFO     | trainer_plot:fit:43 - Epoch: 14/50. Validation set: Average loss: 0.001358
2023-05-22 21:12:26.020 | INFO     | trainer_plot:train_epoch:125 - Train: [0/7970 (0%)]	Loss: 0.001089
2023-05-22 21:12:35.990 | INFO     | trainer_plot:train_epoch:125 - Train: [640/7970 (8%)]	Loss: 0.000862
2023-05-22 21:12:45.963 | INFO     | trainer_plot:train_epoch:125 - Train: [1280/7970 (16%)]	Loss: 0.000571
2023-05-22 21:12:55.943 | INFO     | trainer_plot:train_epoch:125 - Train: [1920/7970 (24%)]	Loss: 0.000556
2023-05-22 21:13:05.981 | INFO     | trainer_plot:train_epoch:125 - Train: [2560/7970 (32%)]	Loss: 0.000504
2023-05-22 21:13:15.963 | INFO     | trainer_plot:train_epoch:125 - Train: [3200/7970 (40%)]	Loss: 0.000527
2023-05-22 21:13:25.940 | INFO     | trainer_plot:train_epoch:125 - Train: [3840/7970 (48%)]	Loss: 0.000239
2023-05-22 21:13:35.927 | INFO     | trainer_plot:train_epoch:125 - Train: [4480/7970 (56%)]	Loss: 0.000553
2023-05-22 21:13:45.910 | INFO     | trainer_plot:train_epoch:125 - Train: [5120/7970 (65%)]	Loss: 0.000213
2023-05-22 21:13:55.900 | INFO     | trainer_plot:train_epoch:125 - Train: [5760/7970 (73%)]	Loss: 0.000415
2023-05-22 21:14:05.900 | INFO     | trainer_plot:train_epoch:125 - Train: [6400/7970 (81%)]	Loss: 0.000593
2023-05-22 21:14:15.896 | INFO     | trainer_plot:train_epoch:125 - Train: [7040/7970 (89%)]	Loss: 0.000323
2023-05-22 21:14:25.891 | INFO     | trainer_plot:train_epoch:125 - Train: [7680/7970 (97%)]	Loss: 0.000399
2023-05-22 21:14:29.003 | INFO     | trainer_plot:fit:33 - Epoch: 15/50. Train set: Average loss: 0.000481
2023-05-22 21:14:38.764 | INFO     | trainer_plot:fit:43 - Epoch: 15/50. Validation set: Average loss: 0.006846
2023-05-22 21:14:40.120 | INFO     | trainer_plot:train_epoch:125 - Train: [0/7970 (0%)]	Loss: 0.000278
2023-05-22 21:14:50.079 | INFO     | trainer_plot:train_epoch:125 - Train: [640/7970 (8%)]	Loss: 0.000417
2023-05-22 21:15:00.044 | INFO     | trainer_plot:train_epoch:125 - Train: [1280/7970 (16%)]	Loss: 0.000315
2023-05-22 21:15:10.027 | INFO     | trainer_plot:train_epoch:125 - Train: [1920/7970 (24%)]	Loss: 0.000287
2023-05-22 21:15:20.011 | INFO     | trainer_plot:train_epoch:125 - Train: [2560/7970 (32%)]	Loss: 0.000289
2023-05-22 21:15:29.996 | INFO     | trainer_plot:train_epoch:125 - Train: [3200/7970 (40%)]	Loss: 0.000396
2023-05-22 21:15:39.988 | INFO     | trainer_plot:train_epoch:125 - Train: [3840/7970 (48%)]	Loss: 0.000413
2023-05-22 21:15:49.971 | INFO     | trainer_plot:train_epoch:125 - Train: [4480/7970 (56%)]	Loss: 0.000187
2023-05-22 21:15:59.955 | INFO     | trainer_plot:train_epoch:125 - Train: [5120/7970 (65%)]	Loss: 0.000218
2023-05-22 21:16:09.944 | INFO     | trainer_plot:train_epoch:125 - Train: [5760/7970 (73%)]	Loss: 0.000250
2023-05-22 21:16:19.920 | INFO     | trainer_plot:train_epoch:125 - Train: [6400/7970 (81%)]	Loss: 0.000195
2023-05-22 21:16:29.903 | INFO     | trainer_plot:train_epoch:125 - Train: [7040/7970 (89%)]	Loss: 0.000222
2023-05-22 21:16:39.887 | INFO     | trainer_plot:train_epoch:125 - Train: [7680/7970 (97%)]	Loss: 0.000206
2023-05-22 21:16:42.997 | INFO     | trainer_plot:fit:33 - Epoch: 16/50. Train set: Average loss: 0.000277
2023-05-22 21:16:52.708 | INFO     | trainer_plot:fit:43 - Epoch: 16/50. Validation set: Average loss: 0.000000
2023-05-22 21:16:54.067 | INFO     | trainer_plot:train_epoch:125 - Train: [0/7970 (0%)]	Loss: 0.000250
2023-05-22 21:17:04.026 | INFO     | trainer_plot:train_epoch:125 - Train: [640/7970 (8%)]	Loss: 0.000505
2023-05-22 21:17:13.995 | INFO     | trainer_plot:train_epoch:125 - Train: [1280/7970 (16%)]	Loss: 0.000178
2023-05-22 21:17:23.967 | INFO     | trainer_plot:train_epoch:125 - Train: [1920/7970 (24%)]	Loss: 0.000236
2023-05-22 21:17:33.939 | INFO     | trainer_plot:train_epoch:125 - Train: [2560/7970 (32%)]	Loss: 0.000298
2023-05-22 21:17:43.915 | INFO     | trainer_plot:train_epoch:125 - Train: [3200/7970 (40%)]	Loss: 0.000259
2023-05-22 21:17:53.895 | INFO     | trainer_plot:train_epoch:125 - Train: [3840/7970 (48%)]	Loss: 0.000258
2023-05-22 21:18:03.879 | INFO     | trainer_plot:train_epoch:125 - Train: [4480/7970 (56%)]	Loss: 0.000271
2023-05-22 21:18:13.851 | INFO     | trainer_plot:train_epoch:125 - Train: [5120/7970 (65%)]	Loss: 0.000273
2023-05-22 21:18:23.839 | INFO     | trainer_plot:train_epoch:125 - Train: [5760/7970 (73%)]	Loss: 0.000151
2023-05-22 21:18:33.836 | INFO     | trainer_plot:train_epoch:125 - Train: [6400/7970 (81%)]	Loss: 0.000274
2023-05-22 21:18:43.823 | INFO     | trainer_plot:train_epoch:125 - Train: [7040/7970 (89%)]	Loss: 0.000416
2023-05-22 21:18:53.811 | INFO     | trainer_plot:train_epoch:125 - Train: [7680/7970 (97%)]	Loss: 0.000200
2023-05-22 21:18:56.929 | INFO     | trainer_plot:fit:33 - Epoch: 17/50. Train set: Average loss: 0.000270
2023-05-22 21:19:06.677 | INFO     | trainer_plot:fit:43 - Epoch: 17/50. Validation set: Average loss: 0.000000
2023-05-22 21:19:08.043 | INFO     | trainer_plot:train_epoch:125 - Train: [0/7970 (0%)]	Loss: 0.000088
2023-05-22 21:19:18.015 | INFO     | trainer_plot:train_epoch:125 - Train: [640/7970 (8%)]	Loss: 0.000243
2023-05-22 21:19:28.003 | INFO     | trainer_plot:train_epoch:125 - Train: [1280/7970 (16%)]	Loss: 0.000353
2023-05-22 21:19:37.997 | INFO     | trainer_plot:train_epoch:125 - Train: [1920/7970 (24%)]	Loss: 0.000452
2023-05-22 21:19:47.991 | INFO     | trainer_plot:train_epoch:125 - Train: [2560/7970 (32%)]	Loss: 0.000297
2023-05-22 21:19:57.997 | INFO     | trainer_plot:train_epoch:125 - Train: [3200/7970 (40%)]	Loss: 0.000372
2023-05-22 21:20:08.002 | INFO     | trainer_plot:train_epoch:125 - Train: [3840/7970 (48%)]	Loss: 0.000142
2023-05-22 21:20:18.004 | INFO     | trainer_plot:train_epoch:125 - Train: [4480/7970 (56%)]	Loss: 0.000193
2023-05-22 21:20:28.005 | INFO     | trainer_plot:train_epoch:125 - Train: [5120/7970 (65%)]	Loss: 0.000159
2023-05-22 21:20:38.014 | INFO     | trainer_plot:train_epoch:125 - Train: [5760/7970 (73%)]	Loss: 0.000164
2023-05-22 21:20:48.011 | INFO     | trainer_plot:train_epoch:125 - Train: [6400/7970 (81%)]	Loss: 0.000250
2023-05-22 21:20:58.019 | INFO     | trainer_plot:train_epoch:125 - Train: [7040/7970 (89%)]	Loss: 0.000168
2023-05-22 21:21:08.022 | INFO     | trainer_plot:train_epoch:125 - Train: [7680/7970 (97%)]	Loss: 0.000151
2023-05-22 21:21:11.134 | INFO     | trainer_plot:fit:33 - Epoch: 18/50. Train set: Average loss: 0.000243
2023-05-22 21:21:20.893 | INFO     | trainer_plot:fit:43 - Epoch: 18/50. Validation set: Average loss: 0.002208
2023-05-22 21:21:22.277 | INFO     | trainer_plot:train_epoch:125 - Train: [0/7970 (0%)]	Loss: 0.000342
2023-05-22 21:21:32.239 | INFO     | trainer_plot:train_epoch:125 - Train: [640/7970 (8%)]	Loss: 0.000095
2023-05-22 21:21:42.224 | INFO     | trainer_plot:train_epoch:125 - Train: [1280/7970 (16%)]	Loss: 0.000254
2023-05-22 21:21:52.197 | INFO     | trainer_plot:train_epoch:125 - Train: [1920/7970 (24%)]	Loss: 0.000222
2023-05-22 21:22:02.174 | INFO     | trainer_plot:train_epoch:125 - Train: [2560/7970 (32%)]	Loss: 0.000117
2023-05-22 21:22:12.153 | INFO     | trainer_plot:train_epoch:125 - Train: [3200/7970 (40%)]	Loss: 0.000294
2023-05-22 21:22:22.133 | INFO     | trainer_plot:train_epoch:125 - Train: [3840/7970 (48%)]	Loss: 0.000134
2023-05-22 21:22:32.121 | INFO     | trainer_plot:train_epoch:125 - Train: [4480/7970 (56%)]	Loss: 0.000218
2023-05-22 21:22:42.099 | INFO     | trainer_plot:train_epoch:125 - Train: [5120/7970 (65%)]	Loss: 0.000203
2023-05-22 21:22:52.086 | INFO     | trainer_plot:train_epoch:125 - Train: [5760/7970 (73%)]	Loss: 0.000226
2023-05-22 21:23:02.147 | INFO     | trainer_plot:train_epoch:125 - Train: [6400/7970 (81%)]	Loss: 0.000283
2023-05-22 21:23:12.130 | INFO     | trainer_plot:train_epoch:125 - Train: [7040/7970 (89%)]	Loss: 0.000227
2023-05-22 21:23:22.106 | INFO     | trainer_plot:train_epoch:125 - Train: [7680/7970 (97%)]	Loss: 0.000174
2023-05-22 21:23:25.219 | INFO     | trainer_plot:fit:33 - Epoch: 19/50. Train set: Average loss: 0.000208
2023-05-22 21:23:35.042 | INFO     | trainer_plot:fit:43 - Epoch: 19/50. Validation set: Average loss: 0.001009
2023-05-22 21:23:36.428 | INFO     | trainer_plot:train_epoch:125 - Train: [0/7970 (0%)]	Loss: 0.000145
2023-05-22 21:23:46.389 | INFO     | trainer_plot:train_epoch:125 - Train: [640/7970 (8%)]	Loss: 0.000144
2023-05-22 21:23:56.359 | INFO     | trainer_plot:train_epoch:125 - Train: [1280/7970 (16%)]	Loss: 0.000256
2023-05-22 21:24:06.328 | INFO     | trainer_plot:train_epoch:125 - Train: [1920/7970 (24%)]	Loss: 0.000117
2023-05-22 21:24:16.304 | INFO     | trainer_plot:train_epoch:125 - Train: [2560/7970 (32%)]	Loss: 0.000284
2023-05-22 21:24:26.278 | INFO     | trainer_plot:train_epoch:125 - Train: [3200/7970 (40%)]	Loss: 0.000501
2023-05-22 21:24:36.243 | INFO     | trainer_plot:train_epoch:125 - Train: [3840/7970 (48%)]	Loss: 0.000224
2023-05-22 21:24:46.219 | INFO     | trainer_plot:train_epoch:125 - Train: [4480/7970 (56%)]	Loss: 0.000271
2023-05-22 21:24:56.198 | INFO     | trainer_plot:train_epoch:125 - Train: [5120/7970 (65%)]	Loss: 0.000297
2023-05-22 21:25:06.180 | INFO     | trainer_plot:train_epoch:125 - Train: [5760/7970 (73%)]	Loss: 0.000303
2023-05-22 21:25:16.172 | INFO     | trainer_plot:train_epoch:125 - Train: [6400/7970 (81%)]	Loss: 0.000234
2023-05-22 21:25:26.167 | INFO     | trainer_plot:train_epoch:125 - Train: [7040/7970 (89%)]	Loss: 0.000445
2023-05-22 21:25:36.159 | INFO     | trainer_plot:train_epoch:125 - Train: [7680/7970 (97%)]	Loss: 0.000256
2023-05-22 21:25:39.266 | INFO     | trainer_plot:fit:33 - Epoch: 20/50. Train set: Average loss: 0.000271
2023-05-22 21:25:48.993 | INFO     | trainer_plot:fit:43 - Epoch: 20/50. Validation set: Average loss: 0.001008
2023-05-22 21:25:50.423 | INFO     | trainer_plot:train_epoch:125 - Train: [0/7970 (0%)]	Loss: 0.000089
2023-05-22 21:26:00.395 | INFO     | trainer_plot:train_epoch:125 - Train: [640/7970 (8%)]	Loss: 0.000261
2023-05-22 21:26:10.356 | INFO     | trainer_plot:train_epoch:125 - Train: [1280/7970 (16%)]	Loss: 0.000149
2023-05-22 21:26:20.336 | INFO     | trainer_plot:train_epoch:125 - Train: [1920/7970 (24%)]	Loss: 0.000351
2023-05-22 21:26:30.321 | INFO     | trainer_plot:train_epoch:125 - Train: [2560/7970 (32%)]	Loss: 0.000175
2023-05-22 21:26:40.303 | INFO     | trainer_plot:train_epoch:125 - Train: [3200/7970 (40%)]	Loss: 0.000212
2023-05-22 21:26:50.277 | INFO     | trainer_plot:train_epoch:125 - Train: [3840/7970 (48%)]	Loss: 0.000271
2023-05-22 21:27:00.260 | INFO     | trainer_plot:train_epoch:125 - Train: [4480/7970 (56%)]	Loss: 0.000355
2023-05-22 21:27:10.240 | INFO     | trainer_plot:train_epoch:125 - Train: [5120/7970 (65%)]	Loss: 0.000277
2023-05-22 21:27:20.212 | INFO     | trainer_plot:train_epoch:125 - Train: [5760/7970 (73%)]	Loss: 0.000156
2023-05-22 21:27:30.192 | INFO     | trainer_plot:train_epoch:125 - Train: [6400/7970 (81%)]	Loss: 0.000209
2023-05-22 21:27:40.168 | INFO     | trainer_plot:train_epoch:125 - Train: [7040/7970 (89%)]	Loss: 0.000201
2023-05-22 21:27:50.143 | INFO     | trainer_plot:train_epoch:125 - Train: [7680/7970 (97%)]	Loss: 0.000297
2023-05-22 21:27:53.262 | INFO     | trainer_plot:fit:33 - Epoch: 21/50. Train set: Average loss: 0.000242
2023-05-22 21:28:03.030 | INFO     | trainer_plot:fit:43 - Epoch: 21/50. Validation set: Average loss: 0.000000
2023-05-22 21:28:04.416 | INFO     | trainer_plot:train_epoch:125 - Train: [0/7970 (0%)]	Loss: 0.000203
2023-05-22 21:28:14.379 | INFO     | trainer_plot:train_epoch:125 - Train: [640/7970 (8%)]	Loss: 0.000221
2023-05-22 21:28:24.355 | INFO     | trainer_plot:train_epoch:125 - Train: [1280/7970 (16%)]	Loss: 0.000320
2023-05-22 21:28:34.324 | INFO     | trainer_plot:train_epoch:125 - Train: [1920/7970 (24%)]	Loss: 0.000097
2023-05-22 21:28:44.298 | INFO     | trainer_plot:train_epoch:125 - Train: [2560/7970 (32%)]	Loss: 0.000208
2023-05-22 21:28:54.280 | INFO     | trainer_plot:train_epoch:125 - Train: [3200/7970 (40%)]	Loss: 0.000201
2023-05-22 21:29:04.260 | INFO     | trainer_plot:train_epoch:125 - Train: [3840/7970 (48%)]	Loss: 0.000175
2023-05-22 21:29:14.245 | INFO     | trainer_plot:train_epoch:125 - Train: [4480/7970 (56%)]	Loss: 0.000300
2023-05-22 21:29:24.238 | INFO     | trainer_plot:train_epoch:125 - Train: [5120/7970 (65%)]	Loss: 0.000261
2023-05-22 21:29:34.231 | INFO     | trainer_plot:train_epoch:125 - Train: [5760/7970 (73%)]	Loss: 0.000133
2023-05-22 21:29:44.233 | INFO     | trainer_plot:train_epoch:125 - Train: [6400/7970 (81%)]	Loss: 0.000086
2023-05-22 21:29:54.295 | INFO     | trainer_plot:train_epoch:125 - Train: [7040/7970 (89%)]	Loss: 0.000155
2023-05-22 21:30:04.284 | INFO     | trainer_plot:train_epoch:125 - Train: [7680/7970 (97%)]	Loss: 0.000370
2023-05-22 21:30:07.407 | INFO     | trainer_plot:fit:33 - Epoch: 22/50. Train set: Average loss: 0.000207
2023-05-22 21:30:17.170 | INFO     | trainer_plot:fit:43 - Epoch: 22/50. Validation set: Average loss: 0.002274
2023-05-22 21:30:18.543 | INFO     | trainer_plot:train_epoch:125 - Train: [0/7970 (0%)]	Loss: 0.000048
2023-05-22 21:30:28.511 | INFO     | trainer_plot:train_epoch:125 - Train: [640/7970 (8%)]	Loss: 0.000148
2023-05-22 21:30:38.488 | INFO     | trainer_plot:train_epoch:125 - Train: [1280/7970 (16%)]	Loss: 0.000115
2023-05-22 21:30:48.456 | INFO     | trainer_plot:train_epoch:125 - Train: [1920/7970 (24%)]	Loss: 0.000165
2023-05-22 21:30:58.435 | INFO     | trainer_plot:train_epoch:125 - Train: [2560/7970 (32%)]	Loss: 0.000172
2023-05-22 21:31:08.403 | INFO     | trainer_plot:train_epoch:125 - Train: [3200/7970 (40%)]	Loss: 0.000211
2023-05-22 21:31:18.375 | INFO     | trainer_plot:train_epoch:125 - Train: [3840/7970 (48%)]	Loss: 0.000197
2023-05-22 21:31:28.351 | INFO     | trainer_plot:train_epoch:125 - Train: [4480/7970 (56%)]	Loss: 0.000197
2023-05-22 21:31:38.332 | INFO     | trainer_plot:train_epoch:125 - Train: [5120/7970 (65%)]	Loss: 0.000257
2023-05-22 21:31:48.313 | INFO     | trainer_plot:train_epoch:125 - Train: [5760/7970 (73%)]	Loss: 0.000193
2023-05-22 21:31:58.288 | INFO     | trainer_plot:train_epoch:125 - Train: [6400/7970 (81%)]	Loss: 0.000258
2023-05-22 21:32:08.279 | INFO     | trainer_plot:train_epoch:125 - Train: [7040/7970 (89%)]	Loss: 0.000347
2023-05-22 21:32:18.264 | INFO     | trainer_plot:train_epoch:125 - Train: [7680/7970 (97%)]	Loss: 0.000189
2023-05-22 21:32:21.372 | INFO     | trainer_plot:fit:33 - Epoch: 23/50. Train set: Average loss: 0.000203
2023-05-22 21:32:31.159 | INFO     | trainer_plot:fit:43 - Epoch: 23/50. Validation set: Average loss: 0.000000
2023-05-22 21:32:32.529 | INFO     | trainer_plot:train_epoch:125 - Train: [0/7970 (0%)]	Loss: 0.000109
2023-05-22 21:32:42.485 | INFO     | trainer_plot:train_epoch:125 - Train: [640/7970 (8%)]	Loss: 0.000327
2023-05-22 21:32:52.445 | INFO     | trainer_plot:train_epoch:125 - Train: [1280/7970 (16%)]	Loss: 0.000122
2023-05-22 21:33:02.407 | INFO     | trainer_plot:train_epoch:125 - Train: [1920/7970 (24%)]	Loss: 0.000155
2023-05-22 21:33:12.387 | INFO     | trainer_plot:train_epoch:125 - Train: [2560/7970 (32%)]	Loss: 0.000085
2023-05-22 21:33:22.356 | INFO     | trainer_plot:train_epoch:125 - Train: [3200/7970 (40%)]	Loss: 0.000175
2023-05-22 21:33:32.356 | INFO     | trainer_plot:train_epoch:125 - Train: [3840/7970 (48%)]	Loss: 0.000169
2023-05-22 21:33:42.328 | INFO     | trainer_plot:train_epoch:125 - Train: [4480/7970 (56%)]	Loss: 0.000051
2023-05-22 21:33:52.295 | INFO     | trainer_plot:train_epoch:125 - Train: [5120/7970 (65%)]	Loss: 0.000222
2023-05-22 21:34:02.272 | INFO     | trainer_plot:train_epoch:125 - Train: [5760/7970 (73%)]	Loss: 0.000234
2023-05-22 21:34:12.265 | INFO     | trainer_plot:train_epoch:125 - Train: [6400/7970 (81%)]	Loss: 0.000114
2023-05-22 21:34:22.249 | INFO     | trainer_plot:train_epoch:125 - Train: [7040/7970 (89%)]	Loss: 0.000230
2023-05-22 21:34:32.224 | INFO     | trainer_plot:train_epoch:125 - Train: [7680/7970 (97%)]	Loss: 0.000204
2023-05-22 21:34:35.324 | INFO     | trainer_plot:fit:33 - Epoch: 24/50. Train set: Average loss: 0.000175
2023-05-22 21:34:45.057 | INFO     | trainer_plot:fit:43 - Epoch: 24/50. Validation set: Average loss: 0.001534
2023-05-22 21:34:46.414 | INFO     | trainer_plot:train_epoch:125 - Train: [0/7970 (0%)]	Loss: 0.000142
2023-05-22 21:34:56.380 | INFO     | trainer_plot:train_epoch:125 - Train: [640/7970 (8%)]	Loss: 0.000208
2023-05-22 21:35:06.347 | INFO     | trainer_plot:train_epoch:125 - Train: [1280/7970 (16%)]	Loss: 0.000120
2023-05-22 21:35:16.315 | INFO     | trainer_plot:train_epoch:125 - Train: [1920/7970 (24%)]	Loss: 0.000225
2023-05-22 21:35:26.389 | INFO     | trainer_plot:train_epoch:125 - Train: [2560/7970 (32%)]	Loss: 0.000467
2023-05-22 21:35:36.337 | INFO     | trainer_plot:train_epoch:125 - Train: [3200/7970 (40%)]	Loss: 0.000139
2023-05-22 21:35:46.315 | INFO     | trainer_plot:train_epoch:125 - Train: [3840/7970 (48%)]	Loss: 0.000106
2023-05-22 21:35:56.289 | INFO     | trainer_plot:train_epoch:125 - Train: [4480/7970 (56%)]	Loss: 0.000233
2023-05-22 21:36:06.273 | INFO     | trainer_plot:train_epoch:125 - Train: [5120/7970 (65%)]	Loss: 0.000102
2023-05-22 21:36:16.266 | INFO     | trainer_plot:train_epoch:125 - Train: [5760/7970 (73%)]	Loss: 0.000254
2023-05-22 21:36:26.254 | INFO     | trainer_plot:train_epoch:125 - Train: [6400/7970 (81%)]	Loss: 0.000115
2023-05-22 21:36:36.232 | INFO     | trainer_plot:train_epoch:125 - Train: [7040/7970 (89%)]	Loss: 0.000135
2023-05-22 21:36:46.210 | INFO     | trainer_plot:train_epoch:125 - Train: [7680/7970 (97%)]	Loss: 0.000268
2023-05-22 21:36:49.314 | INFO     | trainer_plot:fit:33 - Epoch: 25/50. Train set: Average loss: 0.000193
2023-05-22 21:36:59.076 | INFO     | trainer_plot:fit:43 - Epoch: 25/50. Validation set: Average loss: 0.000000
2023-05-22 21:37:00.445 | INFO     | trainer_plot:train_epoch:125 - Train: [0/7970 (0%)]	Loss: 0.000010
2023-05-22 21:37:10.411 | INFO     | trainer_plot:train_epoch:125 - Train: [640/7970 (8%)]	Loss: 0.000089
2023-05-22 21:37:20.382 | INFO     | trainer_plot:train_epoch:125 - Train: [1280/7970 (16%)]	Loss: 0.000297
2023-05-22 21:37:30.347 | INFO     | trainer_plot:train_epoch:125 - Train: [1920/7970 (24%)]	Loss: 0.000269
2023-05-22 21:37:40.325 | INFO     | trainer_plot:train_epoch:125 - Train: [2560/7970 (32%)]	Loss: 0.000256
2023-05-22 21:37:50.311 | INFO     | trainer_plot:train_epoch:125 - Train: [3200/7970 (40%)]	Loss: 0.000217
2023-05-22 21:38:00.290 | INFO     | trainer_plot:train_epoch:125 - Train: [3840/7970 (48%)]	Loss: 0.000244
2023-05-22 21:38:10.282 | INFO     | trainer_plot:train_epoch:125 - Train: [4480/7970 (56%)]	Loss: 0.000181
2023-05-22 21:38:20.274 | INFO     | trainer_plot:train_epoch:125 - Train: [5120/7970 (65%)]	Loss: 0.000191
2023-05-22 21:38:30.277 | INFO     | trainer_plot:train_epoch:125 - Train: [5760/7970 (73%)]	Loss: 0.000264
2023-05-22 21:38:40.274 | INFO     | trainer_plot:train_epoch:125 - Train: [6400/7970 (81%)]	Loss: 0.000107
2023-05-22 21:38:50.257 | INFO     | trainer_plot:train_epoch:125 - Train: [7040/7970 (89%)]	Loss: 0.000095
2023-05-22 21:39:00.255 | INFO     | trainer_plot:train_epoch:125 - Train: [7680/7970 (97%)]	Loss: 0.000333
2023-05-22 21:39:03.370 | INFO     | trainer_plot:fit:33 - Epoch: 26/50. Train set: Average loss: 0.000208
2023-05-22 21:39:13.128 | INFO     | trainer_plot:fit:43 - Epoch: 26/50. Validation set: Average loss: 0.001423
2023-05-22 21:39:14.505 | INFO     | trainer_plot:train_epoch:125 - Train: [0/7970 (0%)]	Loss: 0.000516
2023-05-22 21:39:24.464 | INFO     | trainer_plot:train_epoch:125 - Train: [640/7970 (8%)]	Loss: 0.000143
2023-05-22 21:39:34.437 | INFO     | trainer_plot:train_epoch:125 - Train: [1280/7970 (16%)]	Loss: 0.000243
2023-05-22 21:39:44.417 | INFO     | trainer_plot:train_epoch:125 - Train: [1920/7970 (24%)]	Loss: 0.000078
2023-05-22 21:39:54.404 | INFO     | trainer_plot:train_epoch:125 - Train: [2560/7970 (32%)]	Loss: 0.000060
2023-05-22 21:40:04.393 | INFO     | trainer_plot:train_epoch:125 - Train: [3200/7970 (40%)]	Loss: 0.000140
2023-05-22 21:40:14.379 | INFO     | trainer_plot:train_epoch:125 - Train: [3840/7970 (48%)]	Loss: 0.000247
2023-05-22 21:40:24.361 | INFO     | trainer_plot:train_epoch:125 - Train: [4480/7970 (56%)]	Loss: 0.000237
2023-05-22 21:40:34.349 | INFO     | trainer_plot:train_epoch:125 - Train: [5120/7970 (65%)]	Loss: 0.000366
2023-05-22 21:40:44.330 | INFO     | trainer_plot:train_epoch:125 - Train: [5760/7970 (73%)]	Loss: 0.000349
2023-05-22 21:40:54.319 | INFO     | trainer_plot:train_epoch:125 - Train: [6400/7970 (81%)]	Loss: 0.000109
2023-05-22 21:41:04.298 | INFO     | trainer_plot:train_epoch:125 - Train: [7040/7970 (89%)]	Loss: 0.000192
2023-05-22 21:41:14.299 | INFO     | trainer_plot:train_epoch:125 - Train: [7680/7970 (97%)]	Loss: 0.000063
2023-05-22 21:41:17.415 | INFO     | trainer_plot:fit:33 - Epoch: 27/50. Train set: Average loss: 0.000185
2023-05-22 21:41:27.155 | INFO     | trainer_plot:fit:43 - Epoch: 27/50. Validation set: Average loss: 0.001825
2023-05-22 21:41:28.533 | INFO     | trainer_plot:train_epoch:125 - Train: [0/7970 (0%)]	Loss: 0.000288
2023-05-22 21:41:38.501 | INFO     | trainer_plot:train_epoch:125 - Train: [640/7970 (8%)]	Loss: 0.000186
2023-05-22 21:41:48.470 | INFO     | trainer_plot:train_epoch:125 - Train: [1280/7970 (16%)]	Loss: 0.000079
2023-05-22 21:41:58.443 | INFO     | trainer_plot:train_epoch:125 - Train: [1920/7970 (24%)]	Loss: 0.000042
2023-05-22 21:42:08.424 | INFO     | trainer_plot:train_epoch:125 - Train: [2560/7970 (32%)]	Loss: 0.000081
2023-05-22 21:42:18.416 | INFO     | trainer_plot:train_epoch:125 - Train: [3200/7970 (40%)]	Loss: 0.000106
2023-05-22 21:42:28.403 | INFO     | trainer_plot:train_epoch:125 - Train: [3840/7970 (48%)]	Loss: 0.000188
2023-05-22 21:42:38.381 | INFO     | trainer_plot:train_epoch:125 - Train: [4480/7970 (56%)]	Loss: 0.000088
2023-05-22 21:42:48.365 | INFO     | trainer_plot:train_epoch:125 - Train: [5120/7970 (65%)]	Loss: 0.000120
2023-05-22 21:42:58.351 | INFO     | trainer_plot:train_epoch:125 - Train: [5760/7970 (73%)]	Loss: 0.000280
2023-05-22 21:43:08.348 | INFO     | trainer_plot:train_epoch:125 - Train: [6400/7970 (81%)]	Loss: 0.000151
2023-05-22 21:43:18.337 | INFO     | trainer_plot:train_epoch:125 - Train: [7040/7970 (89%)]	Loss: 0.000200
2023-05-22 21:43:28.329 | INFO     | trainer_plot:train_epoch:125 - Train: [7680/7970 (97%)]	Loss: 0.000134
2023-05-22 21:43:31.446 | INFO     | trainer_plot:fit:33 - Epoch: 28/50. Train set: Average loss: 0.000145
2023-05-22 21:43:41.260 | INFO     | trainer_plot:fit:43 - Epoch: 28/50. Validation set: Average loss: 0.000000
2023-05-22 21:43:42.643 | INFO     | trainer_plot:train_epoch:125 - Train: [0/7970 (0%)]	Loss: 0.000239
2023-05-22 21:43:52.604 | INFO     | trainer_plot:train_epoch:125 - Train: [640/7970 (8%)]	Loss: 0.000236
2023-05-22 21:44:02.575 | INFO     | trainer_plot:train_epoch:125 - Train: [1280/7970 (16%)]	Loss: 0.000172
2023-05-22 21:44:12.552 | INFO     | trainer_plot:train_epoch:125 - Train: [1920/7970 (24%)]	Loss: 0.000313
2023-05-22 21:44:22.532 | INFO     | trainer_plot:train_epoch:125 - Train: [2560/7970 (32%)]	Loss: 0.000147
2023-05-22 21:44:32.521 | INFO     | trainer_plot:train_epoch:125 - Train: [3200/7970 (40%)]	Loss: 0.000237
2023-05-22 21:44:42.515 | INFO     | trainer_plot:train_epoch:125 - Train: [3840/7970 (48%)]	Loss: 0.000319
2023-05-22 21:44:52.495 | INFO     | trainer_plot:train_epoch:125 - Train: [4480/7970 (56%)]	Loss: 0.000351
2023-05-22 21:45:02.480 | INFO     | trainer_plot:train_epoch:125 - Train: [5120/7970 (65%)]	Loss: 0.000101
2023-05-22 21:45:12.467 | INFO     | trainer_plot:train_epoch:125 - Train: [5760/7970 (73%)]	Loss: 0.000097
2023-05-22 21:45:22.445 | INFO     | trainer_plot:train_epoch:125 - Train: [6400/7970 (81%)]	Loss: 0.000122
2023-05-22 21:45:32.504 | INFO     | trainer_plot:train_epoch:125 - Train: [7040/7970 (89%)]	Loss: 0.000087
2023-05-22 21:45:42.487 | INFO     | trainer_plot:train_epoch:125 - Train: [7680/7970 (97%)]	Loss: 0.000184
2023-05-22 21:45:45.596 | INFO     | trainer_plot:fit:33 - Epoch: 29/50. Train set: Average loss: 0.000196
2023-05-22 21:45:55.349 | INFO     | trainer_plot:fit:43 - Epoch: 29/50. Validation set: Average loss: 0.000000
2023-05-22 21:45:56.703 | INFO     | trainer_plot:train_epoch:125 - Train: [0/7970 (0%)]	Loss: 0.000019
2023-05-22 21:46:06.664 | INFO     | trainer_plot:train_epoch:125 - Train: [640/7970 (8%)]	Loss: 0.000120
2023-05-22 21:46:16.638 | INFO     | trainer_plot:train_epoch:125 - Train: [1280/7970 (16%)]	Loss: 0.000060
2023-05-22 21:46:26.622 | INFO     | trainer_plot:train_epoch:125 - Train: [1920/7970 (24%)]	Loss: 0.000449
2023-05-22 21:46:36.604 | INFO     | trainer_plot:train_epoch:125 - Train: [2560/7970 (32%)]	Loss: 0.000111
2023-05-22 21:46:46.573 | INFO     | trainer_plot:train_epoch:125 - Train: [3200/7970 (40%)]	Loss: 0.000103
2023-05-22 21:46:56.552 | INFO     | trainer_plot:train_epoch:125 - Train: [3840/7970 (48%)]	Loss: 0.000249
2023-05-22 21:47:06.539 | INFO     | trainer_plot:train_epoch:125 - Train: [4480/7970 (56%)]	Loss: 0.000216
2023-05-22 21:47:16.522 | INFO     | trainer_plot:train_epoch:125 - Train: [5120/7970 (65%)]	Loss: 0.000307
2023-05-22 21:47:26.500 | INFO     | trainer_plot:train_epoch:125 - Train: [5760/7970 (73%)]	Loss: 0.000127
2023-05-22 21:47:36.488 | INFO     | trainer_plot:train_epoch:125 - Train: [6400/7970 (81%)]	Loss: 0.000121
2023-05-22 21:47:46.462 | INFO     | trainer_plot:train_epoch:125 - Train: [7040/7970 (89%)]	Loss: 0.000097
2023-05-22 21:47:56.441 | INFO     | trainer_plot:train_epoch:125 - Train: [7680/7970 (97%)]	Loss: 0.000278
2023-05-22 21:47:59.561 | INFO     | trainer_plot:fit:33 - Epoch: 30/50. Train set: Average loss: 0.000184
2023-05-22 21:48:09.280 | INFO     | trainer_plot:fit:43 - Epoch: 30/50. Validation set: Average loss: 0.000542
2023-05-22 21:48:10.769 | INFO     | trainer_plot:train_epoch:125 - Train: [0/7970 (0%)]	Loss: 0.000000
2023-05-22 21:48:20.728 | INFO     | trainer_plot:train_epoch:125 - Train: [640/7970 (8%)]	Loss: 0.000114
2023-05-22 21:48:30.705 | INFO     | trainer_plot:train_epoch:125 - Train: [1280/7970 (16%)]	Loss: 0.000187
2023-05-22 21:48:40.673 | INFO     | trainer_plot:train_epoch:125 - Train: [1920/7970 (24%)]	Loss: 0.000246
2023-05-22 21:48:50.660 | INFO     | trainer_plot:train_epoch:125 - Train: [2560/7970 (32%)]	Loss: 0.000251
2023-05-22 21:49:00.642 | INFO     | trainer_plot:train_epoch:125 - Train: [3200/7970 (40%)]	Loss: 0.000213
2023-05-22 21:49:10.625 | INFO     | trainer_plot:train_epoch:125 - Train: [3840/7970 (48%)]	Loss: 0.000131
2023-05-22 21:49:20.602 | INFO     | trainer_plot:train_epoch:125 - Train: [4480/7970 (56%)]	Loss: 0.000056
2023-05-22 21:49:30.580 | INFO     | trainer_plot:train_epoch:125 - Train: [5120/7970 (65%)]	Loss: 0.000252
2023-05-22 21:49:40.573 | INFO     | trainer_plot:train_epoch:125 - Train: [5760/7970 (73%)]	Loss: 0.000239
2023-05-22 21:49:50.555 | INFO     | trainer_plot:train_epoch:125 - Train: [6400/7970 (81%)]	Loss: 0.000127
2023-05-22 21:50:00.543 | INFO     | trainer_plot:train_epoch:125 - Train: [7040/7970 (89%)]	Loss: 0.000109
2023-05-22 21:50:10.531 | INFO     | trainer_plot:train_epoch:125 - Train: [7680/7970 (97%)]	Loss: 0.000166
2023-05-22 21:50:13.649 | INFO     | trainer_plot:fit:33 - Epoch: 31/50. Train set: Average loss: 0.000175
2023-05-22 21:50:23.412 | INFO     | trainer_plot:fit:43 - Epoch: 31/50. Validation set: Average loss: 0.002751
2023-05-22 21:50:24.785 | INFO     | trainer_plot:train_epoch:125 - Train: [0/7970 (0%)]	Loss: 0.000069
2023-05-22 21:50:34.760 | INFO     | trainer_plot:train_epoch:125 - Train: [640/7970 (8%)]	Loss: 0.000029
2023-05-22 21:50:44.724 | INFO     | trainer_plot:train_epoch:125 - Train: [1280/7970 (16%)]	Loss: 0.000099
2023-05-22 21:50:54.783 | INFO     | trainer_plot:train_epoch:125 - Train: [1920/7970 (24%)]	Loss: 0.000086
2023-05-22 21:51:04.757 | INFO     | trainer_plot:train_epoch:125 - Train: [2560/7970 (32%)]	Loss: 0.000157
2023-05-22 21:51:14.725 | INFO     | trainer_plot:train_epoch:125 - Train: [3200/7970 (40%)]	Loss: 0.000199
2023-05-22 21:51:24.700 | INFO     | trainer_plot:train_epoch:125 - Train: [3840/7970 (48%)]	Loss: 0.000176
2023-05-22 21:51:34.680 | INFO     | trainer_plot:train_epoch:125 - Train: [4480/7970 (56%)]	Loss: 0.000053
2023-05-22 21:51:44.657 | INFO     | trainer_plot:train_epoch:125 - Train: [5120/7970 (65%)]	Loss: 0.000179
2023-05-22 21:51:54.631 | INFO     | trainer_plot:train_epoch:125 - Train: [5760/7970 (73%)]	Loss: 0.000040
2023-05-22 21:52:04.619 | INFO     | trainer_plot:train_epoch:125 - Train: [6400/7970 (81%)]	Loss: 0.000197
2023-05-22 21:52:14.607 | INFO     | trainer_plot:train_epoch:125 - Train: [7040/7970 (89%)]	Loss: 0.000156
2023-05-22 21:52:24.587 | INFO     | trainer_plot:train_epoch:125 - Train: [7680/7970 (97%)]	Loss: 0.000187
2023-05-22 21:52:27.675 | INFO     | trainer_plot:fit:33 - Epoch: 32/50. Train set: Average loss: 0.000133
2023-05-22 21:52:37.442 | INFO     | trainer_plot:fit:43 - Epoch: 32/50. Validation set: Average loss: 0.001023
2023-05-22 21:52:38.803 | INFO     | trainer_plot:train_epoch:125 - Train: [0/7970 (0%)]	Loss: 0.000375
2023-05-22 21:52:48.772 | INFO     | trainer_plot:train_epoch:125 - Train: [640/7970 (8%)]	Loss: 0.000149
2023-05-22 21:52:58.739 | INFO     | trainer_plot:train_epoch:125 - Train: [1280/7970 (16%)]	Loss: 0.000251
2023-05-22 21:53:08.724 | INFO     | trainer_plot:train_epoch:125 - Train: [1920/7970 (24%)]	Loss: 0.000098
2023-05-22 21:53:18.705 | INFO     | trainer_plot:train_epoch:125 - Train: [2560/7970 (32%)]	Loss: 0.000085
2023-05-22 21:53:28.680 | INFO     | trainer_plot:train_epoch:125 - Train: [3200/7970 (40%)]	Loss: 0.000177
2023-05-22 21:53:38.679 | INFO     | trainer_plot:train_epoch:125 - Train: [3840/7970 (48%)]	Loss: 0.000078
2023-05-22 21:53:48.660 | INFO     | trainer_plot:train_epoch:125 - Train: [4480/7970 (56%)]	Loss: 0.000140
2023-05-22 21:53:58.647 | INFO     | trainer_plot:train_epoch:125 - Train: [5120/7970 (65%)]	Loss: 0.000103
2023-05-22 21:54:08.635 | INFO     | trainer_plot:train_epoch:125 - Train: [5760/7970 (73%)]	Loss: 0.000090
2023-05-22 21:54:18.611 | INFO     | trainer_plot:train_epoch:125 - Train: [6400/7970 (81%)]	Loss: 0.000199
2023-05-22 21:54:28.608 | INFO     | trainer_plot:train_epoch:125 - Train: [7040/7970 (89%)]	Loss: 0.000281
2023-05-22 21:54:38.597 | INFO     | trainer_plot:train_epoch:125 - Train: [7680/7970 (97%)]	Loss: 0.000156
2023-05-22 21:54:41.714 | INFO     | trainer_plot:fit:33 - Epoch: 33/50. Train set: Average loss: 0.000154
2023-05-22 21:54:51.429 | INFO     | trainer_plot:fit:43 - Epoch: 33/50. Validation set: Average loss: 0.000504
2023-05-22 21:54:52.809 | INFO     | trainer_plot:train_epoch:125 - Train: [0/7970 (0%)]	Loss: 0.000918
2023-05-22 21:55:02.775 | INFO     | trainer_plot:train_epoch:125 - Train: [640/7970 (8%)]	Loss: 0.000348
2023-05-22 21:55:12.745 | INFO     | trainer_plot:train_epoch:125 - Train: [1280/7970 (16%)]	Loss: 0.000044
2023-05-22 21:55:22.718 | INFO     | trainer_plot:train_epoch:125 - Train: [1920/7970 (24%)]	Loss: 0.000183
2023-05-22 21:55:32.706 | INFO     | trainer_plot:train_epoch:125 - Train: [2560/7970 (32%)]	Loss: 0.000219
2023-05-22 21:55:42.683 | INFO     | trainer_plot:train_epoch:125 - Train: [3200/7970 (40%)]	Loss: 0.000248
2023-05-22 21:55:52.666 | INFO     | trainer_plot:train_epoch:125 - Train: [3840/7970 (48%)]	Loss: 0.000166
2023-05-22 21:56:02.648 | INFO     | trainer_plot:train_epoch:125 - Train: [4480/7970 (56%)]	Loss: 0.000277
2023-05-22 21:56:12.627 | INFO     | trainer_plot:train_epoch:125 - Train: [5120/7970 (65%)]	Loss: 0.000076
2023-05-22 21:56:22.628 | INFO     | trainer_plot:train_epoch:125 - Train: [5760/7970 (73%)]	Loss: 0.000070
2023-05-22 21:56:32.609 | INFO     | trainer_plot:train_epoch:125 - Train: [6400/7970 (81%)]	Loss: 0.000128
2023-05-22 21:56:42.600 | INFO     | trainer_plot:train_epoch:125 - Train: [7040/7970 (89%)]	Loss: 0.000204
2023-05-22 21:56:52.591 | INFO     | trainer_plot:train_epoch:125 - Train: [7680/7970 (97%)]	Loss: 0.000092
2023-05-22 21:56:55.690 | INFO     | trainer_plot:fit:33 - Epoch: 34/50. Train set: Average loss: 0.000176
2023-05-22 21:57:05.452 | INFO     | trainer_plot:fit:43 - Epoch: 34/50. Validation set: Average loss: 0.001982
2023-05-22 21:57:06.836 | INFO     | trainer_plot:train_epoch:125 - Train: [0/7970 (0%)]	Loss: 0.000035
2023-05-22 21:57:16.805 | INFO     | trainer_plot:train_epoch:125 - Train: [640/7970 (8%)]	Loss: 0.000148
2023-05-22 21:57:26.779 | INFO     | trainer_plot:train_epoch:125 - Train: [1280/7970 (16%)]	Loss: 0.000180
2023-05-22 21:57:36.758 | INFO     | trainer_plot:train_epoch:125 - Train: [1920/7970 (24%)]	Loss: 0.000085
2023-05-22 21:57:46.741 | INFO     | trainer_plot:train_epoch:125 - Train: [2560/7970 (32%)]	Loss: 0.000094
2023-05-22 21:57:56.722 | INFO     | trainer_plot:train_epoch:125 - Train: [3200/7970 (40%)]	Loss: 0.000144
2023-05-22 21:58:06.721 | INFO     | trainer_plot:train_epoch:125 - Train: [3840/7970 (48%)]	Loss: 0.000203
2023-05-22 21:58:16.706 | INFO     | trainer_plot:train_epoch:125 - Train: [4480/7970 (56%)]	Loss: 0.000075
2023-05-22 21:58:26.694 | INFO     | trainer_plot:train_epoch:125 - Train: [5120/7970 (65%)]	Loss: 0.000296
2023-05-22 21:58:36.691 | INFO     | trainer_plot:train_epoch:125 - Train: [5760/7970 (73%)]	Loss: 0.000309
2023-05-22 21:58:46.687 | INFO     | trainer_plot:train_epoch:125 - Train: [6400/7970 (81%)]	Loss: 0.000237
2023-05-22 21:58:56.668 | INFO     | trainer_plot:train_epoch:125 - Train: [7040/7970 (89%)]	Loss: 0.000039
2023-05-22 21:59:06.655 | INFO     | trainer_plot:train_epoch:125 - Train: [7680/7970 (97%)]	Loss: 0.000147
2023-05-22 21:59:09.780 | INFO     | trainer_plot:fit:33 - Epoch: 35/50. Train set: Average loss: 0.000163
2023-05-22 21:59:19.551 | INFO     | trainer_plot:fit:43 - Epoch: 35/50. Validation set: Average loss: 0.000243
2023-05-22 21:59:20.924 | INFO     | trainer_plot:train_epoch:125 - Train: [0/7970 (0%)]	Loss: 0.000286
2023-05-22 21:59:30.891 | INFO     | trainer_plot:train_epoch:125 - Train: [640/7970 (8%)]	Loss: 0.000204
2023-05-22 21:59:40.864 | INFO     | trainer_plot:train_epoch:125 - Train: [1280/7970 (16%)]	Loss: 0.000269
2023-05-22 21:59:50.837 | INFO     | trainer_plot:train_epoch:125 - Train: [1920/7970 (24%)]	Loss: 0.000331
2023-05-22 22:00:00.823 | INFO     | trainer_plot:train_epoch:125 - Train: [2560/7970 (32%)]	Loss: 0.000153
2023-05-22 22:00:10.800 | INFO     | trainer_plot:train_epoch:125 - Train: [3200/7970 (40%)]	Loss: 0.000165
2023-05-22 22:00:20.785 | INFO     | trainer_plot:train_epoch:125 - Train: [3840/7970 (48%)]	Loss: 0.000260
2023-05-22 22:00:30.769 | INFO     | trainer_plot:train_epoch:125 - Train: [4480/7970 (56%)]	Loss: 0.000274
2023-05-22 22:00:40.753 | INFO     | trainer_plot:train_epoch:125 - Train: [5120/7970 (65%)]	Loss: 0.000127
2023-05-22 22:00:50.747 | INFO     | trainer_plot:train_epoch:125 - Train: [5760/7970 (73%)]	Loss: 0.000088
2023-05-22 22:01:00.804 | INFO     | trainer_plot:train_epoch:125 - Train: [6400/7970 (81%)]	Loss: 0.000119
2023-05-22 22:01:10.794 | INFO     | trainer_plot:train_epoch:125 - Train: [7040/7970 (89%)]	Loss: 0.000123
2023-05-22 22:01:20.789 | INFO     | trainer_plot:train_epoch:125 - Train: [7680/7970 (97%)]	Loss: 0.000201
2023-05-22 22:01:23.905 | INFO     | trainer_plot:fit:33 - Epoch: 36/50. Train set: Average loss: 0.000192
2023-05-22 22:01:33.685 | INFO     | trainer_plot:fit:43 - Epoch: 36/50. Validation set: Average loss: 0.001707
2023-05-22 22:01:35.039 | INFO     | trainer_plot:train_epoch:125 - Train: [0/7970 (0%)]	Loss: 0.000211
2023-05-22 22:01:45.004 | INFO     | trainer_plot:train_epoch:125 - Train: [640/7970 (8%)]	Loss: 0.000048
2023-05-22 22:01:54.992 | INFO     | trainer_plot:train_epoch:125 - Train: [1280/7970 (16%)]	Loss: 0.000166
2023-05-22 22:02:04.963 | INFO     | trainer_plot:train_epoch:125 - Train: [1920/7970 (24%)]	Loss: 0.000250
2023-05-22 22:02:14.942 | INFO     | trainer_plot:train_epoch:125 - Train: [2560/7970 (32%)]	Loss: 0.000282
2023-05-22 22:02:24.931 | INFO     | trainer_plot:train_epoch:125 - Train: [3200/7970 (40%)]	Loss: 0.000190
2023-05-22 22:02:34.918 | INFO     | trainer_plot:train_epoch:125 - Train: [3840/7970 (48%)]	Loss: 0.000183
2023-05-22 22:02:44.911 | INFO     | trainer_plot:train_epoch:125 - Train: [4480/7970 (56%)]	Loss: 0.000239
2023-05-22 22:02:54.903 | INFO     | trainer_plot:train_epoch:125 - Train: [5120/7970 (65%)]	Loss: 0.000149
2023-05-22 22:03:04.891 | INFO     | trainer_plot:train_epoch:125 - Train: [5760/7970 (73%)]	Loss: 0.000221
2023-05-22 22:03:14.884 | INFO     | trainer_plot:train_epoch:125 - Train: [6400/7970 (81%)]	Loss: 0.000164
2023-05-22 22:03:24.883 | INFO     | trainer_plot:train_epoch:125 - Train: [7040/7970 (89%)]	Loss: 0.000136
2023-05-22 22:03:34.878 | INFO     | trainer_plot:train_epoch:125 - Train: [7680/7970 (97%)]	Loss: 0.000123
2023-05-22 22:03:38.007 | INFO     | trainer_plot:fit:33 - Epoch: 37/50. Train set: Average loss: 0.000177
2023-05-22 22:03:47.785 | INFO     | trainer_plot:fit:43 - Epoch: 37/50. Validation set: Average loss: 0.002972
2023-05-22 22:03:49.168 | INFO     | trainer_plot:train_epoch:125 - Train: [0/7970 (0%)]	Loss: 0.000057
2023-05-22 22:03:59.138 | INFO     | trainer_plot:train_epoch:125 - Train: [640/7970 (8%)]	Loss: 0.000109
2023-05-22 22:04:09.123 | INFO     | trainer_plot:train_epoch:125 - Train: [1280/7970 (16%)]	Loss: 0.000236
2023-05-22 22:04:19.108 | INFO     | trainer_plot:train_epoch:125 - Train: [1920/7970 (24%)]	Loss: 0.000265
2023-05-22 22:04:29.087 | INFO     | trainer_plot:train_epoch:125 - Train: [2560/7970 (32%)]	Loss: 0.000065
2023-05-22 22:04:39.070 | INFO     | trainer_plot:train_epoch:125 - Train: [3200/7970 (40%)]	Loss: 0.000191
2023-05-22 22:04:49.068 | INFO     | trainer_plot:train_epoch:125 - Train: [3840/7970 (48%)]	Loss: 0.000182
2023-05-22 22:04:59.051 | INFO     | trainer_plot:train_epoch:125 - Train: [4480/7970 (56%)]	Loss: 0.000040
2023-05-22 22:05:09.040 | INFO     | trainer_plot:train_epoch:125 - Train: [5120/7970 (65%)]	Loss: 0.000072
2023-05-22 22:05:19.023 | INFO     | trainer_plot:train_epoch:125 - Train: [5760/7970 (73%)]	Loss: 0.000233
2023-05-22 22:05:29.012 | INFO     | trainer_plot:train_epoch:125 - Train: [6400/7970 (81%)]	Loss: 0.000203
2023-05-22 22:05:38.999 | INFO     | trainer_plot:train_epoch:125 - Train: [7040/7970 (89%)]	Loss: 0.000123
2023-05-22 22:05:48.989 | INFO     | trainer_plot:train_epoch:125 - Train: [7680/7970 (97%)]	Loss: 0.000191
2023-05-22 22:05:52.111 | INFO     | trainer_plot:fit:33 - Epoch: 38/50. Train set: Average loss: 0.000157
2023-05-22 22:06:01.881 | INFO     | trainer_plot:fit:43 - Epoch: 38/50. Validation set: Average loss: 0.000000
2023-05-22 22:06:03.262 | INFO     | trainer_plot:train_epoch:125 - Train: [0/7970 (0%)]	Loss: 0.000023
2023-05-22 22:06:13.224 | INFO     | trainer_plot:train_epoch:125 - Train: [640/7970 (8%)]	Loss: 0.000198
2023-05-22 22:06:23.200 | INFO     | trainer_plot:train_epoch:125 - Train: [1280/7970 (16%)]	Loss: 0.000219
2023-05-22 22:06:33.182 | INFO     | trainer_plot:train_epoch:125 - Train: [1920/7970 (24%)]	Loss: 0.000265
2023-05-22 22:06:43.235 | INFO     | trainer_plot:train_epoch:125 - Train: [2560/7970 (32%)]	Loss: 0.000154
2023-05-22 22:06:53.216 | INFO     | trainer_plot:train_epoch:125 - Train: [3200/7970 (40%)]	Loss: 0.000185
2023-05-22 22:07:03.202 | INFO     | trainer_plot:train_epoch:125 - Train: [3840/7970 (48%)]	Loss: 0.000153
2023-05-22 22:07:13.196 | INFO     | trainer_plot:train_epoch:125 - Train: [4480/7970 (56%)]	Loss: 0.000311
2023-05-22 22:07:23.189 | INFO     | trainer_plot:train_epoch:125 - Train: [5120/7970 (65%)]	Loss: 0.000210
2023-05-22 22:07:33.211 | INFO     | trainer_plot:train_epoch:125 - Train: [5760/7970 (73%)]	Loss: 0.000215
2023-05-22 22:07:43.208 | INFO     | trainer_plot:train_epoch:125 - Train: [6400/7970 (81%)]	Loss: 0.000505
2023-05-22 22:07:53.218 | INFO     | trainer_plot:train_epoch:125 - Train: [7040/7970 (89%)]	Loss: 0.000139
2023-05-22 22:08:03.223 | INFO     | trainer_plot:train_epoch:125 - Train: [7680/7970 (97%)]	Loss: 0.000431
2023-05-22 22:08:06.340 | INFO     | trainer_plot:fit:33 - Epoch: 39/50. Train set: Average loss: 0.000270
2023-05-22 22:08:16.142 | INFO     | trainer_plot:fit:43 - Epoch: 39/50. Validation set: Average loss: 0.001268
2023-05-22 22:08:17.518 | INFO     | trainer_plot:train_epoch:125 - Train: [0/7970 (0%)]	Loss: 0.000016
2023-05-22 22:08:27.484 | INFO     | trainer_plot:train_epoch:125 - Train: [640/7970 (8%)]	Loss: 0.000164
2023-05-22 22:08:37.484 | INFO     | trainer_plot:train_epoch:125 - Train: [1280/7970 (16%)]	Loss: 0.000215
2023-05-22 22:08:47.472 | INFO     | trainer_plot:train_epoch:125 - Train: [1920/7970 (24%)]	Loss: 0.000095
2023-05-22 22:08:57.476 | INFO     | trainer_plot:train_epoch:125 - Train: [2560/7970 (32%)]	Loss: 0.000197
2023-05-22 22:09:07.470 | INFO     | trainer_plot:train_epoch:125 - Train: [3200/7970 (40%)]	Loss: 0.000152
2023-05-22 22:09:17.470 | INFO     | trainer_plot:train_epoch:125 - Train: [3840/7970 (48%)]	Loss: 0.000128
2023-05-22 22:09:27.448 | INFO     | trainer_plot:train_epoch:125 - Train: [4480/7970 (56%)]	Loss: 0.000061
2023-05-22 22:09:37.439 | INFO     | trainer_plot:train_epoch:125 - Train: [5120/7970 (65%)]	Loss: 0.000249
2023-05-22 22:09:47.424 | INFO     | trainer_plot:train_epoch:125 - Train: [5760/7970 (73%)]	Loss: 0.000177
2023-05-22 22:09:57.399 | INFO     | trainer_plot:train_epoch:125 - Train: [6400/7970 (81%)]	Loss: 0.000061
2023-05-22 22:10:07.397 | INFO     | trainer_plot:train_epoch:125 - Train: [7040/7970 (89%)]	Loss: 0.000130
2023-05-22 22:10:17.384 | INFO     | trainer_plot:train_epoch:125 - Train: [7680/7970 (97%)]	Loss: 0.000159
2023-05-22 22:10:20.503 | INFO     | trainer_plot:fit:33 - Epoch: 40/50. Train set: Average loss: 0.000146
2023-05-22 22:10:30.206 | INFO     | trainer_plot:fit:43 - Epoch: 40/50. Validation set: Average loss: 0.000037
2023-05-22 22:10:31.714 | INFO     | trainer_plot:train_epoch:125 - Train: [0/7970 (0%)]	Loss: 0.000038
2023-05-22 22:10:41.686 | INFO     | trainer_plot:train_epoch:125 - Train: [640/7970 (8%)]	Loss: 0.000110
2023-05-22 22:10:51.676 | INFO     | trainer_plot:train_epoch:125 - Train: [1280/7970 (16%)]	Loss: 0.000124
2023-05-22 22:11:01.657 | INFO     | trainer_plot:train_epoch:125 - Train: [1920/7970 (24%)]	Loss: 0.000153
2023-05-22 22:11:11.649 | INFO     | trainer_plot:train_epoch:125 - Train: [2560/7970 (32%)]	Loss: 0.000232
2023-05-22 22:11:21.632 | INFO     | trainer_plot:train_epoch:125 - Train: [3200/7970 (40%)]	Loss: 0.000145
2023-05-22 22:11:31.630 | INFO     | trainer_plot:train_epoch:125 - Train: [3840/7970 (48%)]	Loss: 0.000047
2023-05-22 22:11:41.624 | INFO     | trainer_plot:train_epoch:125 - Train: [4480/7970 (56%)]	Loss: 0.000196
2023-05-22 22:11:51.607 | INFO     | trainer_plot:train_epoch:125 - Train: [5120/7970 (65%)]	Loss: 0.000113
2023-05-22 22:12:01.601 | INFO     | trainer_plot:train_epoch:125 - Train: [5760/7970 (73%)]	Loss: 0.000123
2023-05-22 22:12:11.584 | INFO     | trainer_plot:train_epoch:125 - Train: [6400/7970 (81%)]	Loss: 0.000123
2023-05-22 22:12:21.575 | INFO     | trainer_plot:train_epoch:125 - Train: [7040/7970 (89%)]	Loss: 0.000225
2023-05-22 22:12:31.571 | INFO     | trainer_plot:train_epoch:125 - Train: [7680/7970 (97%)]	Loss: 0.000089
2023-05-22 22:12:34.688 | INFO     | trainer_plot:fit:33 - Epoch: 41/50. Train set: Average loss: 0.000136
2023-05-22 22:12:44.476 | INFO     | trainer_plot:fit:43 - Epoch: 41/50. Validation set: Average loss: 0.003660
2023-05-22 22:12:45.856 | INFO     | trainer_plot:train_epoch:125 - Train: [0/7970 (0%)]	Loss: 0.000022
2023-05-22 22:12:55.824 | INFO     | trainer_plot:train_epoch:125 - Train: [640/7970 (8%)]	Loss: 0.000322
2023-05-22 22:13:05.820 | INFO     | trainer_plot:train_epoch:125 - Train: [1280/7970 (16%)]	Loss: 0.000132
2023-05-22 22:13:15.819 | INFO     | trainer_plot:train_epoch:125 - Train: [1920/7970 (24%)]	Loss: 0.000117
2023-05-22 22:13:25.823 | INFO     | trainer_plot:train_epoch:125 - Train: [2560/7970 (32%)]	Loss: 0.000175
2023-05-22 22:13:35.835 | INFO     | trainer_plot:train_epoch:125 - Train: [3200/7970 (40%)]	Loss: 0.000176
2023-05-22 22:13:45.832 | INFO     | trainer_plot:train_epoch:125 - Train: [3840/7970 (48%)]	Loss: 0.000222
2023-05-22 22:13:55.837 | INFO     | trainer_plot:train_epoch:125 - Train: [4480/7970 (56%)]	Loss: 0.000260
2023-05-22 22:14:05.839 | INFO     | trainer_plot:train_epoch:125 - Train: [5120/7970 (65%)]	Loss: 0.000081
2023-05-22 22:14:15.840 | INFO     | trainer_plot:train_epoch:125 - Train: [5760/7970 (73%)]	Loss: 0.000036
2023-05-22 22:14:25.839 | INFO     | trainer_plot:train_epoch:125 - Train: [6400/7970 (81%)]	Loss: 0.000279
2023-05-22 22:14:35.844 | INFO     | trainer_plot:train_epoch:125 - Train: [7040/7970 (89%)]	Loss: 0.000127
2023-05-22 22:14:45.857 | INFO     | trainer_plot:train_epoch:125 - Train: [7680/7970 (97%)]	Loss: 0.000146
2023-05-22 22:14:48.970 | INFO     | trainer_plot:fit:33 - Epoch: 42/50. Train set: Average loss: 0.000169
2023-05-22 22:14:58.711 | INFO     | trainer_plot:fit:43 - Epoch: 42/50. Validation set: Average loss: 0.000716
2023-05-22 22:15:00.086 | INFO     | trainer_plot:train_epoch:125 - Train: [0/7970 (0%)]	Loss: 0.000269
2023-05-22 22:15:10.057 | INFO     | trainer_plot:train_epoch:125 - Train: [640/7970 (8%)]	Loss: 0.000092
2023-05-22 22:15:20.046 | INFO     | trainer_plot:train_epoch:125 - Train: [1280/7970 (16%)]	Loss: 0.000414
2023-05-22 22:15:30.031 | INFO     | trainer_plot:train_epoch:125 - Train: [1920/7970 (24%)]	Loss: 0.000129
2023-05-22 22:15:40.027 | INFO     | trainer_plot:train_epoch:125 - Train: [2560/7970 (32%)]	Loss: 0.000265
2023-05-22 22:15:50.016 | INFO     | trainer_plot:train_epoch:125 - Train: [3200/7970 (40%)]	Loss: 0.000042
2023-05-22 22:16:00.004 | INFO     | trainer_plot:train_epoch:125 - Train: [3840/7970 (48%)]	Loss: 0.000205
2023-05-22 22:16:09.983 | INFO     | trainer_plot:train_epoch:125 - Train: [4480/7970 (56%)]	Loss: 0.000196
2023-05-22 22:16:20.049 | INFO     | trainer_plot:train_epoch:125 - Train: [5120/7970 (65%)]	Loss: 0.000306
2023-05-22 22:16:30.043 | INFO     | trainer_plot:train_epoch:125 - Train: [5760/7970 (73%)]	Loss: 0.000117
2023-05-22 22:16:40.035 | INFO     | trainer_plot:train_epoch:125 - Train: [6400/7970 (81%)]	Loss: 0.000223
2023-05-22 22:16:50.031 | INFO     | trainer_plot:train_epoch:125 - Train: [7040/7970 (89%)]	Loss: 0.000082
2023-05-22 22:17:00.023 | INFO     | trainer_plot:train_epoch:125 - Train: [7680/7970 (97%)]	Loss: 0.000168
2023-05-22 22:17:03.149 | INFO     | trainer_plot:fit:33 - Epoch: 43/50. Train set: Average loss: 0.000188
2023-05-22 22:17:12.906 | INFO     | trainer_plot:fit:43 - Epoch: 43/50. Validation set: Average loss: 0.003124
2023-05-22 22:17:14.297 | INFO     | trainer_plot:train_epoch:125 - Train: [0/7970 (0%)]	Loss: 0.000083
2023-05-22 22:17:24.277 | INFO     | trainer_plot:train_epoch:125 - Train: [640/7970 (8%)]	Loss: 0.000264
2023-05-22 22:17:34.272 | INFO     | trainer_plot:train_epoch:125 - Train: [1280/7970 (16%)]	Loss: 0.000050
2023-05-22 22:17:44.276 | INFO     | trainer_plot:train_epoch:125 - Train: [1920/7970 (24%)]	Loss: 0.000115
2023-05-22 22:17:54.272 | INFO     | trainer_plot:train_epoch:125 - Train: [2560/7970 (32%)]	Loss: 0.000206
2023-05-22 22:18:04.268 | INFO     | trainer_plot:train_epoch:125 - Train: [3200/7970 (40%)]	Loss: 0.000164
2023-05-22 22:18:14.261 | INFO     | trainer_plot:train_epoch:125 - Train: [3840/7970 (48%)]	Loss: 0.000115
2023-05-22 22:18:24.249 | INFO     | trainer_plot:train_epoch:125 - Train: [4480/7970 (56%)]	Loss: 0.000225
2023-05-22 22:18:34.242 | INFO     | trainer_plot:train_epoch:125 - Train: [5120/7970 (65%)]	Loss: 0.000127
2023-05-22 22:18:44.238 | INFO     | trainer_plot:train_epoch:125 - Train: [5760/7970 (73%)]	Loss: 0.000131
2023-05-22 22:18:54.241 | INFO     | trainer_plot:train_epoch:125 - Train: [6400/7970 (81%)]	Loss: 0.000240
2023-05-22 22:19:04.249 | INFO     | trainer_plot:train_epoch:125 - Train: [7040/7970 (89%)]	Loss: 0.000197
2023-05-22 22:19:14.241 | INFO     | trainer_plot:train_epoch:125 - Train: [7680/7970 (97%)]	Loss: 0.000137
2023-05-22 22:19:17.329 | INFO     | trainer_plot:fit:33 - Epoch: 44/50. Train set: Average loss: 0.000168
2023-05-22 22:19:27.115 | INFO     | trainer_plot:fit:43 - Epoch: 44/50. Validation set: Average loss: 0.002061
2023-05-22 22:19:28.484 | INFO     | trainer_plot:train_epoch:125 - Train: [0/7970 (0%)]	Loss: 0.000048
2023-05-22 22:19:38.452 | INFO     | trainer_plot:train_epoch:125 - Train: [640/7970 (8%)]	Loss: 0.000273
2023-05-22 22:19:48.432 | INFO     | trainer_plot:train_epoch:125 - Train: [1280/7970 (16%)]	Loss: 0.000147
2023-05-22 22:19:58.419 | INFO     | trainer_plot:train_epoch:125 - Train: [1920/7970 (24%)]	Loss: 0.000195
2023-05-22 22:20:08.416 | INFO     | trainer_plot:train_epoch:125 - Train: [2560/7970 (32%)]	Loss: 0.000120
2023-05-22 22:20:18.408 | INFO     | trainer_plot:train_epoch:125 - Train: [3200/7970 (40%)]	Loss: 0.000247
2023-05-22 22:20:28.397 | INFO     | trainer_plot:train_epoch:125 - Train: [3840/7970 (48%)]	Loss: 0.000091
2023-05-22 22:20:38.371 | INFO     | trainer_plot:train_epoch:125 - Train: [4480/7970 (56%)]	Loss: 0.000128
2023-05-22 22:20:48.363 | INFO     | trainer_plot:train_epoch:125 - Train: [5120/7970 (65%)]	Loss: 0.000152
2023-05-22 22:20:58.351 | INFO     | trainer_plot:train_epoch:125 - Train: [5760/7970 (73%)]	Loss: 0.000158
2023-05-22 22:21:08.329 | INFO     | trainer_plot:train_epoch:125 - Train: [6400/7970 (81%)]	Loss: 0.000050
2023-05-22 22:21:18.319 | INFO     | trainer_plot:train_epoch:125 - Train: [7040/7970 (89%)]	Loss: 0.000179
2023-05-22 22:21:28.309 | INFO     | trainer_plot:train_epoch:125 - Train: [7680/7970 (97%)]	Loss: 0.000200
2023-05-22 22:21:31.428 | INFO     | trainer_plot:fit:33 - Epoch: 45/50. Train set: Average loss: 0.000162
2023-05-22 22:21:41.235 | INFO     | trainer_plot:fit:43 - Epoch: 45/50. Validation set: Average loss: 0.001820
2023-05-22 22:21:42.618 | INFO     | trainer_plot:train_epoch:125 - Train: [0/7970 (0%)]	Loss: 0.000024
2023-05-22 22:21:52.588 | INFO     | trainer_plot:train_epoch:125 - Train: [640/7970 (8%)]	Loss: 0.000120
2023-05-22 22:22:02.575 | INFO     | trainer_plot:train_epoch:125 - Train: [1280/7970 (16%)]	Loss: 0.000128
2023-05-22 22:22:12.639 | INFO     | trainer_plot:train_epoch:125 - Train: [1920/7970 (24%)]	Loss: 0.000190
2023-05-22 22:22:22.626 | INFO     | trainer_plot:train_epoch:125 - Train: [2560/7970 (32%)]	Loss: 0.000111
2023-05-22 22:22:32.628 | INFO     | trainer_plot:train_epoch:125 - Train: [3200/7970 (40%)]	Loss: 0.000202
2023-05-22 22:22:42.623 | INFO     | trainer_plot:train_epoch:125 - Train: [3840/7970 (48%)]	Loss: 0.000071
2023-05-22 22:22:52.615 | INFO     | trainer_plot:train_epoch:125 - Train: [4480/7970 (56%)]	Loss: 0.000155
2023-05-22 22:23:02.615 | INFO     | trainer_plot:train_epoch:125 - Train: [5120/7970 (65%)]	Loss: 0.000115
2023-05-22 22:23:12.614 | INFO     | trainer_plot:train_epoch:125 - Train: [5760/7970 (73%)]	Loss: 0.000251
2023-05-22 22:23:22.618 | INFO     | trainer_plot:train_epoch:125 - Train: [6400/7970 (81%)]	Loss: 0.000113
2023-05-22 22:23:32.604 | INFO     | trainer_plot:train_epoch:125 - Train: [7040/7970 (89%)]	Loss: 0.000034
2023-05-22 22:23:42.596 | INFO     | trainer_plot:train_epoch:125 - Train: [7680/7970 (97%)]	Loss: 0.000140
2023-05-22 22:23:45.713 | INFO     | trainer_plot:fit:33 - Epoch: 46/50. Train set: Average loss: 0.000135
2023-05-22 22:23:55.489 | INFO     | trainer_plot:fit:43 - Epoch: 46/50. Validation set: Average loss: 0.001795
2023-05-22 22:23:56.880 | INFO     | trainer_plot:train_epoch:125 - Train: [0/7970 (0%)]	Loss: 0.000136
2023-05-22 22:24:06.847 | INFO     | trainer_plot:train_epoch:125 - Train: [640/7970 (8%)]	Loss: 0.000198
2023-05-22 22:24:16.827 | INFO     | trainer_plot:train_epoch:125 - Train: [1280/7970 (16%)]	Loss: 0.000115
2023-05-22 22:24:26.803 | INFO     | trainer_plot:train_epoch:125 - Train: [1920/7970 (24%)]	Loss: 0.000188
2023-05-22 22:24:36.782 | INFO     | trainer_plot:train_epoch:125 - Train: [2560/7970 (32%)]	Loss: 0.000104
2023-05-22 22:24:46.780 | INFO     | trainer_plot:train_epoch:125 - Train: [3200/7970 (40%)]	Loss: 0.000102
2023-05-22 22:24:56.779 | INFO     | trainer_plot:train_epoch:125 - Train: [3840/7970 (48%)]	Loss: 0.000141
2023-05-22 22:25:06.773 | INFO     | trainer_plot:train_epoch:125 - Train: [4480/7970 (56%)]	Loss: 0.000064
2023-05-22 22:25:16.769 | INFO     | trainer_plot:train_epoch:125 - Train: [5120/7970 (65%)]	Loss: 0.000228
2023-05-22 22:25:26.771 | INFO     | trainer_plot:train_epoch:125 - Train: [5760/7970 (73%)]	Loss: 0.000190
2023-05-22 22:25:36.765 | INFO     | trainer_plot:train_epoch:125 - Train: [6400/7970 (81%)]	Loss: 0.000042
2023-05-22 22:25:46.770 | INFO     | trainer_plot:train_epoch:125 - Train: [7040/7970 (89%)]	Loss: 0.000081
2023-05-22 22:25:56.763 | INFO     | trainer_plot:train_epoch:125 - Train: [7680/7970 (97%)]	Loss: 0.000139
2023-05-22 22:25:59.881 | INFO     | trainer_plot:fit:33 - Epoch: 47/50. Train set: Average loss: 0.000134
2023-05-22 22:26:09.660 | INFO     | trainer_plot:fit:43 - Epoch: 47/50. Validation set: Average loss: 0.001471
2023-05-22 22:26:11.048 | INFO     | trainer_plot:train_epoch:125 - Train: [0/7970 (0%)]	Loss: 0.000001
2023-05-22 22:26:21.015 | INFO     | trainer_plot:train_epoch:125 - Train: [640/7970 (8%)]	Loss: 0.000172
2023-05-22 22:26:30.996 | INFO     | trainer_plot:train_epoch:125 - Train: [1280/7970 (16%)]	Loss: 0.000074
2023-05-22 22:26:40.975 | INFO     | trainer_plot:train_epoch:125 - Train: [1920/7970 (24%)]	Loss: 0.000077
2023-05-22 22:26:50.959 | INFO     | trainer_plot:train_epoch:125 - Train: [2560/7970 (32%)]	Loss: 0.000126
2023-05-22 22:27:00.956 | INFO     | trainer_plot:train_epoch:125 - Train: [3200/7970 (40%)]	Loss: 0.000054
2023-05-22 22:27:10.952 | INFO     | trainer_plot:train_epoch:125 - Train: [3840/7970 (48%)]	Loss: 0.000132
2023-05-22 22:27:20.952 | INFO     | trainer_plot:train_epoch:125 - Train: [4480/7970 (56%)]	Loss: 0.000138
2023-05-22 22:27:30.954 | INFO     | trainer_plot:train_epoch:125 - Train: [5120/7970 (65%)]	Loss: 0.000131
2023-05-22 22:27:40.942 | INFO     | trainer_plot:train_epoch:125 - Train: [5760/7970 (73%)]	Loss: 0.000180
2023-05-22 22:27:50.951 | INFO     | trainer_plot:train_epoch:125 - Train: [6400/7970 (81%)]	Loss: 0.000141
2023-05-22 22:28:00.942 | INFO     | trainer_plot:train_epoch:125 - Train: [7040/7970 (89%)]	Loss: 0.000133
2023-05-22 22:28:10.948 | INFO     | trainer_plot:train_epoch:125 - Train: [7680/7970 (97%)]	Loss: 0.000201
2023-05-22 22:28:14.073 | INFO     | trainer_plot:fit:33 - Epoch: 48/50. Train set: Average loss: 0.000126
2023-05-22 22:28:23.900 | INFO     | trainer_plot:fit:43 - Epoch: 48/50. Validation set: Average loss: 0.000888
2023-05-22 22:28:25.293 | INFO     | trainer_plot:train_epoch:125 - Train: [0/7970 (0%)]	Loss: 0.000181
2023-05-22 22:28:35.266 | INFO     | trainer_plot:train_epoch:125 - Train: [640/7970 (8%)]	Loss: 0.000143
2023-05-22 22:28:45.247 | INFO     | trainer_plot:train_epoch:125 - Train: [1280/7970 (16%)]	Loss: 0.000173
2023-05-22 22:28:55.225 | INFO     | trainer_plot:train_epoch:125 - Train: [1920/7970 (24%)]	Loss: 0.000194
2023-05-22 22:29:05.220 | INFO     | trainer_plot:train_epoch:125 - Train: [2560/7970 (32%)]	Loss: 0.000171
2023-05-22 22:29:15.210 | INFO     | trainer_plot:train_epoch:125 - Train: [3200/7970 (40%)]	Loss: 0.000228
2023-05-22 22:29:25.188 | INFO     | trainer_plot:train_epoch:125 - Train: [3840/7970 (48%)]	Loss: 0.000102
2023-05-22 22:29:35.188 | INFO     | trainer_plot:train_epoch:125 - Train: [4480/7970 (56%)]	Loss: 0.000092
2023-05-22 22:29:45.184 | INFO     | trainer_plot:train_epoch:125 - Train: [5120/7970 (65%)]	Loss: 0.000172
2023-05-22 22:29:55.180 | INFO     | trainer_plot:train_epoch:125 - Train: [5760/7970 (73%)]	Loss: 0.000105
2023-05-22 22:30:05.167 | INFO     | trainer_plot:train_epoch:125 - Train: [6400/7970 (81%)]	Loss: 0.000034
2023-05-22 22:30:15.161 | INFO     | trainer_plot:train_epoch:125 - Train: [7040/7970 (89%)]	Loss: 0.000136
2023-05-22 22:30:25.147 | INFO     | trainer_plot:train_epoch:125 - Train: [7680/7970 (97%)]	Loss: 0.000114
2023-05-22 22:30:28.263 | INFO     | trainer_plot:fit:33 - Epoch: 49/50. Train set: Average loss: 0.000138
2023-05-22 22:30:38.068 | INFO     | trainer_plot:fit:43 - Epoch: 49/50. Validation set: Average loss: 0.002015
2023-05-22 22:30:39.457 | INFO     | trainer_plot:train_epoch:125 - Train: [0/7970 (0%)]	Loss: 0.000443
2023-05-22 22:30:49.425 | INFO     | trainer_plot:train_epoch:125 - Train: [640/7970 (8%)]	Loss: 0.000259
2023-05-22 22:30:59.398 | INFO     | trainer_plot:train_epoch:125 - Train: [1280/7970 (16%)]	Loss: 0.000294
2023-05-22 22:31:09.374 | INFO     | trainer_plot:train_epoch:125 - Train: [1920/7970 (24%)]	Loss: 0.000062
2023-05-22 22:31:19.354 | INFO     | trainer_plot:train_epoch:125 - Train: [2560/7970 (32%)]	Loss: 0.000389
2023-05-22 22:31:29.334 | INFO     | trainer_plot:train_epoch:125 - Train: [3200/7970 (40%)]	Loss: 0.000154
2023-05-22 22:31:39.331 | INFO     | trainer_plot:train_epoch:125 - Train: [3840/7970 (48%)]	Loss: 0.000164
2023-05-22 22:31:49.324 | INFO     | trainer_plot:train_epoch:125 - Train: [4480/7970 (56%)]	Loss: 0.000117
2023-05-22 22:31:59.323 | INFO     | trainer_plot:train_epoch:125 - Train: [5120/7970 (65%)]	Loss: 0.000249
2023-05-22 22:32:09.324 | INFO     | trainer_plot:train_epoch:125 - Train: [5760/7970 (73%)]	Loss: 0.000256
2023-05-22 22:32:19.318 | INFO     | trainer_plot:train_epoch:125 - Train: [6400/7970 (81%)]	Loss: 0.000170
2023-05-22 22:32:29.387 | INFO     | trainer_plot:train_epoch:125 - Train: [7040/7970 (89%)]	Loss: 0.000117
2023-05-22 22:32:39.379 | INFO     | trainer_plot:train_epoch:125 - Train: [7680/7970 (97%)]	Loss: 0.000168
2023-05-22 22:32:42.492 | INFO     | trainer_plot:fit:33 - Epoch: 50/50. Train set: Average loss: 0.000204
2023-05-22 22:32:52.254 | INFO     | trainer_plot:fit:43 - Epoch: 50/50. Validation set: Average loss: 0.000504
