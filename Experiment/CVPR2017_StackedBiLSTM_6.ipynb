{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea7f6401",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from analysis import *\n",
    "import argparse\n",
    "from sys import platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c192d33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(12)\n",
    "torch.cuda.manual_seed(12)\n",
    "np.random.seed(12)\n",
    "torch.backends.cudnn.deterministics = True\n",
    "torch.set_num_threads(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "daf1a8a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "0\n",
      "<torch.cuda.device object at 0x7f6814646730>\n",
      "NVIDIA TITAN V\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.current_device())\n",
    "\n",
    "\n",
    "print(torch.cuda.device(0))\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff733115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iv: image option\n",
    "length = 440\n",
    "channel = 128\n",
    "min_CNN = 200\n",
    "n_classes = 40\n",
    "classes = range(n_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b68db2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['block_splits_by_image_all.pth', 'block_splits_by_image_single.pth', 'eeg_14_70_std.pth', 'eeg_55_95_std.pth', 'eeg_5_95_std.pth', 'eeg_signals_raw_with_mean_std.pth']\n"
     ]
    }
   ],
   "source": [
    "if platform == \"linux\" or platform == \"linux2\":\n",
    "    torch_models_dir = r\"/media/titan/AI Research1/Data/CVPR2017\"\n",
    "elif platform == \"win32\":\n",
    "    torch_models_dir = r\"D:\\Data\\CVPR2021-02785\\CVPR2021-02785\\preprocessed\\torch_models\"\n",
    "block_splits_all, block_splits_single, eeg_14_70, eeg_55_95, eeg_5_95, eeg_raw = os.listdir(torch_models_dir)\n",
    "print(os.listdir(torch_models_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd3ad4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/titan/AI Research1/Data/CVPR2017/eeg_5_95_std.pth \n",
      " /media/titan/AI Research1/Data/CVPR2017/block_splits_by_image_all.pth \n",
      " /media/titan/AI Research1/Data/CVPR2017/block_splits_by_image_single.pth\n"
     ]
    }
   ],
   "source": [
    "eeg_dataset = os.path.join(torch_models_dir, eeg_5_95)\n",
    "splits_all_path = os.path.join(torch_models_dir, block_splits_all)\n",
    "splits_single_path = os.path.join(torch_models_dir, block_splits_single)\n",
    "# splits_path = os.path.join(torch_models_dir, splits_shuffled_path)\n",
    "print(eeg_dataset,'\\n', splits_all_path, '\\n', splits_single_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "659d4a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits_all = torch.load(splits_all_path)\n",
    "splits_single = torch.load(splits_single_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f3ef344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "3\n",
      "7984\n",
      "1996\n",
      "1985\n",
      "[0, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 27, 29, 33, 35, 36, 37, 38, 39, 42, 43, 44, 45, 46, 47, 48, 51, 52, 54, 55]\n",
      "[1, 2, 3, 4, 6, 8, 9, 12, 13, 20, 25, 26, 27, 28, 30, 32, 33, 35, 37, 38, 39, 40, 44, 45, 46, 50, 52, 54, 56, 58, 59, 60, 62, 65, 68, 72, 73, 74, 76, 81]\n",
      "[2, 3, 4, 5, 6, 7, 8, 10, 11, 13]\n",
      "[1, 2, 4, 7, 9, 10, 12, 13, 14, 15]\n"
     ]
    }
   ],
   "source": [
    "print(len(splits_all['splits']))\n",
    "print(len(splits_all['splits'][0]))\n",
    "\n",
    "print(len(splits_all['splits'][5]['train']))\n",
    "print(len(splits_all['splits'][5]['val']))\n",
    "print(len(splits_all['splits'][5]['test']))\n",
    "print(splits_all['splits'][0]['train'][:40])\n",
    "print(splits_all['splits'][1]['train'][:40])\n",
    "print(splits_all['splits'][2]['train'][:10])\n",
    "print(splits_all['splits'][3]['train'][:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b27b3181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "669\n",
      "167\n",
      "164\n"
     ]
    }
   ],
   "source": [
    "# print(splits_single)\n",
    "print(len(splits_single['splits'][0]['train']))\n",
    "print(len(splits_single['splits'][0]['val']))\n",
    "print(len(splits_single['splits'][0]['test']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed58c00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_loaded = torch.load(eeg_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89460bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "dict_keys(['dataset', 'labels', 'images'])\n",
      "40\n",
      "1996\n",
      "11965\n",
      "['n02389026', 'n03888257', 'n03584829', 'n02607072', 'n03297495', 'n03063599', 'n03792782', 'n04086273', 'n02510455', 'n11939491', 'n02951358', 'n02281787', 'n02106662', 'n04120489', 'n03590841', 'n02992529', 'n03445777', 'n03180011', 'n02906734', 'n07873807', 'n03773504', 'n02492035', 'n03982430', 'n03709823', 'n03100240', 'n03376595', 'n03877472', 'n03775071', 'n03272010', 'n04069434', 'n03452741', 'n03792972', 'n07753592', 'n13054560', 'n03197337', 'n02504458', 'n02690373', 'n03272562', 'n04044716', 'n02124075']\n",
      "n02951358_31190\n",
      "torch.Size([128, 500])\n",
      "{'eeg': tensor([[-0.0098,  0.0195,  0.0620,  ...,  0.0638,  0.0120, -0.0118],\n",
      "        [-0.0045,  0.1303,  0.2673,  ...,  0.0894,  0.0342, -0.0082],\n",
      "        [ 0.0215, -0.2017, -0.4305,  ..., -0.2022, -0.0940,  0.0188],\n",
      "        ...,\n",
      "        [ 0.0160,  0.0707,  0.1005,  ...,  0.2066,  0.1156,  0.0036],\n",
      "        [-0.0046, -0.0084, -0.0119,  ...,  0.0007, -0.0026, -0.0053],\n",
      "        [ 0.0040,  0.0419,  0.0665,  ...,  0.0765,  0.0309, -0.0063]]), 'image': 0, 'label': 10, 'subject': 4}\n"
     ]
    }
   ],
   "source": [
    "print(len(eeg_loaded))\n",
    "print(eeg_loaded.keys())\n",
    "dataset, labels, images = [eeg_loaded[k] for k in eeg_loaded.keys()]\n",
    "print(len(labels))\n",
    "print(len(images))\n",
    "print(len(dataset))\n",
    "\n",
    "print(labels)\n",
    "print(images[0])\n",
    "print(dataset[0]['eeg'].shape)\n",
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d20c958c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "opt = {\n",
    "    # Dataset options\n",
    "#     \"iv\": \"image\",\n",
    "#     \"offset\": None,\n",
    "    \"results_file\": \"results.pkl\",\n",
    "    \"subject\": 0,\n",
    "    \"time_low\": 20,\n",
    "    \"time_high\": 460,\n",
    "#     \"run\": \"none\",\n",
    "    \"eeg_dataset\": eeg_dataset,\n",
    "    \"model_type\": \"model10\",\n",
    "    \"splits_path\": splits_all_path,\n",
    "    \"split_num\": 0,\n",
    "    \"split_name\": \"train\",\n",
    "#     \"fold\": 5,\n",
    "    #Training options\n",
    "    \"batch_size\": 16,\n",
    "    \"optim\": \"Adam\",\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"learning_rate_decay_by\": 0.5,\n",
    "    \"learning_rate_decay_every\": 10,\n",
    "    \"epochs\": 100,\n",
    "    \"GPUindex\": 0,\n",
    "    \"kind\":\"from-scratch\",\n",
    "    #Backend options\n",
    "    \"no_cuda\": False,\n",
    "    \"classifier\": None\n",
    "}\n",
    "opt = argparse.Namespace(**opt)\n",
    "print(opt.time_low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce8d6e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from torch.utils.data import DataLoader\n",
    "# from data_loader import EEGDataset, Splitter, SplitterWithData\n",
    "from data_loader_CVPR2017 import EEGDataset, Splitter\n",
    "from EEG_Encoder.LSTM import classifier_LSTM\n",
    "from EEG_Encoder.CNN import classifier_CNN\n",
    "from EEG_Encoder.EEGNet import classifier_EEGNet\n",
    "from EEG_Encoder.SyncNet import classifier_SyncNet\n",
    "from EEG_Encoder.EEGChannelNet import classifier_EEGChannelNet\n",
    "from EEG_Encoder.net_generator import Classifier\n",
    "from EEG_Encoder.net_trainer import net_trainer\n",
    "from p_values import *\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a5b475c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(\n",
    "#              offset,\n",
    "             eeg_dataset,\n",
    "             splits_path,\n",
    "             split_num, # (0-5) - 6 fold cross validation\n",
    "             split_name,\n",
    "#              total, \n",
    "#              classes,\n",
    "#              classifier,\n",
    "             batch_size,\n",
    "#              GPUindex,\n",
    "#              length, # 500\n",
    "#              channel, # 128\n",
    "#              min_CNN,\n",
    "             opt,\n",
    "             kind=\"from-scratch\"):        \n",
    "    # Load dataset\n",
    "    dataset = EEGDataset(opt, eeg_dataset)\n",
    "    print(\"DONE: LOAD DATASET\")\n",
    "#     # Create loaders for LSTM/MLP/CNN/SCNN/EEGNet/SyncNet/EEGChannelNet\n",
    "#     if kind==\"from-scratch\":\n",
    "#         relabel = False\n",
    "#     if kind==\"incremental\":\n",
    "#         relabel = False\n",
    "#     if kind==\"no-model-file\":\n",
    "#         relabel = True\n",
    "    splitter = {split: Splitter(dataset,\n",
    "                    splits_path,\n",
    "                    split_num,\n",
    "                    split_name = split) for split in [\"train\", \"val\", \"test\"]}\n",
    "    loaders = {split: DataLoader(\n",
    "                        splitter[split],\n",
    "                        batch_size = batch_size,\n",
    "                        drop_last = False,\n",
    "                        shuffle = True)\n",
    "                    for split in [\"train\", \"val\", \"test\"]}\n",
    "    channel_idx = None    \n",
    "    print(\"DONE: Create loaders for model\")            \n",
    "    return dataset, loaders, splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a242cae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Options\n",
    "opt.classifier = \"Stacked_BiLSTM\"\n",
    "opt.batch_size = 16\n",
    "# opt.kind = \"from-scratch\"\n",
    "# opt.run = \"imagenet40-1000\"\n",
    "# opt.fold = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "633488a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE: LOAD DATASET\n",
      "DONE: Create loaders for model\n"
     ]
    }
   ],
   "source": [
    "dataset, loaders, splitter = load_dataset(\n",
    "#              offset,\n",
    "             opt.eeg_dataset,\n",
    "             opt.splits_path,\n",
    "             opt.split_num, # (0-5) - 6 fold cross validation\n",
    "             opt.split_name,\n",
    "#              total, \n",
    "#              classes,\n",
    "#              classifier,\n",
    "             opt.batch_size,\n",
    "#              GPUindex,\n",
    "#              length, # 500\n",
    "#              channel, # 128\n",
    "#              min_CNN,\n",
    "             opt,\n",
    "             opt.kind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e99fc973",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'data_loader_CVPR2017.EEGDataset'>\n",
      "<class 'dict'>\n",
      "3 [498, 125, 125]\n",
      "1: Target size: torch.Size([16]); input size: torch.Size([16, 128, 440])\n",
      "2: Target size: torch.Size([16]); input size: torch.Size([16, 128, 440])\n",
      "3: Target size: torch.Size([16]); input size: torch.Size([16, 128, 440])\n",
      "4: Target size: torch.Size([16]); input size: torch.Size([16, 128, 440])\n",
      "5: Target size: torch.Size([16]); input size: torch.Size([16, 128, 440])\n",
      "6: Target size: torch.Size([16]); input size: torch.Size([16, 128, 440])\n",
      "7: Target size: torch.Size([16]); input size: torch.Size([16, 128, 440])\n",
      "8: Target size: torch.Size([16]); input size: torch.Size([16, 128, 440])\n",
      "9: Target size: torch.Size([16]); input size: torch.Size([16, 128, 440])\n",
      "10: Target size: torch.Size([16]); input size: torch.Size([16, 128, 440])\n",
      "11: Target size: torch.Size([16]); input size: torch.Size([16, 128, 440])\n",
      "12: Target size: torch.Size([16]); input size: torch.Size([16, 128, 440])\n",
      "13: Target size: torch.Size([16]); input size: torch.Size([16, 128, 440])\n",
      "14: Target size: torch.Size([16]); input size: torch.Size([16, 128, 440])\n",
      "15: Target size: torch.Size([16]); input size: torch.Size([16, 128, 440])\n",
      "16: Target size: torch.Size([16]); input size: torch.Size([16, 128, 440])\n",
      "17: Target size: torch.Size([16]); input size: torch.Size([16, 128, 440])\n",
      "18: Target size: torch.Size([16]); input size: torch.Size([16, 128, 440])\n",
      "19: Target size: torch.Size([16]); input size: torch.Size([16, 128, 440])\n",
      "20: Target size: torch.Size([16]); input size: torch.Size([16, 128, 440])\n"
     ]
    }
   ],
   "source": [
    "# loaders: divide the splits data in each fold with batch_size\n",
    "# Each fold has {train: 8000 idx, val: 2000 idx, test: 2000 idx}\n",
    "# Each loader batch has {train: 2000 idx, val: 250 idx, test: 250 idx}\n",
    "print(type(dataset))\n",
    "print(type(loaders))\n",
    "print(len(loaders), [len(loaders[name]) for name in [\"train\", \"val\", \"test\"] ])\n",
    "for i, (input, target) in enumerate(loaders[\"train\"]):\n",
    "    if i<20:\n",
    "        print(f\"{i+1}: Target size: {target.size()}; input size: {input.size()}\")\n",
    "# for i in range(0, 40):\n",
    "#     eeg, label_val = splitter[\"val\"][i]\n",
    "#     eeg, label_train = splitter[\"train\"][i]\n",
    "#     print(f\"{i+1}: Label val: {label_val}; label train: {label_train}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "39a07cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE: CREATE TORCH CLASSIFIER\n",
      "classifier_Stacked_BiLSTM(\n",
      "  (stacked_bilstm): LSTM(128, 128, num_layers=6, batch_first=True, bidirectional=True)\n",
      "  (output1): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (output2): Linear(in_features=128, out_features=40, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "classifier_Stacked_BiLSTM                [1, 40]                   --\n",
       "├─LSTM: 1-1                              [1, 440, 256]             2,240,512\n",
       "├─Linear: 1-2                            [1, 128]                  32,896\n",
       "├─ReLU: 1-3                              [1, 128]                  --\n",
       "├─Linear: 1-4                            [1, 40]                   5,160\n",
       "==========================================================================================\n",
       "Total params: 2,278,568\n",
       "Trainable params: 2,278,568\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 985.86\n",
       "==========================================================================================\n",
       "Input size (MB): 0.23\n",
       "Forward/backward pass size (MB): 0.90\n",
       "Params size (MB): 9.11\n",
       "Estimated Total Size (MB): 10.24\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net, nonclasses = Classifier(\n",
    "                 n_classes,\n",
    "                 classes,\n",
    "                 opt.classifier,\n",
    "                 opt.GPUindex,\n",
    "                 length,\n",
    "                 channel,\n",
    "                 min_CNN,\n",
    "                 opt.kind)\n",
    "# print(len(nonclasses))\n",
    "summary(net, input_size=(1,128, 440))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a8d6995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacked_BiLSTM-440-128-6layers\n"
     ]
    }
   ],
   "source": [
    "model_path = (   opt.classifier+\n",
    "                  \"-\"+\n",
    "                  str(length)+\n",
    "                  \"-\"+\n",
    "                  str(channel) + \"-\" + \"6layers\" )\n",
    "print(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b753db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(results_file='results.pkl', subject=0, time_low=20, time_high=460, eeg_dataset='/media/titan/AI Research1/Data/CVPR2017/eeg_5_95_std.pth', model_type='model10', splits_path='/media/titan/AI Research1/Data/CVPR2017/block_splits_by_image_all.pth', split_num=0, split_name='train', batch_size=16, optim='Adam', learning_rate=0.001, learning_rate_decay_by=0.5, learning_rate_decay_every=10, epochs=100, GPUindex=0, kind='from-scratch', no_cuda=False, classifier='Stacked_BiLSTM')\n"
     ]
    }
   ],
   "source": [
    "print(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5334cb84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Train Batch 100 (every 100 batch): Loss=3.6593; accuracy=0.0250\n",
      "Train Batch 200 (every 100 batch): Loss=3.6804; accuracy=0.0259\n",
      "Train Batch 300 (every 100 batch): Loss=3.6826; accuracy=0.0250\n",
      "Train Batch 400 (every 100 batch): Loss=3.6758; accuracy=0.0267\n",
      "Epoch 1 summary: train_loss: 3.6903 | train_acc: 0.0267 | val_loss: 3.6998 | val_acc: 0.0243\n",
      "Epoch 2\n",
      "Train Batch 100 (every 100 batch): Loss=3.6807; accuracy=0.0312\n",
      "Train Batch 200 (every 100 batch): Loss=3.6914; accuracy=0.0325\n",
      "Train Batch 300 (every 100 batch): Loss=3.6916; accuracy=0.0312\n",
      "Train Batch 400 (every 100 batch): Loss=3.6722; accuracy=0.0295\n",
      "Epoch 2 summary: train_loss: 3.6878 | train_acc: 0.0305 | val_loss: 3.7033 | val_acc: 0.0240\n",
      "Epoch 3\n",
      "Train Batch 100 (every 100 batch): Loss=3.7155; accuracy=0.0281\n",
      "Train Batch 200 (every 100 batch): Loss=3.7035; accuracy=0.0291\n",
      "Train Batch 300 (every 100 batch): Loss=3.7097; accuracy=0.0296\n",
      "Train Batch 400 (every 100 batch): Loss=3.6903; accuracy=0.0291\n",
      "Epoch 3 summary: train_loss: 3.6873 | train_acc: 0.0280 | val_loss: 3.7074 | val_acc: 0.0180\n",
      "Epoch 4\n",
      "Train Batch 100 (every 100 batch): Loss=3.6770; accuracy=0.0262\n",
      "Train Batch 200 (every 100 batch): Loss=3.6744; accuracy=0.0306\n",
      "Train Batch 300 (every 100 batch): Loss=3.6692; accuracy=0.0304\n",
      "Train Batch 400 (every 100 batch): Loss=3.6692; accuracy=0.0298\n",
      "Epoch 4 summary: train_loss: 3.6870 | train_acc: 0.0283 | val_loss: 3.7003 | val_acc: 0.0240\n",
      "Epoch 5\n",
      "Train Batch 100 (every 100 batch): Loss=3.6848; accuracy=0.0325\n",
      "Train Batch 200 (every 100 batch): Loss=3.7286; accuracy=0.0316\n",
      "Train Batch 300 (every 100 batch): Loss=3.6896; accuracy=0.0306\n",
      "Train Batch 400 (every 100 batch): Loss=3.6927; accuracy=0.0305\n",
      "Epoch 5 summary: train_loss: 3.6867 | train_acc: 0.0300 | val_loss: 3.7032 | val_acc: 0.0183\n",
      "Epoch 6\n",
      "Train Batch 100 (every 100 batch): Loss=3.6849; accuracy=0.0262\n",
      "Train Batch 200 (every 100 batch): Loss=3.6769; accuracy=0.0275\n",
      "Train Batch 300 (every 100 batch): Loss=3.6920; accuracy=0.0292\n",
      "Train Batch 400 (every 100 batch): Loss=3.6479; accuracy=0.0289\n",
      "Epoch 6 summary: train_loss: 3.6864 | train_acc: 0.0286 | val_loss: 3.7020 | val_acc: 0.0240\n",
      "Epoch 7\n",
      "Train Batch 100 (every 100 batch): Loss=3.6550; accuracy=0.0344\n",
      "Train Batch 200 (every 100 batch): Loss=3.6854; accuracy=0.0319\n",
      "Train Batch 300 (every 100 batch): Loss=3.7103; accuracy=0.0302\n",
      "Train Batch 400 (every 100 batch): Loss=3.6940; accuracy=0.0317\n",
      "Epoch 7 summary: train_loss: 3.6849 | train_acc: 0.0299 | val_loss: 3.7049 | val_acc: 0.0225\n",
      "Epoch 8\n",
      "Train Batch 100 (every 100 batch): Loss=3.6769; accuracy=0.0262\n",
      "Train Batch 200 (every 100 batch): Loss=3.6672; accuracy=0.0284\n",
      "Train Batch 300 (every 100 batch): Loss=3.6835; accuracy=0.0298\n",
      "Train Batch 400 (every 100 batch): Loss=3.6933; accuracy=0.0308\n",
      "Epoch 8 summary: train_loss: 3.6840 | train_acc: 0.0299 | val_loss: 3.7030 | val_acc: 0.0180\n",
      "Epoch 9\n",
      "Train Batch 100 (every 100 batch): Loss=3.7024; accuracy=0.0250\n",
      "Train Batch 200 (every 100 batch): Loss=3.7071; accuracy=0.0272\n",
      "Train Batch 300 (every 100 batch): Loss=3.6601; accuracy=0.0267\n",
      "Train Batch 400 (every 100 batch): Loss=3.6804; accuracy=0.0287\n",
      "Epoch 9 summary: train_loss: 3.6833 | train_acc: 0.0282 | val_loss: 3.7064 | val_acc: 0.0208\n",
      "Epoch 10\n",
      "Train Batch 100 (every 100 batch): Loss=3.6734; accuracy=0.0269\n",
      "Train Batch 200 (every 100 batch): Loss=3.6996; accuracy=0.0331\n",
      "Train Batch 300 (every 100 batch): Loss=3.6300; accuracy=0.0310\n",
      "Train Batch 400 (every 100 batch): Loss=3.6096; accuracy=0.0312\n",
      "Epoch 10 summary: train_loss: 3.6796 | train_acc: 0.0301 | val_loss: 3.7026 | val_acc: 0.0190\n",
      "Epoch 11\n",
      "Train Batch 100 (every 100 batch): Loss=3.7342; accuracy=0.0262\n",
      "Train Batch 200 (every 100 batch): Loss=3.6188; accuracy=0.0281\n",
      "Train Batch 300 (every 100 batch): Loss=3.6772; accuracy=0.0269\n",
      "Train Batch 400 (every 100 batch): Loss=3.6915; accuracy=0.0261\n",
      "Epoch 11 summary: train_loss: 3.6778 | train_acc: 0.0285 | val_loss: 3.7053 | val_acc: 0.0205\n",
      "Epoch 12\n",
      "Train Batch 100 (every 100 batch): Loss=3.6289; accuracy=0.0381\n",
      "Train Batch 200 (every 100 batch): Loss=3.7423; accuracy=0.0350\n",
      "Train Batch 300 (every 100 batch): Loss=3.6264; accuracy=0.0344\n",
      "Train Batch 400 (every 100 batch): Loss=3.6445; accuracy=0.0330\n",
      "Epoch 12 summary: train_loss: 3.6712 | train_acc: 0.0329 | val_loss: 3.6862 | val_acc: 0.0240\n",
      "Epoch 13\n",
      "Train Batch 100 (every 100 batch): Loss=3.7322; accuracy=0.0394\n",
      "Train Batch 200 (every 100 batch): Loss=3.6895; accuracy=0.0381\n",
      "Train Batch 300 (every 100 batch): Loss=3.6161; accuracy=0.0360\n",
      "Train Batch 400 (every 100 batch): Loss=3.6798; accuracy=0.0367\n",
      "Epoch 13 summary: train_loss: 3.6460 | train_acc: 0.0363 | val_loss: 3.6439 | val_acc: 0.0265\n",
      "Epoch 14\n",
      "Train Batch 100 (every 100 batch): Loss=3.6583; accuracy=0.0337\n",
      "Train Batch 200 (every 100 batch): Loss=3.6148; accuracy=0.0344\n",
      "Train Batch 300 (every 100 batch): Loss=3.6165; accuracy=0.0381\n",
      "Train Batch 400 (every 100 batch): Loss=3.4855; accuracy=0.0373\n",
      "Epoch 14 summary: train_loss: 3.5831 | train_acc: 0.0364 | val_loss: 3.5793 | val_acc: 0.0308\n",
      "Epoch 15\n",
      "Train Batch 100 (every 100 batch): Loss=3.4933; accuracy=0.0362\n",
      "Train Batch 200 (every 100 batch): Loss=3.5957; accuracy=0.0378\n",
      "Train Batch 300 (every 100 batch): Loss=3.3302; accuracy=0.0406\n",
      "Train Batch 400 (every 100 batch): Loss=3.3124; accuracy=0.0408\n",
      "Epoch 15 summary: train_loss: 3.4507 | train_acc: 0.0430 | val_loss: 3.3442 | val_acc: 0.0415\n",
      "Epoch 16\n",
      "Train Batch 100 (every 100 batch): Loss=3.5960; accuracy=0.0644\n",
      "Train Batch 200 (every 100 batch): Loss=3.1232; accuracy=0.0628\n",
      "Train Batch 300 (every 100 batch): Loss=3.4417; accuracy=0.0648\n",
      "Train Batch 400 (every 100 batch): Loss=3.3628; accuracy=0.0652\n",
      "Epoch 16 summary: train_loss: 3.2432 | train_acc: 0.0666 | val_loss: 3.1496 | val_acc: 0.0663\n",
      "Epoch 17\n",
      "Train Batch 100 (every 100 batch): Loss=2.9847; accuracy=0.0769\n",
      "Train Batch 200 (every 100 batch): Loss=2.9149; accuracy=0.0744\n",
      "Train Batch 300 (every 100 batch): Loss=2.7517; accuracy=0.0792\n",
      "Train Batch 400 (every 100 batch): Loss=2.6760; accuracy=0.0820\n",
      "Epoch 17 summary: train_loss: 2.9839 | train_acc: 0.0827 | val_loss: 2.9151 | val_acc: 0.0791\n",
      "Epoch 18\n",
      "Train Batch 100 (every 100 batch): Loss=3.0336; accuracy=0.0856\n",
      "Train Batch 200 (every 100 batch): Loss=2.6248; accuracy=0.0956\n",
      "Train Batch 300 (every 100 batch): Loss=2.5662; accuracy=0.0954\n",
      "Train Batch 400 (every 100 batch): Loss=2.8815; accuracy=0.0953\n",
      "Epoch 18 summary: train_loss: 2.8005 | train_acc: 0.0989 | val_loss: 2.7463 | val_acc: 0.0965\n",
      "Epoch 19\n",
      "Train Batch 100 (every 100 batch): Loss=2.6851; accuracy=0.1212\n",
      "Train Batch 200 (every 100 batch): Loss=2.8700; accuracy=0.1125\n",
      "Train Batch 300 (every 100 batch): Loss=2.8498; accuracy=0.1127\n",
      "Train Batch 400 (every 100 batch): Loss=2.6480; accuracy=0.1122\n",
      "Epoch 19 summary: train_loss: 2.6524 | train_acc: 0.1157 | val_loss: 2.8231 | val_acc: 0.0899\n",
      "Epoch 20\n",
      "Train Batch 100 (every 100 batch): Loss=2.6174; accuracy=0.1169\n",
      "Train Batch 200 (every 100 batch): Loss=2.7767; accuracy=0.1272\n",
      "Train Batch 300 (every 100 batch): Loss=2.4560; accuracy=0.1269\n",
      "Train Batch 400 (every 100 batch): Loss=2.6533; accuracy=0.1342\n",
      "Epoch 20 summary: train_loss: 2.5135 | train_acc: 0.1362 | val_loss: 2.5538 | val_acc: 0.1149\n",
      "Epoch 21\n",
      "Train Batch 100 (every 100 batch): Loss=2.4869; accuracy=0.1550\n",
      "Train Batch 200 (every 100 batch): Loss=2.2096; accuracy=0.1591\n",
      "Train Batch 300 (every 100 batch): Loss=2.5875; accuracy=0.1558\n",
      "Train Batch 400 (every 100 batch): Loss=2.3914; accuracy=0.1570\n",
      "Epoch 21 summary: train_loss: 2.4072 | train_acc: 0.1577 | val_loss: 2.4581 | val_acc: 0.1350\n",
      "Epoch 22\n",
      "Train Batch 100 (every 100 batch): Loss=2.4313; accuracy=0.1794\n",
      "Train Batch 200 (every 100 batch): Loss=2.4229; accuracy=0.1569\n",
      "Train Batch 300 (every 100 batch): Loss=2.3000; accuracy=0.1610\n",
      "Train Batch 400 (every 100 batch): Loss=2.4755; accuracy=0.1622\n",
      "Epoch 22 summary: train_loss: 2.3321 | train_acc: 0.1674 | val_loss: 2.5953 | val_acc: 0.1183\n",
      "Epoch 23\n",
      "Train Batch 100 (every 100 batch): Loss=2.1327; accuracy=0.2000\n",
      "Train Batch 200 (every 100 batch): Loss=2.3848; accuracy=0.1953\n",
      "Train Batch 300 (every 100 batch): Loss=2.3881; accuracy=0.1923\n",
      "Train Batch 400 (every 100 batch): Loss=2.0992; accuracy=0.1933\n",
      "Epoch 23 summary: train_loss: 2.2198 | train_acc: 0.1916 | val_loss: 2.3418 | val_acc: 0.1733\n",
      "Epoch 24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Batch 100 (every 100 batch): Loss=2.1188; accuracy=0.2062\n",
      "Train Batch 200 (every 100 batch): Loss=2.5336; accuracy=0.2069\n",
      "Train Batch 300 (every 100 batch): Loss=2.2547; accuracy=0.2054\n",
      "Train Batch 400 (every 100 batch): Loss=2.3587; accuracy=0.2011\n",
      "Epoch 24 summary: train_loss: 2.1702 | train_acc: 0.2017 | val_loss: 2.3996 | val_acc: 0.1555\n",
      "Epoch 25\n",
      "Train Batch 100 (every 100 batch): Loss=1.8461; accuracy=0.2369\n",
      "Train Batch 200 (every 100 batch): Loss=2.3798; accuracy=0.2241\n",
      "Train Batch 300 (every 100 batch): Loss=1.7655; accuracy=0.2206\n",
      "Train Batch 400 (every 100 batch): Loss=2.2577; accuracy=0.2203\n",
      "Epoch 25 summary: train_loss: 2.0904 | train_acc: 0.2165 | val_loss: 2.3838 | val_acc: 0.1766\n",
      "Epoch 26\n",
      "Train Batch 100 (every 100 batch): Loss=2.1674; accuracy=0.2400\n",
      "Train Batch 200 (every 100 batch): Loss=2.0193; accuracy=0.2400\n",
      "Train Batch 300 (every 100 batch): Loss=1.6424; accuracy=0.2410\n",
      "Train Batch 400 (every 100 batch): Loss=2.2197; accuracy=0.2402\n",
      "Epoch 26 summary: train_loss: 2.0331 | train_acc: 0.2391 | val_loss: 2.4120 | val_acc: 0.1752\n",
      "Epoch 27\n",
      "Train Batch 100 (every 100 batch): Loss=1.9659; accuracy=0.2650\n",
      "Train Batch 200 (every 100 batch): Loss=1.5634; accuracy=0.2562\n",
      "Train Batch 300 (every 100 batch): Loss=2.3927; accuracy=0.2519\n",
      "Train Batch 400 (every 100 batch): Loss=2.3422; accuracy=0.2498\n",
      "Epoch 27 summary: train_loss: 1.9860 | train_acc: 0.2500 | val_loss: 2.3557 | val_acc: 0.1656\n",
      "Epoch 28\n",
      "Train Batch 100 (every 100 batch): Loss=1.9611; accuracy=0.2612\n",
      "Train Batch 200 (every 100 batch): Loss=1.6976; accuracy=0.2566\n",
      "Train Batch 300 (every 100 batch): Loss=2.4460; accuracy=0.2517\n",
      "Train Batch 400 (every 100 batch): Loss=2.0459; accuracy=0.2533\n",
      "Epoch 28 summary: train_loss: 1.9254 | train_acc: 0.2553 | val_loss: 2.3402 | val_acc: 0.1700\n",
      "Epoch 29\n",
      "Train Batch 100 (every 100 batch): Loss=1.8507; accuracy=0.2925\n",
      "Train Batch 200 (every 100 batch): Loss=1.8759; accuracy=0.2850\n",
      "Train Batch 300 (every 100 batch): Loss=1.9023; accuracy=0.2796\n",
      "Train Batch 400 (every 100 batch): Loss=1.6008; accuracy=0.2828\n",
      "Epoch 29 summary: train_loss: 1.8656 | train_acc: 0.2807 | val_loss: 2.4411 | val_acc: 0.1871\n",
      "Epoch 30\n",
      "Train Batch 100 (every 100 batch): Loss=2.0114; accuracy=0.3175\n",
      "Train Batch 200 (every 100 batch): Loss=2.3083; accuracy=0.3072\n",
      "Train Batch 300 (every 100 batch): Loss=1.6480; accuracy=0.3025\n",
      "Train Batch 400 (every 100 batch): Loss=1.7654; accuracy=0.2916\n",
      "Epoch 30 summary: train_loss: 1.8317 | train_acc: 0.2898 | val_loss: 2.6516 | val_acc: 0.1752\n",
      "Epoch 31\n",
      "Train Batch 100 (every 100 batch): Loss=1.9480; accuracy=0.3137\n",
      "Train Batch 200 (every 100 batch): Loss=2.0513; accuracy=0.3141\n",
      "Train Batch 300 (every 100 batch): Loss=1.4872; accuracy=0.3148\n",
      "Train Batch 400 (every 100 batch): Loss=1.5028; accuracy=0.3122\n",
      "Epoch 31 summary: train_loss: 1.7842 | train_acc: 0.3109 | val_loss: 2.5216 | val_acc: 0.1711\n",
      "Epoch 32\n",
      "Train Batch 100 (every 100 batch): Loss=1.9258; accuracy=0.3406\n",
      "Train Batch 200 (every 100 batch): Loss=1.4866; accuracy=0.3428\n",
      "Train Batch 300 (every 100 batch): Loss=1.5545; accuracy=0.3344\n",
      "Train Batch 400 (every 100 batch): Loss=1.7947; accuracy=0.3281\n",
      "Epoch 32 summary: train_loss: 1.7341 | train_acc: 0.3227 | val_loss: 2.7801 | val_acc: 0.1861\n",
      "Epoch 33\n",
      "Train Batch 100 (every 100 batch): Loss=1.3722; accuracy=0.3575\n",
      "Train Batch 200 (every 100 batch): Loss=1.5809; accuracy=0.3469\n",
      "Train Batch 300 (every 100 batch): Loss=1.4485; accuracy=0.3454\n",
      "Train Batch 400 (every 100 batch): Loss=1.6786; accuracy=0.3408\n",
      "Epoch 33 summary: train_loss: 1.7172 | train_acc: 0.3358 | val_loss: 2.4376 | val_acc: 0.2221\n",
      "Epoch 34\n",
      "Train Batch 100 (every 100 batch): Loss=1.6303; accuracy=0.3862\n",
      "Train Batch 200 (every 100 batch): Loss=1.6456; accuracy=0.3775\n",
      "Train Batch 300 (every 100 batch): Loss=1.8721; accuracy=0.3719\n",
      "Train Batch 400 (every 100 batch): Loss=1.8541; accuracy=0.3653\n",
      "Epoch 34 summary: train_loss: 1.6330 | train_acc: 0.3601 | val_loss: 2.6723 | val_acc: 0.1959\n",
      "Epoch 35\n",
      "Train Batch 100 (every 100 batch): Loss=1.3002; accuracy=0.3806\n",
      "Train Batch 200 (every 100 batch): Loss=1.3540; accuracy=0.3678\n",
      "Train Batch 300 (every 100 batch): Loss=1.4908; accuracy=0.3594\n",
      "Train Batch 400 (every 100 batch): Loss=1.8331; accuracy=0.3559\n",
      "Epoch 35 summary: train_loss: 1.6135 | train_acc: 0.3604 | val_loss: 2.7310 | val_acc: 0.1941\n",
      "Epoch 36\n",
      "Train Batch 100 (every 100 batch): Loss=1.5576; accuracy=0.3962\n",
      "Train Batch 200 (every 100 batch): Loss=1.3782; accuracy=0.4175\n",
      "Train Batch 300 (every 100 batch): Loss=1.6710; accuracy=0.4096\n",
      "Train Batch 400 (every 100 batch): Loss=1.8586; accuracy=0.4069\n",
      "Epoch 36 summary: train_loss: 1.5398 | train_acc: 0.4021 | val_loss: 2.5440 | val_acc: 0.2217\n",
      "Epoch 37\n",
      "Train Batch 100 (every 100 batch): Loss=1.7688; accuracy=0.4225\n",
      "Train Batch 200 (every 100 batch): Loss=1.2048; accuracy=0.4078\n",
      "Train Batch 300 (every 100 batch): Loss=1.7752; accuracy=0.4142\n",
      "Train Batch 400 (every 100 batch): Loss=1.6057; accuracy=0.4133\n",
      "Epoch 37 summary: train_loss: 1.4920 | train_acc: 0.4128 | val_loss: 2.6535 | val_acc: 0.2029\n",
      "Epoch 38\n",
      "Train Batch 100 (every 100 batch): Loss=1.6157; accuracy=0.4294\n",
      "Train Batch 200 (every 100 batch): Loss=2.0096; accuracy=0.4484\n",
      "Train Batch 300 (every 100 batch): Loss=1.4540; accuracy=0.4408\n",
      "Train Batch 400 (every 100 batch): Loss=2.0535; accuracy=0.4298\n",
      "Epoch 38 summary: train_loss: 1.4699 | train_acc: 0.4184 | val_loss: 2.7572 | val_acc: 0.1803\n",
      "Epoch 39\n",
      "Train Batch 100 (every 100 batch): Loss=1.1594; accuracy=0.4537\n",
      "Train Batch 200 (every 100 batch): Loss=1.6309; accuracy=0.4478\n",
      "Train Batch 300 (every 100 batch): Loss=1.2414; accuracy=0.4410\n",
      "Train Batch 400 (every 100 batch): Loss=0.9248; accuracy=0.4412\n",
      "Epoch 39 summary: train_loss: 1.4205 | train_acc: 0.4402 | val_loss: 2.7098 | val_acc: 0.2086\n",
      "Epoch 40\n",
      "Train Batch 100 (every 100 batch): Loss=1.3050; accuracy=0.4437\n",
      "Train Batch 200 (every 100 batch): Loss=1.6439; accuracy=0.4497\n",
      "Train Batch 300 (every 100 batch): Loss=1.6484; accuracy=0.4548\n",
      "Train Batch 400 (every 100 batch): Loss=1.2496; accuracy=0.4536\n",
      "Epoch 40 summary: train_loss: 1.4272 | train_acc: 0.4494 | val_loss: 2.9150 | val_acc: 0.2073\n",
      "Epoch 41\n",
      "Train Batch 100 (every 100 batch): Loss=0.9370; accuracy=0.4900\n",
      "Train Batch 200 (every 100 batch): Loss=1.8521; accuracy=0.4872\n",
      "Train Batch 300 (every 100 batch): Loss=1.1818; accuracy=0.4746\n",
      "Train Batch 400 (every 100 batch): Loss=0.9324; accuracy=0.4762\n",
      "Epoch 41 summary: train_loss: 1.3340 | train_acc: 0.4767 | val_loss: 3.0810 | val_acc: 0.2098\n",
      "Epoch 42\n",
      "Train Batch 100 (every 100 batch): Loss=1.4931; accuracy=0.4950\n",
      "Train Batch 200 (every 100 batch): Loss=1.3650; accuracy=0.4953\n",
      "Train Batch 300 (every 100 batch): Loss=1.4916; accuracy=0.4919\n",
      "Train Batch 400 (every 100 batch): Loss=1.3547; accuracy=0.4884\n",
      "Epoch 42 summary: train_loss: 1.3169 | train_acc: 0.4928 | val_loss: 3.0755 | val_acc: 0.2041\n",
      "Epoch 43\n",
      "Train Batch 100 (every 100 batch): Loss=1.3909; accuracy=0.5138\n",
      "Train Batch 200 (every 100 batch): Loss=1.2459; accuracy=0.5122\n",
      "Train Batch 300 (every 100 batch): Loss=1.3071; accuracy=0.5133\n",
      "Train Batch 400 (every 100 batch): Loss=1.1984; accuracy=0.5123\n",
      "Epoch 43 summary: train_loss: 1.2629 | train_acc: 0.5129 | val_loss: 3.0010 | val_acc: 0.1972\n",
      "Epoch 44\n",
      "Train Batch 100 (every 100 batch): Loss=0.9737; accuracy=0.5400\n",
      "Train Batch 200 (every 100 batch): Loss=1.2282; accuracy=0.5437\n",
      "Train Batch 300 (every 100 batch): Loss=1.6159; accuracy=0.5321\n",
      "Train Batch 400 (every 100 batch): Loss=1.1626; accuracy=0.5261\n",
      "Epoch 44 summary: train_loss: 1.2222 | train_acc: 0.5256 | val_loss: 3.0688 | val_acc: 0.2194\n",
      "Epoch 45\n",
      "Train Batch 100 (every 100 batch): Loss=1.3171; accuracy=0.5737\n",
      "Train Batch 200 (every 100 batch): Loss=0.9430; accuracy=0.5725\n",
      "Train Batch 300 (every 100 batch): Loss=1.5800; accuracy=0.5635\n",
      "Train Batch 400 (every 100 batch): Loss=1.2898; accuracy=0.5520\n",
      "Epoch 45 summary: train_loss: 1.1598 | train_acc: 0.5463 | val_loss: 3.1142 | val_acc: 0.2322\n",
      "Epoch 46\n",
      "Train Batch 100 (every 100 batch): Loss=1.2232; accuracy=0.5700\n",
      "Train Batch 200 (every 100 batch): Loss=1.3443; accuracy=0.5669\n",
      "Train Batch 300 (every 100 batch): Loss=1.1864; accuracy=0.5569\n",
      "Train Batch 400 (every 100 batch): Loss=1.1014; accuracy=0.5578\n",
      "Epoch 46 summary: train_loss: 1.1412 | train_acc: 0.5506 | val_loss: 3.0863 | val_acc: 0.2141\n",
      "Epoch 47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Batch 100 (every 100 batch): Loss=1.2018; accuracy=0.5756\n",
      "Train Batch 200 (every 100 batch): Loss=1.1033; accuracy=0.5778\n",
      "Train Batch 300 (every 100 batch): Loss=1.1589; accuracy=0.5646\n",
      "Train Batch 400 (every 100 batch): Loss=0.8275; accuracy=0.5650\n",
      "Epoch 47 summary: train_loss: 1.1255 | train_acc: 0.5655 | val_loss: 3.3174 | val_acc: 0.2077\n",
      "Epoch 48\n",
      "Train Batch 100 (every 100 batch): Loss=1.0397; accuracy=0.6175\n",
      "Train Batch 200 (every 100 batch): Loss=0.6639; accuracy=0.5909\n",
      "Train Batch 300 (every 100 batch): Loss=1.3855; accuracy=0.5867\n",
      "Train Batch 400 (every 100 batch): Loss=1.1090; accuracy=0.5920\n",
      "Epoch 48 summary: train_loss: 1.0854 | train_acc: 0.5869 | val_loss: 3.4144 | val_acc: 0.2243\n",
      "Epoch 49\n",
      "Train Batch 100 (every 100 batch): Loss=1.0501; accuracy=0.5950\n",
      "Train Batch 200 (every 100 batch): Loss=1.4079; accuracy=0.6019\n",
      "Train Batch 300 (every 100 batch): Loss=0.9143; accuracy=0.5954\n",
      "Train Batch 400 (every 100 batch): Loss=0.6530; accuracy=0.5745\n",
      "Epoch 49 summary: train_loss: 1.1013 | train_acc: 0.5769 | val_loss: 3.2470 | val_acc: 0.2214\n",
      "Epoch 50\n",
      "Train Batch 100 (every 100 batch): Loss=0.9022; accuracy=0.6231\n",
      "Train Batch 200 (every 100 batch): Loss=0.5017; accuracy=0.6284\n",
      "Train Batch 300 (every 100 batch): Loss=0.6692; accuracy=0.6225\n",
      "Train Batch 400 (every 100 batch): Loss=1.6564; accuracy=0.6203\n",
      "Epoch 50 summary: train_loss: 1.0043 | train_acc: 0.6123 | val_loss: 3.4371 | val_acc: 0.2201\n",
      "Epoch 51\n",
      "Train Batch 100 (every 100 batch): Loss=1.3043; accuracy=0.6375\n",
      "Train Batch 200 (every 100 batch): Loss=0.9395; accuracy=0.6400\n",
      "Train Batch 300 (every 100 batch): Loss=1.0411; accuracy=0.6319\n",
      "Train Batch 400 (every 100 batch): Loss=0.8711; accuracy=0.6248\n",
      "Epoch 51 summary: train_loss: 0.9970 | train_acc: 0.6158 | val_loss: 3.3108 | val_acc: 0.2259\n",
      "Epoch 52\n",
      "Train Batch 100 (every 100 batch): Loss=0.5580; accuracy=0.6488\n",
      "Train Batch 200 (every 100 batch): Loss=0.6704; accuracy=0.6541\n",
      "Train Batch 300 (every 100 batch): Loss=0.8435; accuracy=0.6513\n",
      "Train Batch 400 (every 100 batch): Loss=0.6620; accuracy=0.6502\n",
      "Epoch 52 summary: train_loss: 0.9052 | train_acc: 0.6430 | val_loss: 3.8682 | val_acc: 0.2014\n",
      "Epoch 53\n",
      "Train Batch 100 (every 100 batch): Loss=0.6882; accuracy=0.6469\n",
      "Train Batch 200 (every 100 batch): Loss=0.6453; accuracy=0.6434\n",
      "Train Batch 300 (every 100 batch): Loss=1.4776; accuracy=0.6283\n",
      "Train Batch 400 (every 100 batch): Loss=0.8764; accuracy=0.6248\n",
      "Epoch 53 summary: train_loss: 0.9707 | train_acc: 0.6251 | val_loss: 3.7611 | val_acc: 0.2022\n",
      "Epoch 54\n",
      "Train Batch 100 (every 100 batch): Loss=0.3441; accuracy=0.6756\n",
      "Train Batch 200 (every 100 batch): Loss=0.8751; accuracy=0.6644\n",
      "Train Batch 300 (every 100 batch): Loss=1.0197; accuracy=0.6583\n",
      "Train Batch 400 (every 100 batch): Loss=0.7322; accuracy=0.6606\n",
      "Epoch 54 summary: train_loss: 0.8955 | train_acc: 0.6572 | val_loss: 3.7279 | val_acc: 0.1991\n",
      "Epoch 55\n",
      "Train Batch 100 (every 100 batch): Loss=1.0347; accuracy=0.6856\n",
      "Train Batch 200 (every 100 batch): Loss=0.9143; accuracy=0.6859\n",
      "Train Batch 300 (every 100 batch): Loss=1.2121; accuracy=0.6704\n",
      "Train Batch 400 (every 100 batch): Loss=0.4463; accuracy=0.6737\n",
      "Epoch 55 summary: train_loss: 0.8834 | train_acc: 0.6669 | val_loss: 3.6950 | val_acc: 0.2119\n",
      "Epoch 56\n",
      "Train Batch 100 (every 100 batch): Loss=0.9648; accuracy=0.6756\n",
      "Train Batch 300 (every 100 batch): Loss=1.0540; accuracy=0.6665\n",
      "Train Batch 400 (every 100 batch): Loss=0.6408; accuracy=0.6589\n",
      "Epoch 56 summary: train_loss: 0.8691 | train_acc: 0.6632 | val_loss: 4.0875 | val_acc: 0.2238\n",
      "Epoch 57\n",
      "Train Batch 100 (every 100 batch): Loss=0.8653; accuracy=0.6681\n",
      "Train Batch 200 (every 100 batch): Loss=0.5683; accuracy=0.6641\n",
      "Train Batch 300 (every 100 batch): Loss=1.1221; accuracy=0.6727\n",
      "Train Batch 400 (every 100 batch): Loss=0.5840; accuracy=0.6753\n",
      "Epoch 57 summary: train_loss: 0.8515 | train_acc: 0.6757 | val_loss: 4.0896 | val_acc: 0.2188\n",
      "Epoch 58\n",
      "Train Batch 100 (every 100 batch): Loss=1.1347; accuracy=0.6794\n",
      "Train Batch 200 (every 100 batch): Loss=0.4989; accuracy=0.6991\n",
      "Train Batch 300 (every 100 batch): Loss=0.7988; accuracy=0.6883\n",
      "Train Batch 400 (every 100 batch): Loss=0.5975; accuracy=0.6780\n",
      "Epoch 58 summary: train_loss: 0.8206 | train_acc: 0.6830 | val_loss: 4.0139 | val_acc: 0.1959\n",
      "Epoch 59\n",
      "Train Batch 100 (every 100 batch): Loss=0.1928; accuracy=0.6950\n",
      "Train Batch 200 (every 100 batch): Loss=1.7931; accuracy=0.6916\n",
      "Train Batch 300 (every 100 batch): Loss=0.6402; accuracy=0.6913\n",
      "Train Batch 400 (every 100 batch): Loss=0.8539; accuracy=0.6959\n",
      "Epoch 59 summary: train_loss: 0.7921 | train_acc: 0.6994 | val_loss: 4.3147 | val_acc: 0.2056\n",
      "Epoch 60\n",
      "Train Batch 100 (every 100 batch): Loss=1.1269; accuracy=0.7169\n",
      "Train Batch 200 (every 100 batch): Loss=0.8900; accuracy=0.7203\n",
      "Train Batch 300 (every 100 batch): Loss=0.6488; accuracy=0.7075\n",
      "Train Batch 400 (every 100 batch): Loss=0.4009; accuracy=0.7016\n",
      "Epoch 60 summary: train_loss: 0.7781 | train_acc: 0.7029 | val_loss: 4.2245 | val_acc: 0.2021\n",
      "Epoch 61\n",
      "Train Batch 100 (every 100 batch): Loss=0.6625; accuracy=0.7262\n",
      "Train Batch 200 (every 100 batch): Loss=0.5352; accuracy=0.7334\n",
      "Train Batch 300 (every 100 batch): Loss=1.3389; accuracy=0.7281\n",
      "Train Batch 400 (every 100 batch): Loss=0.7833; accuracy=0.7195\n",
      "Epoch 61 summary: train_loss: 0.7594 | train_acc: 0.7198 | val_loss: 4.0390 | val_acc: 0.2128\n",
      "Epoch 62\n",
      "Train Batch 100 (every 100 batch): Loss=0.3982; accuracy=0.7375\n",
      "Train Batch 200 (every 100 batch): Loss=0.4828; accuracy=0.7281\n",
      "Train Batch 300 (every 100 batch): Loss=1.4325; accuracy=0.7269\n",
      "Train Batch 400 (every 100 batch): Loss=1.0631; accuracy=0.7159\n",
      "Epoch 62 summary: train_loss: 0.7508 | train_acc: 0.7155 | val_loss: 4.2207 | val_acc: 0.2091\n",
      "Epoch 63\n",
      "Train Batch 100 (every 100 batch): Loss=0.3793; accuracy=0.7575\n",
      "Train Batch 200 (every 100 batch): Loss=0.4372; accuracy=0.7312\n",
      "Train Batch 300 (every 100 batch): Loss=0.5661; accuracy=0.7279\n",
      "Train Batch 400 (every 100 batch): Loss=0.9478; accuracy=0.7291\n",
      "Epoch 63 summary: train_loss: 0.7048 | train_acc: 0.7318 | val_loss: 4.4364 | val_acc: 0.2008\n",
      "Epoch 64\n",
      "Train Batch 100 (every 100 batch): Loss=0.5266; accuracy=0.7869\n",
      "Train Batch 200 (every 100 batch): Loss=0.5294; accuracy=0.7369\n",
      "Train Batch 300 (every 100 batch): Loss=0.5216; accuracy=0.7398\n",
      "Train Batch 400 (every 100 batch): Loss=0.7209; accuracy=0.7434\n",
      "Epoch 64 summary: train_loss: 0.7123 | train_acc: 0.7414 | val_loss: 4.3474 | val_acc: 0.1981\n",
      "Epoch 65\n",
      "Train Batch 100 (every 100 batch): Loss=0.6106; accuracy=0.7719\n",
      "Train Batch 200 (every 100 batch): Loss=0.4693; accuracy=0.7650\n",
      "Train Batch 300 (every 100 batch): Loss=0.5651; accuracy=0.7569\n",
      "Train Batch 400 (every 100 batch): Loss=0.5180; accuracy=0.7489\n",
      "Epoch 65 summary: train_loss: 0.6670 | train_acc: 0.7470 | val_loss: 4.4232 | val_acc: 0.2301\n",
      "Epoch 66\n",
      "Train Batch 100 (every 100 batch): Loss=0.6657; accuracy=0.7519\n",
      "Train Batch 200 (every 100 batch): Loss=0.5843; accuracy=0.7406\n",
      "Train Batch 300 (every 100 batch): Loss=0.9286; accuracy=0.7254\n",
      "Train Batch 400 (every 100 batch): Loss=0.7977; accuracy=0.7334\n",
      "Epoch 66 summary: train_loss: 0.7326 | train_acc: 0.7400 | val_loss: 4.4275 | val_acc: 0.2089\n",
      "Epoch 67\n",
      "Train Batch 100 (every 100 batch): Loss=0.5247; accuracy=0.7575\n",
      "Train Batch 200 (every 100 batch): Loss=0.6024; accuracy=0.7747\n",
      "Train Batch 300 (every 100 batch): Loss=2.0843; accuracy=0.7625\n",
      "Train Batch 400 (every 100 batch): Loss=0.7061; accuracy=0.7487\n",
      "Epoch 67 summary: train_loss: 0.6962 | train_acc: 0.7454 | val_loss: 4.2484 | val_acc: 0.2094\n",
      "Epoch 68\n",
      "Train Batch 100 (every 100 batch): Loss=0.5017; accuracy=0.7925\n",
      "Train Batch 200 (every 100 batch): Loss=0.5609; accuracy=0.7856\n",
      "Train Batch 300 (every 100 batch): Loss=1.2746; accuracy=0.7804\n",
      "Train Batch 400 (every 100 batch): Loss=0.6248; accuracy=0.7650\n",
      "Epoch 68 summary: train_loss: 0.6263 | train_acc: 0.7637 | val_loss: 4.4731 | val_acc: 0.2166\n",
      "Epoch 69\n",
      "Train Batch 100 (every 100 batch): Loss=0.5429; accuracy=0.8181\n",
      "Train Batch 200 (every 100 batch): Loss=0.4349; accuracy=0.7991\n",
      "Train Batch 300 (every 100 batch): Loss=1.0286; accuracy=0.7873\n",
      "Train Batch 400 (every 100 batch): Loss=0.4227; accuracy=0.7802\n",
      "Epoch 69 summary: train_loss: 0.6026 | train_acc: 0.7753 | val_loss: 4.3672 | val_acc: 0.2138\n",
      "Epoch 70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Batch 100 (every 100 batch): Loss=0.6353; accuracy=0.8100\n",
      "Train Batch 200 (every 100 batch): Loss=0.6775; accuracy=0.7947\n",
      "Train Batch 300 (every 100 batch): Loss=0.8788; accuracy=0.7919\n",
      "Train Batch 400 (every 100 batch): Loss=1.1105; accuracy=0.7834\n",
      "Epoch 70 summary: train_loss: 0.6107 | train_acc: 0.7720 | val_loss: 4.5437 | val_acc: 0.1976\n",
      "Epoch 71\n",
      "Train Batch 100 (every 100 batch): Loss=0.5074; accuracy=0.7887\n",
      "Train Batch 200 (every 100 batch): Loss=0.9475; accuracy=0.7903\n",
      "Train Batch 300 (every 100 batch): Loss=0.4285; accuracy=0.7752\n",
      "Train Batch 400 (every 100 batch): Loss=0.5376; accuracy=0.7784\n",
      "Epoch 71 summary: train_loss: 0.6325 | train_acc: 0.7718 | val_loss: 4.8072 | val_acc: 0.1990\n",
      "Epoch 72\n",
      "Train Batch 100 (every 100 batch): Loss=0.2289; accuracy=0.7856\n",
      "Train Batch 200 (every 100 batch): Loss=0.4670; accuracy=0.7862\n",
      "Train Batch 300 (every 100 batch): Loss=0.3773; accuracy=0.7983\n",
      "Train Batch 400 (every 100 batch): Loss=0.4545; accuracy=0.7933\n",
      "Epoch 72 summary: train_loss: 0.5619 | train_acc: 0.7905 | val_loss: 4.5598 | val_acc: 0.2166\n",
      "Epoch 73\n",
      "Train Batch 100 (every 100 batch): Loss=0.8790; accuracy=0.8094\n",
      "Train Batch 200 (every 100 batch): Loss=0.3653; accuracy=0.8106\n",
      "Train Batch 300 (every 100 batch): Loss=0.9789; accuracy=0.7977\n",
      "Train Batch 400 (every 100 batch): Loss=0.2718; accuracy=0.7995\n",
      "Epoch 73 summary: train_loss: 0.5764 | train_acc: 0.7892 | val_loss: 4.5176 | val_acc: 0.2181\n",
      "Epoch 74\n",
      "Train Batch 100 (every 100 batch): Loss=0.4397; accuracy=0.8287\n",
      "Train Batch 200 (every 100 batch): Loss=0.2962; accuracy=0.8103\n",
      "Train Batch 300 (every 100 batch): Loss=0.9243; accuracy=0.8000\n",
      "Train Batch 400 (every 100 batch): Loss=0.4707; accuracy=0.7928\n",
      "Epoch 74 summary: train_loss: 0.5714 | train_acc: 0.7938 | val_loss: 4.7871 | val_acc: 0.1994\n",
      "Epoch 75\n",
      "Train Batch 100 (every 100 batch): Loss=0.7457; accuracy=0.8200\n",
      "Train Batch 200 (every 100 batch): Loss=0.6816; accuracy=0.8137\n",
      "Train Batch 300 (every 100 batch): Loss=0.5633; accuracy=0.8071\n",
      "Train Batch 400 (every 100 batch): Loss=1.2058; accuracy=0.8044\n",
      "Epoch 75 summary: train_loss: 0.5477 | train_acc: 0.7968 | val_loss: 4.6494 | val_acc: 0.2217\n",
      "Epoch 76\n",
      "Train Batch 100 (every 100 batch): Loss=0.1979; accuracy=0.8144\n",
      "Train Batch 200 (every 100 batch): Loss=0.2563; accuracy=0.8300\n"
     ]
    }
   ],
   "source": [
    "channel_idx=None\n",
    "non_classes=None\n",
    "if opt.kind==\"from-scratch\":\n",
    "    loss_history, accuracy_val, accuracy_test = net_trainer(\n",
    "            net,\n",
    "            loaders,\n",
    "            opt,\n",
    "            channel_idx,\n",
    "            nonclasses,\n",
    "            None,\n",
    "            True,\n",
    "            model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0199dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# val =accuracy_val\n",
    "# test = accuracy_test\n",
    "\n",
    "# print(\"Validation accuracy: \", val)\n",
    "# print(\"Test accuracy: \", test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c56b086",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913f370e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9a7d31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2334ae6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b77fc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3080e706",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17823cb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8b650c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdb911b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b43930",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28237288",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ded073",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfcbdda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1fb11a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b75470",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8939417",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a5c258",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e7de01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597563e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d74a8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db30ed4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1544e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
