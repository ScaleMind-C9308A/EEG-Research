{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea7f6401",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from analysis import *\n",
    "import argparse\n",
    "from sys import platform\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c192d33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(12)\n",
    "torch.cuda.manual_seed(12)\n",
    "np.random.seed(12)\n",
    "torch.backends.cudnn.deterministics = True\n",
    "torch.set_num_threads(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "daf1a8a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "2\n",
      "0\n",
      "<torch.cuda.device object at 0x7f01b5f43f40>\n",
      "NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.current_device())\n",
    "\n",
    "\n",
    "print(torch.cuda.device(0))\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff733115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iv: image option\n",
    "length = 440\n",
    "channel = 128\n",
    "min_CNN = 200\n",
    "n_classes = 40\n",
    "classes = range(n_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b68db2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if platform == \"linux\" or platform == \"linux2\":\n",
    "    torch_models_dir = r\"/media/mountHDD1/LanxHuyen/CVPR2017\"\n",
    "elif platform == \"win32\":\n",
    "    torch_models_dir = r\"D:\\Data\\CVPR2021-02785\\CVPR2021-02785\\preprocessed\\torch_models\"\n",
    "block_splits_all = '/media/mountHDD1/LanxHuyen/CVPR2017/block_splits_by_image_all.pth' \n",
    "eeg_raw = '/media/mountHDD1/LanxHuyen/CVPR2017/eeg_55_95_std.pth'\n",
    "# block_splits_all, block_splits_single, eeg_14_70, eeg_55_95, eeg_5_95, eeg_raw = os.listdir(torch_models_dir)\n",
    "# print(os.listdir(torch_models_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd3ad4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/mountHDD1/LanxHuyen/CVPR2017/eeg_55_95_std.pth \n",
      " /media/mountHDD1/LanxHuyen/CVPR2017/block_splits_by_image_all.pth\n"
     ]
    }
   ],
   "source": [
    "# eeg_dataset = os.path.join(torch_models_dir, eeg_5_95)\n",
    "# splits_all_path = os.path.join(torch_models_dir, block_splits_all)\n",
    "eeg_dataset = eeg_raw\n",
    "splits_all_path = block_splits_all\n",
    "\n",
    "print(eeg_dataset,'\\n', splits_all_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "659d4a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits_all = torch.load(splits_all_path)\n",
    "# splits_single = torch.load(splits_single_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f3ef344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "3\n",
      "7984\n",
      "1996\n",
      "1985\n",
      "[0, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 27, 29, 33, 35, 36, 37, 38, 39, 42, 43, 44, 45, 46, 47, 48, 51, 52, 54, 55]\n",
      "[1, 2, 3, 4, 6, 8, 9, 12, 13, 20, 25, 26, 27, 28, 30, 32, 33, 35, 37, 38, 39, 40, 44, 45, 46, 50, 52, 54, 56, 58, 59, 60, 62, 65, 68, 72, 73, 74, 76, 81]\n",
      "[2, 3, 4, 5, 6, 7, 8, 10, 11, 13]\n",
      "[1, 2, 4, 7, 9, 10, 12, 13, 14, 15]\n"
     ]
    }
   ],
   "source": [
    "print(len(splits_all['splits']))\n",
    "print(len(splits_all['splits'][0]))\n",
    "\n",
    "print(len(splits_all['splits'][5]['train']))\n",
    "print(len(splits_all['splits'][5]['val']))\n",
    "print(len(splits_all['splits'][5]['test']))\n",
    "print(splits_all['splits'][0]['train'][:40])\n",
    "print(splits_all['splits'][1]['train'][:40])\n",
    "print(splits_all['splits'][2]['train'][:10])\n",
    "print(splits_all['splits'][3]['train'][:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89460bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "dict_keys(['dataset', 'labels', 'images'])\n",
      "40\n",
      "1996\n",
      "11965\n",
      "n02389026 n03888257 n03584829 n02607072 n03297495 n03063599 n03792782 n04086273 n02510455 n11939491 n02951358 n02281787 n02106662 n04120489 n03590841 n02992529 n03445777 n03180011 n02906734 n07873807 n03773504 n02492035 n03982430 n03709823 n03100240 n03376595 n03877472 n03775071 n03272010 n04069434 n03452741 n03792972 n07753592 n13054560 n03197337 n02504458 n02690373 n03272562 n04044716 n02124075\n",
      "n02951358_31190\n",
      "torch.Size([128, 500])\n",
      "{'eeg': tensor([[ 1.7147e-02,  2.3283e-01,  4.0575e-01,  ..., -6.0889e-01,\n",
      "         -3.4890e-01, -3.1541e-02],\n",
      "        [ 2.3134e-02,  2.8261e-01,  4.9883e-01,  ..., -6.2466e-01,\n",
      "         -3.5702e-01, -3.1965e-02],\n",
      "        [-2.3792e-02, -4.0139e-01, -7.0958e-01,  ...,  7.1729e-01,\n",
      "          4.1546e-01,  1.6468e-02],\n",
      "        ...,\n",
      "        [ 1.1773e-02,  2.2352e-02,  2.3448e-02,  ..., -1.5988e-01,\n",
      "         -9.4679e-02, -1.2204e-02],\n",
      "        [ 1.3201e-03,  1.5371e-02,  2.5863e-02,  ..., -1.9464e-02,\n",
      "         -1.1201e-02, -3.8365e-04],\n",
      "        [ 5.7138e-03,  1.0533e-01,  1.7794e-01,  ..., -1.9640e-01,\n",
      "         -1.1400e-01, -6.4751e-03]]), 'image': 1950, 'label': 16, 'subject': 4}\n"
     ]
    }
   ],
   "source": [
    "eeg_loaded = torch.load(eeg_dataset)\n",
    "dataset, labels, images = [eeg_loaded[k] for k in eeg_loaded.keys()]\n",
    "print(len(eeg_loaded))\n",
    "print(eeg_loaded.keys())\n",
    "print(len(labels))\n",
    "print(len(images))\n",
    "print(len(dataset))\n",
    "print(*labels)\n",
    "print(images[0])\n",
    "print(dataset[0]['eeg'].shape)\n",
    "print(dataset[1950])\n",
    "#Trial 0-1995 - subject 4\n",
    "#Trial 1996 - 3980 - subject 1\n",
    "#Trial 3981 - 5976 - subject 6\n",
    "#Trial 5977 - 7972 - subject 3\n",
    "#Trial 7973 - 9968 - subject 2\n",
    "#Trial 9969 - 11964 - subject 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d20c958c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(results_file='results.pkl', subject=0, time_low=20, time_high=460, eeg_dataset='/media/mountHDD1/LanxHuyen/CVPR2017/eeg_55_95_std.pth', model_type='model10', splits_path='/media/mountHDD1/LanxHuyen/CVPR2017/block_splits_by_image_all.pth', split_num=0, split_name='train', batch_size=16, optim='Adam', learning_rate=0.001, learning_rate_decay_by=0.5, learning_rate_decay_every=10, epochs=100, GPUindex=0, kind='from-scratch', no_cuda=False, classifier=None)\n"
     ]
    }
   ],
   "source": [
    "opt = {\n",
    "    # Dataset options\n",
    "#     \"iv\": \"image\",\n",
    "#     \"offset\": None,\n",
    "    \"results_file\": \"results.pkl\",\n",
    "    \"subject\": 0,\n",
    "    \"time_low\": 20,\n",
    "    \"time_high\": 460,\n",
    "#     \"run\": \"none\",\n",
    "    \"eeg_dataset\": eeg_dataset,\n",
    "    \"model_type\": \"model10\",\n",
    "    \"splits_path\": splits_all_path,\n",
    "    \"split_num\": 0,\n",
    "    \"split_name\": \"train\",\n",
    "#     \"fold\": 5,\n",
    "    #Training options\n",
    "    \"batch_size\": 16,\n",
    "    \"optim\": \"Adam\",\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"learning_rate_decay_by\": 0.5,\n",
    "    \"learning_rate_decay_every\": 10,\n",
    "    \"epochs\": 100,\n",
    "    \"GPUindex\": 0,\n",
    "    \"kind\":\"from-scratch\",\n",
    "    #Backend options\n",
    "    \"no_cuda\": False,\n",
    "    \"classifier\": None\n",
    "}\n",
    "opt = argparse.Namespace(**opt)\n",
    "print(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce8d6e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from torch.utils.data import DataLoader\n",
    "# from data_loader import EEGDataset, Splitter, SplitterWithData\n",
    "from data_loader_CVPR2017 import EEGDataset, Splitter\n",
    "from EEG_Encoder.LSTM import classifier_LSTM\n",
    "from EEG_Encoder.CNN import classifier_CNN\n",
    "from EEG_Encoder.EEGNet import classifier_EEGNet\n",
    "from EEG_Encoder.SyncNet import classifier_SyncNet\n",
    "from EEG_Encoder.EEGChannelNet import classifier_EEGChannelNet\n",
    "from EEG_Encoder.net_generator import Classifier\n",
    "from EEG_Encoder.net_trainer import net_trainer\n",
    "from p_values import *\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a5b475c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(\n",
    "#              offset,\n",
    "             eeg_dataset,\n",
    "             splits_path,\n",
    "             split_num, # (0-5) - 6 fold cross validation\n",
    "#              total, \n",
    "#              classes,\n",
    "#              classifier,\n",
    "             batch_size,\n",
    "#              GPUindex,\n",
    "#              length, # 500\n",
    "#              channel, # 128\n",
    "#              min_CNN,\n",
    "             opt,\n",
    "             kind=\"from-scratch\"):        \n",
    "    # Load dataset\n",
    "    dataset = EEGDataset(opt, eeg_dataset)\n",
    "    print(\"DONE: LOAD DATASET\")\n",
    "#     # Create loaders for LSTM/MLP/CNN/SCNN/EEGNet/SyncNet/EEGChannelNet\n",
    "#     if kind==\"from-scratch\":\n",
    "#         relabel = False\n",
    "#     if kind==\"incremental\":\n",
    "#         relabel = False\n",
    "#     if kind==\"no-model-file\":\n",
    "#         relabel = True\n",
    "    splitter = {split: Splitter(dataset,\n",
    "                    splits_path,\n",
    "                    split_num,\n",
    "                    split_name=split) for split in [\"train\", \"val\", \"test\"]}\n",
    "    loaders = {split: DataLoader(\n",
    "                        splitter[split],\n",
    "                        batch_size = batch_size,\n",
    "                        drop_last = False,\n",
    "                        shuffle = True)\n",
    "                    for split in [\"train\", \"val\", \"test\"]}\n",
    "    channel_idx = None    \n",
    "    print(\"DONE: Create loaders for model\")            \n",
    "    return dataset, loaders, splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a242cae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Options\n",
    "opt.classifier = \"EEGChannelNet\"\n",
    "opt.batch_size = 32\n",
    "# opt.kind = \"from-scratch\"\n",
    "# opt.run = \"imagenet40-1000\"\n",
    "# opt.fold = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "633488a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE: LOAD DATASET\n",
      "DONE: Create loaders for model\n"
     ]
    }
   ],
   "source": [
    "dataset, loaders, splitter = load_dataset(\n",
    "#              offset,\n",
    "             opt.eeg_dataset,\n",
    "             opt.splits_path,\n",
    "             opt.split_num, # (0-5) - 6 fold cross validation\n",
    "#              total, \n",
    "#              classes,\n",
    "#              classifier,\n",
    "             opt.batch_size,\n",
    "#              GPUindex,\n",
    "#              length, # 500\n",
    "#              channel, # 128\n",
    "#              min_CNN,\n",
    "             opt,\n",
    "             opt.kind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e99fc973",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'data_loader_CVPR2017.EEGDataset'>\n",
      "<class 'dict'>\n",
      "3 [249, 63, 63]\n",
      "1: Label val: 37; label train: 10\n",
      "2: Label val: 38; label train: 10\n",
      "3: Label val: 11; label train: 30\n",
      "4: Label val: 10; label train: 25\n",
      "5: Label val: 7; label train: 18\n",
      "6: Label val: 35; label train: 3\n",
      "7: Label val: 13; label train: 8\n",
      "8: Label val: 2; label train: 11\n",
      "9: Label val: 14; label train: 18\n",
      "10: Label val: 2; label train: 28\n",
      "11: Label val: 33; label train: 38\n",
      "12: Label val: 26; label train: 20\n",
      "13: Label val: 34; label train: 3\n",
      "14: Label val: 18; label train: 28\n",
      "15: Label val: 11; label train: 23\n",
      "16: Label val: 32; label train: 0\n",
      "17: Label val: 6; label train: 34\n",
      "18: Label val: 22; label train: 20\n",
      "19: Label val: 24; label train: 23\n",
      "20: Label val: 24; label train: 39\n",
      "21: Label val: 29; label train: 0\n",
      "22: Label val: 3; label train: 34\n",
      "23: Label val: 25; label train: 21\n",
      "24: Label val: 11; label train: 39\n",
      "25: Label val: 22; label train: 6\n",
      "26: Label val: 36; label train: 26\n",
      "27: Label val: 30; label train: 20\n",
      "28: Label val: 32; label train: 1\n",
      "29: Label val: 22; label train: 27\n",
      "30: Label val: 39; label train: 37\n",
      "31: Label val: 23; label train: 19\n",
      "32: Label val: 4; label train: 9\n",
      "33: Label val: 10; label train: 12\n",
      "34: Label val: 3; label train: 18\n",
      "35: Label val: 24; label train: 25\n",
      "36: Label val: 27; label train: 27\n",
      "37: Label val: 20; label train: 34\n",
      "38: Label val: 1; label train: 35\n",
      "39: Label val: 38; label train: 8\n",
      "40: Label val: 15; label train: 29\n"
     ]
    }
   ],
   "source": [
    "# loaders: divide the splits data in each fold with batch_size\n",
    "# Each fold has {train: 8000 idx, val: 2000 idx, test: 2000 idx}\n",
    "# Each loader batch has {train: 2000 idx, val: 250 idx, test: 250 idx}\n",
    "print(type(dataset))\n",
    "print(type(loaders))\n",
    "print(len(loaders), [len(loaders[name]) for name in [\"train\", \"val\", \"test\"] ])\n",
    "# for i, (input, target) in enumerate(loaders[\"train\"]):\n",
    "#     if i<20:\n",
    "#         print(f\"{i+1}: Target size: {target.size()}; input size: {input.size()}\")\n",
    "for i in range(0, 40):\n",
    "    eeg, label_val = splitter[\"val\"][i]\n",
    "    eeg, label_train = splitter[\"train\"][i]\n",
    "    print(f\"{i+1}: Label val: {label_val}; label train: {label_train}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "39a07cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE: CREATE TORCH CLASSIFIER\n",
      "classifier_EEGChannelNet(\n",
      "  (encoder): FeaturesExtractor(\n",
      "    (temporal_block): TemporalBlock(\n",
      "      (layers): ModuleList(\n",
      "        (0): ConvLayer2D(\n",
      "          (norm): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv): Conv2d(1, 10, kernel_size=(1, 33), stride=(1, 2), padding=(0, 16))\n",
      "          (drop): Dropout2d(p=0.2, inplace=False)\n",
      "        )\n",
      "        (1): ConvLayer2D(\n",
      "          (norm): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv): Conv2d(1, 10, kernel_size=(1, 33), stride=(1, 2), padding=(0, 32), dilation=(1, 2))\n",
      "          (drop): Dropout2d(p=0.2, inplace=False)\n",
      "        )\n",
      "        (2): ConvLayer2D(\n",
      "          (norm): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv): Conv2d(1, 10, kernel_size=(1, 33), stride=(1, 2), padding=(0, 64), dilation=(1, 4))\n",
      "          (drop): Dropout2d(p=0.2, inplace=False)\n",
      "        )\n",
      "        (3): ConvLayer2D(\n",
      "          (norm): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv): Conv2d(1, 10, kernel_size=(1, 33), stride=(1, 2), padding=(0, 128), dilation=(1, 8))\n",
      "          (drop): Dropout2d(p=0.2, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (spatial_block): SpatialBlock(\n",
      "      (layers): ModuleList(\n",
      "        (0): ConvLayer2D(\n",
      "          (norm): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv): Conv2d(40, 50, kernel_size=(128, 1), stride=(2, 1), padding=(63, 0))\n",
      "          (drop): Dropout2d(p=0.2, inplace=False)\n",
      "        )\n",
      "        (1): ConvLayer2D(\n",
      "          (norm): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv): Conv2d(40, 50, kernel_size=(64, 1), stride=(2, 1), padding=(31, 0))\n",
      "          (drop): Dropout2d(p=0.2, inplace=False)\n",
      "        )\n",
      "        (2): ConvLayer2D(\n",
      "          (norm): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv): Conv2d(40, 50, kernel_size=(42, 1), stride=(2, 1), padding=(20, 0))\n",
      "          (drop): Dropout2d(p=0.2, inplace=False)\n",
      "        )\n",
      "        (3): ConvLayer2D(\n",
      "          (norm): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv): Conv2d(40, 50, kernel_size=(32, 1), stride=(2, 1), padding=(15, 0))\n",
      "          (drop): Dropout2d(p=0.2, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (res_blocks): ModuleList(\n",
      "      (0-3): 4 x Sequential(\n",
      "        (0): ResidualBlock(\n",
      "          (conv1): Conv2d(200, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(200, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (1): ConvLayer2D(\n",
      "          (norm): BatchNorm2d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv): Conv2d(200, 200, kernel_size=(3, 3), stride=(2, 2))\n",
      "          (drop): Dropout2d(p=0.2, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_conv): ConvLayer2D(\n",
      "      (norm): BatchNorm2d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv): Conv2d(200, 50, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (drop): Dropout2d(p=0.2, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=500, out_features=1000, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Linear(in_features=1000, out_features=40, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "classifier_EEGChannelNet                      [1, 40]                   --\n",
       "├─FeaturesExtractor: 1-1                      [1, 50, 1, 10]            --\n",
       "│    └─TemporalBlock: 2-1                     [1, 40, 128, 220]         --\n",
       "│    │    └─ModuleList: 3-1                   --                        1,368\n",
       "│    └─SpatialBlock: 2-2                      [1, 200, 64, 220]         --\n",
       "│    │    └─ModuleList: 3-2                   --                        532,520\n",
       "│    └─ModuleList: 2-3                        --                        --\n",
       "│    │    └─Sequential: 3-3                   [1, 200, 31, 109]         1,081,400\n",
       "│    │    └─Sequential: 3-4                   [1, 200, 15, 54]          1,081,400\n",
       "│    │    └─Sequential: 3-5                   [1, 200, 7, 26]           1,081,400\n",
       "│    │    └─Sequential: 3-6                   [1, 200, 3, 12]           1,081,400\n",
       "│    └─ConvLayer2D: 2-4                       [1, 50, 1, 10]            --\n",
       "│    │    └─BatchNorm2d: 3-7                  [1, 200, 3, 12]           400\n",
       "│    │    └─ReLU: 3-8                         [1, 200, 3, 12]           --\n",
       "│    │    └─Conv2d: 3-9                       [1, 50, 1, 10]            90,050\n",
       "│    │    └─Dropout2d: 3-10                   [1, 50, 1, 10]            --\n",
       "├─Sequential: 1-2                             [1, 40]                   --\n",
       "│    └─Linear: 2-5                            [1, 1000]                 501,000\n",
       "│    └─ReLU: 2-6                              [1, 1000]                 --\n",
       "│    └─Linear: 2-7                            [1, 40]                   40,040\n",
       "===============================================================================================\n",
       "Total params: 5,490,978\n",
       "Trainable params: 5,490,978\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 22.41\n",
       "===============================================================================================\n",
       "Input size (MB): 0.23\n",
       "Forward/backward pass size (MB): 224.12\n",
       "Params size (MB): 21.96\n",
       "Estimated Total Size (MB): 246.30\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net, nonclasses = Classifier(\n",
    "                 n_classes,\n",
    "                 classes,\n",
    "                 opt.classifier,\n",
    "                 opt.GPUindex,\n",
    "                 length,\n",
    "                 channel,\n",
    "                 min_CNN,\n",
    "                 opt.kind)\n",
    "# print(len(nonclasses))\n",
    "summary(net, input_size=(1,128, 440))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a8d6995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CVPR2017-EEGChannelNet-440-128-Test_\n"
     ]
    }
   ],
   "source": [
    "model_path = (   \"CVPR2017-\" +\n",
    "                  opt.classifier+\n",
    "                  \"-\"+\n",
    "                  str(length)+\n",
    "                  \"-\"+\n",
    "                  str(channel)+\n",
    "                  \"-\"+\n",
    "                  'Test_' )\n",
    "print(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b753db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(results_file='results.pkl', subject=0, time_low=20, time_high=460, eeg_dataset='/media/mountHDD1/LanxHuyen/CVPR2017/eeg_55_95_std.pth', model_type='model10', splits_path='/media/mountHDD1/LanxHuyen/CVPR2017/block_splits_by_image_all.pth', split_num=0, split_name='train', batch_size=32, optim='Adam', learning_rate=0.001, learning_rate_decay_by=0.5, learning_rate_decay_every=10, epochs=100, GPUindex=0, kind='from-scratch', no_cuda=False, classifier='EEGChannelNet')\n"
     ]
    }
   ],
   "source": [
    "print(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0199dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# val = results[\"val_acc\"]\n",
    "# # test = results[\"test_acc\"]\n",
    "\n",
    "# print(\"Validation accuracy: \", val)\n",
    "# # print(\"Test accuracy: \", test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c56b086",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913f370e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9a7d31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2334ae6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b77fc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3080e706",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17823cb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8b650c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdb911b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b43930",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28237288",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ded073",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfcbdda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1fb11a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b75470",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8939417",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a5c258",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e7de01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597563e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d74a8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db30ed4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1544e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
