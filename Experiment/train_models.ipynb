{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3675927f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from analysis import *\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e2301c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(12)\n",
    "torch.cuda.manual_seed(12)\n",
    "np.random.seed(12)\n",
    "torch.backends.cudnn.deterministics = True\n",
    "torch.set_num_threads(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7454d60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "0\n",
      "<torch.cuda.device object at 0x0000022DCB509730>\n",
      "NVIDIA TITAN V\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.current_device())\n",
    "\n",
    "print(torch.cuda.device(0))\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "499dbec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iv: image option\n",
    "length = 512\n",
    "channel = 96\n",
    "min_CNN = 200\n",
    "n_classes = 40\n",
    "classes = range(n_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cef3bc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_models_dir = r\"D:\\Data\\CVPR2021-02785\\CVPR2021-02785\\preprocessed\\torch_models\"\n",
    "eeg_dataset, splits_path = os.listdir(torch_models_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37e239e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Data\\CVPR2021-02785\\CVPR2021-02785\\preprocessed\\torch_models\\imagenet40-1000-1.pth \n",
      " D:\\Data\\CVPR2021-02785\\CVPR2021-02785\\preprocessed\\torch_models\\imagenet40-1000-1_splits.pth\n"
     ]
    }
   ],
   "source": [
    "eeg_dataset = os.path.join(torch_models_dir, eeg_dataset)\n",
    "splits_path = os.path.join(torch_models_dir, splits_path)\n",
    "print(eeg_dataset,'\\n', splits_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "009ff0e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image\n"
     ]
    }
   ],
   "source": [
    "opt = {\n",
    "    # Dataset options\n",
    "    \"iv\": \"image\",\n",
    "    \"offset\": None,\n",
    "    \"results_file\": \"results.pkl\",\n",
    "    \"subject\": 0,\n",
    "    \"run\": \"none\",\n",
    "    \"eeg_dataset\": eeg_dataset,\n",
    "    \"splits_path\": splits_path,\n",
    "    \"fold\": 5,\n",
    "    #Training options\n",
    "    \"batch_size\": 16,\n",
    "    \"optim\": \"Adam\",\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"learning_rate_decay_by\": 0.5,\n",
    "    \"learning_rate_decay_every\": 10,\n",
    "    \"epochs\": 100,\n",
    "    \"GPUindex\": 0,\n",
    "    \"kind\":\"incremental\",\n",
    "    #Backend options\n",
    "    \"no_cuda\": False,\n",
    "    \"classifier\": None\n",
    "}\n",
    "opt = argparse.Namespace(**opt)\n",
    "print(opt.iv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c69a8f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from data_loader import EEGDataset, Splitter, SplitterWithData\n",
    "from EEG_Encoder.LSTM import classifier_LSTM\n",
    "from EEG_Encoder.CNN import classifier_CNN\n",
    "from EEG_Encoder.EEGNet import classifier_EEGNet\n",
    "from EEG_Encoder.SyncNet import classifier_SyncNet\n",
    "from EEG_Encoder.EEGChannelNet import classifier_EEGChannelNet\n",
    "from EEG_Encoder.net_trainer import net_trainer\n",
    "from p_values import *\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0dfd17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(iv,\n",
    "             offset,\n",
    "             fold,\n",
    "             eeg_dataset,\n",
    "             splits_path,\n",
    "             total,\n",
    "             classes,\n",
    "             classifier,\n",
    "             batch_size,\n",
    "             GPUindex,\n",
    "             length, # 512\n",
    "             channel, # 96\n",
    "             min_CNN,\n",
    "             opt,\n",
    "             kind):\n",
    "    for split_num in range(fold):\n",
    "        \n",
    "        # Load dataset\n",
    "        dataset = EEGDataset(iv, eeg_dataset, classifier, map_idx = None)\n",
    "        print(\"DONE: LOAD DATASET\")\n",
    "        # Create loaders for LSTM/MLP/CNN/SCNN/EEGNet/SyncNet/EEGChannelNet\n",
    "        if kind==\"from-scratch\":\n",
    "            relabel = True\n",
    "        if kind==\"incremental\":\n",
    "            relabel = False\n",
    "        if kind==\"no-model-file\":\n",
    "            relabel = True\n",
    "        loaders = {split: DataLoader(\n",
    "            SplitterWithData(iv,\n",
    "                        dataset,\n",
    "                        splits_path,\n",
    "                        classes,\n",
    "                        split_num,\n",
    "                        split,\n",
    "                        relabel),\n",
    "            batch_size = batch_size,\n",
    "            drop_last = False,\n",
    "            shuffle = True)\n",
    "                for split in [\"train\", \"val\", \"test\"]}\n",
    "        channel_idx = None    \n",
    "        print(\"DONE: Create loaders for model\")            \n",
    "        return dataset, loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9444ef36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Classifier(iv,\n",
    "             offset,\n",
    "             fold,\n",
    "             eeg_dataset,\n",
    "             splits_path,\n",
    "             total,\n",
    "             classes,\n",
    "             classifier,\n",
    "             batch_size,\n",
    "             GPUindex,\n",
    "             length, # 512\n",
    "             channel, # 96\n",
    "             min_CNN,\n",
    "             opt,\n",
    "             kind):\n",
    "    if classifier==\"LSTM\":\n",
    "        if kind==\"from-scratch\":\n",
    "            output_size = 128\n",
    "        if kind==\"incremental\":\n",
    "            output_size = 128\n",
    "        if kind==\"no-model-file\":\n",
    "            output_size = 128\n",
    "        net = classifier_LSTM(\n",
    "            True,\n",
    "            input_size = channel,\n",
    "            lstm_layers = 1,\n",
    "            lstm_size = 128,\n",
    "            output1_size = 128,\n",
    "            output2_size = None,\n",
    "            GPUindex = GPUindex)\n",
    "    elif classifier==\"LSTM1\":\n",
    "        if kind==\"from-scratch\":\n",
    "            output_size = 128\n",
    "        if kind==\"incremental\":\n",
    "            output_size = 128\n",
    "        if kind==\"no-model-file\":\n",
    "            output_size = 128\n",
    "        net = classifier_LSTM(\n",
    "            False,\n",
    "            input_size = channel,\n",
    "            lstm_layers = 1,\n",
    "            lstm_size = 128,\n",
    "            output1_size = 128,\n",
    "            output2_size = None,\n",
    "            GPUindex = GPUindex)\n",
    "    elif classifier==\"LSTM2\":\n",
    "        if kind==\"from-scratch\":\n",
    "            output_size = len(classes)\n",
    "        if kind==\"incremental\":\n",
    "            output_size = total\n",
    "        if kind==\"no-model-file\":\n",
    "            output_size = len(classes)\n",
    "        net = classifier_LSTM(\n",
    "            False,\n",
    "            input_size = channel,\n",
    "            lstm_layers = 1,\n",
    "            lstm_size = 128,\n",
    "            output1_size = output_size,\n",
    "            output2_size = None,\n",
    "            GPUindex = GPUindex)\n",
    "    elif classifier==\"LSTM3\":\n",
    "        if kind==\"from-scratch\":\n",
    "            output_size = len(classes)\n",
    "        if kind==\"incremental\":\n",
    "            output_size = total\n",
    "        if kind==\"no-model-file\":\n",
    "            output_size = len(classes)\n",
    "        net = classifier_LSTM(\n",
    "            True,\n",
    "            input_size = channel,\n",
    "            lstm_layers = 1,\n",
    "            lstm_size = 128,\n",
    "            output1_size = output_size,\n",
    "            output2_size = None,\n",
    "            GPUindex = GPUindex)\n",
    "    elif classifier==\"LSTM4\":\n",
    "        if kind==\"from-scratch\":\n",
    "            output_size = len(classes)\n",
    "        if kind==\"incremental\":\n",
    "            output_size = total\n",
    "        if kind==\"no-model-file\":\n",
    "            output_size = len(classes)\n",
    "        net = classifier_LSTM(\n",
    "            True,\n",
    "            input_size = channel,\n",
    "            lstm_layers = 1,\n",
    "            lstm_size = 128,\n",
    "            output1_size = 128,\n",
    "            output2_size = output_size,\n",
    "            GPUindex = GPUindex)        \n",
    "    elif classifier==\"CNN\":\n",
    "        if length<min_CNN:\n",
    "            return\n",
    "        if kind==\"from-scratch\":\n",
    "            output_size = len(classes)\n",
    "        if kind==\"incremental\":\n",
    "            output_size = total\n",
    "        if kind==\"no-model-file\":\n",
    "            output_size = len(classes)\n",
    "        net = classifier_CNN(\n",
    "            in_channel = channel,\n",
    "            num_points = length,\n",
    "                output_size = output_size)\n",
    "    elif classifier==\"EEGNet\":\n",
    "        if length<min_CNN:\n",
    "            return\n",
    "        if kind==\"from-scratch\":\n",
    "            output_size = len(classes)\n",
    "        if kind==\"incremental\":\n",
    "            output_size = total\n",
    "        if kind==\"no-model-file\":\n",
    "            output_size = len(classes)\n",
    "        net = classifier_EEGNet(channel, length)\n",
    "    elif classifier==\"SyncNet\":\n",
    "        if length<min_CNN:\n",
    "            return \n",
    "        if kind==\"from-scratch\":\n",
    "            output_size = len(classes)\n",
    "        if kind==\"incremental\":\n",
    "            output_size = total\n",
    "        if kind==\"no-model-file\":\n",
    "            output_size = len(classes)\n",
    "        net = classifier_SyncNet(channel, length)\n",
    "    elif classifier==\"EEGChannelNet\":\n",
    "        if length<min_CNN:\n",
    "            return\n",
    "        if kind==\"from-scratch\":\n",
    "            output_size = len(classes)\n",
    "        if kind==\"incremental\":\n",
    "            output_size = total\n",
    "        if kind==\"no-model-file\":\n",
    "            output_size = len(classes)\n",
    "        net = classifier_EEGChannelNet(channel, length)\n",
    "    print(\"DONE: CREATE TORCH CLASSIFIER\")\n",
    "    print(net)\n",
    "    nonclasses = [i for i in range(output_size) if i not in classes]\n",
    "    return net, nonclasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "aae9c3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM network\n",
    "opt.classifier = \"LSTM4\"\n",
    "opt.batch_size = 16\n",
    "opt.kind = \"from-scratch\"\n",
    "opt.run = \"imagenet40-1000\"\n",
    "opt.fold = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810cc0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, loaders = load_dataset(opt.iv,\n",
    "                             opt.offset,\n",
    "                             opt.fold,\n",
    "                             opt.eeg_dataset,\n",
    "                             opt.splits_path,\n",
    "                             n_classes,\n",
    "                             classes,\n",
    "                             opt.classifier,\n",
    "                             opt.batch_size,\n",
    "                             opt.GPUindex,\n",
    "                             length,\n",
    "                             channel,\n",
    "                             min_CNN,\n",
    "                             opt,\n",
    "                             opt.kind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8191cbe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'data_loader.EEGDataset'>\n",
      "<class 'dict'>\n",
      "3 [2000, 250, 250]\n",
      "40000\n"
     ]
    }
   ],
   "source": [
    "print(type(dataset))\n",
    "print(type(loaders))\n",
    "print(len(loaders), [len(loaders[name]) for name in [\"train\", \"val\", \"test\"] ])\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "14ee5423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE: CREATE TORCH CLASSIFIER\n",
      "classifier_LSTM(\n",
      "  (lstm): LSTM(96, 128, batch_first=True)\n",
      "  (output1): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (output2): Linear(in_features=128, out_features=40, bias=True)\n",
      ")\n",
      "0\n",
      "torch.Size([1, 512, 96])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "classifier_LSTM                          [1, 40]                   --\n",
       "├─LSTM: 1-1                              [1, 512, 128]             115,712\n",
       "├─Linear: 1-2                            [1, 128]                  16,512\n",
       "├─ReLU: 1-3                              [1, 128]                  --\n",
       "├─Linear: 1-4                            [1, 40]                   5,160\n",
       "==========================================================================================\n",
       "Total params: 137,384\n",
       "Trainable params: 137,384\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 59.27\n",
       "==========================================================================================\n",
       "Input size (MB): 0.20\n",
       "Forward/backward pass size (MB): 0.53\n",
       "Params size (MB): 0.55\n",
       "Estimated Total Size (MB): 1.27\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net, nonclasses = Classifier(opt.iv,\n",
    "                 opt.offset,\n",
    "                 opt.fold,\n",
    "                 opt.eeg_dataset,\n",
    "                 opt.splits_path,\n",
    "                 n_classes,\n",
    "                 classes,\n",
    "                 opt.classifier,\n",
    "                 opt.batch_size,\n",
    "                 opt.GPUindex,\n",
    "                 length,\n",
    "                 channel,\n",
    "                 min_CNN,\n",
    "                 opt,\n",
    "                 opt.kind)\n",
    "print(len(nonclasses))\n",
    "summary(net, input_size=(1, 512, 96))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "711f9772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image-LSTM4-512-96-0\n"
     ]
    }
   ],
   "source": [
    "model_path = (opt.iv+\n",
    "                  \"-\"+\n",
    "                  opt.classifier+\n",
    "                  \"-\"+\n",
    "                  str(length)+\n",
    "                  \"-\"+\n",
    "                  str(channel)+\n",
    "                  \"-\"+\n",
    "                  str(0))\n",
    "channel_idx=None\n",
    "print(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0eb0cdb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "torch.Size([16, 96, 512])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "input.size(-1) must be equal to input_size. Expected 96, got 512",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m opt\u001b[38;5;241m.\u001b[39mkind\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom-scratch\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m----> 2\u001b[0m     accuracy_val, accuracy_test, counts_val, counts_test \u001b[38;5;241m=\u001b[39m \u001b[43mnet_trainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m            \u001b[49m\u001b[43mloaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m            \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m            \u001b[49m\u001b[43mchannel_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnonclasses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\GithubCloneRepo\\EEG-Research\\Experiment\\EEG_Encoder\\net_trainer.py:63\u001b[0m, in \u001b[0;36mnet_trainer\u001b[1;34m(net, loaders, opt, channel_idx, nonclasses, pretrain, train, save)\u001b[0m\n\u001b[0;32m     61\u001b[0m target \u001b[38;5;241m=\u001b[39m Variable(target)\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# Forward\u001b[39;00m\n\u001b[1;32m---> 63\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     64\u001b[0m loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mcross_entropy(output, target)\n\u001b[0;32m     65\u001b[0m losses[split] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32mD:\\GithubCloneRepo\\EEG-Research\\.env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mD:\\GithubCloneRepo\\EEG-Research\\Experiment\\EEG_Encoder\\LSTM.py:45\u001b[0m, in \u001b[0;36mclassifier_LSTM.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     42\u001b[0m     lstm_init \u001b[38;5;241m=\u001b[39m (lstm_init[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcuda(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mGPUindex),\n\u001b[0;32m     43\u001b[0m                  lstm_init[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcuda(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mGPUindex))\n\u001b[0;32m     44\u001b[0m lstm_init \u001b[38;5;241m=\u001b[39m (Variable(lstm_init[\u001b[38;5;241m0\u001b[39m]), Variable(lstm_init[\u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m---> 45\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlstm_init\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m][:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]\n\u001b[0;32m     46\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput1(x)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelup:\n",
      "File \u001b[1;32mD:\\GithubCloneRepo\\EEG-Research\\.env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mD:\\GithubCloneRepo\\EEG-Research\\.env\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:772\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    768\u001b[0m     \u001b[38;5;66;03m# Each batch of the hidden state should match the input sequence that\u001b[39;00m\n\u001b[0;32m    769\u001b[0m     \u001b[38;5;66;03m# the user believes he/she is passing in.\u001b[39;00m\n\u001b[0;32m    770\u001b[0m     hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[1;32m--> 772\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_forward_args\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    773\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    774\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers,\n\u001b[0;32m    775\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first)\n",
      "File \u001b[1;32mD:\\GithubCloneRepo\\EEG-Research\\.env\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:697\u001b[0m, in \u001b[0;36mLSTM.check_forward_args\u001b[1;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[0;32m    692\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_forward_args\u001b[39m(\u001b[38;5;28mself\u001b[39m,  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[0;32m    693\u001b[0m                        \u001b[38;5;28minput\u001b[39m: Tensor,\n\u001b[0;32m    694\u001b[0m                        hidden: Tuple[Tensor, Tensor],\n\u001b[0;32m    695\u001b[0m                        batch_sizes: Optional[Tensor],\n\u001b[0;32m    696\u001b[0m                        ):\n\u001b[1;32m--> 697\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    698\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_hidden_size(hidden[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_expected_hidden_size(\u001b[38;5;28minput\u001b[39m, batch_sizes),\n\u001b[0;32m    699\u001b[0m                            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected hidden[0] size \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_hidden_size(hidden[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_expected_cell_size(\u001b[38;5;28minput\u001b[39m, batch_sizes),\n\u001b[0;32m    701\u001b[0m                            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected hidden[1] size \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mD:\\GithubCloneRepo\\EEG-Research\\.env\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:210\u001b[0m, in \u001b[0;36mRNNBase.check_input\u001b[1;34m(self, input, batch_sizes)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    207\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput must have \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m dimensions, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    208\u001b[0m             expected_input_dim, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim()))\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_size \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m--> 210\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    211\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput.size(-1) must be equal to input_size. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    212\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_size, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: input.size(-1) must be equal to input_size. Expected 96, got 512"
     ]
    }
   ],
   "source": [
    "if opt.kind==\"from-scratch\":\n",
    "    accuracy_val, accuracy_test, counts_val, counts_test = net_trainer(\n",
    "            net,\n",
    "            loaders,\n",
    "            opt,\n",
    "            channel_idx,\n",
    "            nonclasses,\n",
    "            None,\n",
    "            True,\n",
    "            model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38570ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
