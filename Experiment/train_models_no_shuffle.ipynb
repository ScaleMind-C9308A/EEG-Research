{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3675927f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from analysis import *\n",
    "import argparse\n",
    "from sys import platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e2301c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(12)\n",
    "torch.cuda.manual_seed(12)\n",
    "np.random.seed(12)\n",
    "torch.backends.cudnn.deterministics = True\n",
    "torch.set_num_threads(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7454d60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "0\n",
      "<torch.cuda.device object at 0x7ff9e1b48b80>\n",
      "NVIDIA TITAN V\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.current_device())\n",
    "\n",
    "print(torch.cuda.device(0))\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "499dbec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iv: image option\n",
    "length = 512\n",
    "channel = 96\n",
    "min_CNN = 200\n",
    "n_classes = 40\n",
    "classes = range(n_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cef3bc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "if platform == \"linux\" or platform == \"linux2\":\n",
    "    torch_models_dir = r\"/media/titan/AI Research/Data/CVPR2021-02785/CVPR2021-02785/preprocessed/torch_models\"\n",
    "elif platform == \"win32\":\n",
    "    torch_models_dir = r\"D:\\Data\\CVPR2021-02785\\CVPR2021-02785\\preprocessed\\torch_models\"\n",
    "eeg_dataset, splits_path, splits_shuffled_path = os.listdir(torch_models_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37e239e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/titan/AI Research/Data/CVPR2021-02785/CVPR2021-02785/preprocessed/torch_models/imagenet40-1000-1.pth \n",
      " /media/titan/AI Research/Data/CVPR2021-02785/CVPR2021-02785/preprocessed/torch_models/imagenet40-1000-1_splits.pth\n"
     ]
    }
   ],
   "source": [
    "eeg_dataset = os.path.join(torch_models_dir, eeg_dataset)\n",
    "splits_path = os.path.join(torch_models_dir, splits_path)\n",
    "# splits_path = os.path.join(torch_models_dir, splits_shuffled_path)\n",
    "print(eeg_dataset,'\\n', splits_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "009ff0e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image\n"
     ]
    }
   ],
   "source": [
    "opt = {\n",
    "    # Dataset options\n",
    "    \"iv\": \"image\",\n",
    "    \"offset\": None,\n",
    "    \"results_file\": \"results.pkl\",\n",
    "    \"subject\": 0,\n",
    "    \"run\": \"none\",\n",
    "    \"eeg_dataset\": eeg_dataset,\n",
    "    \"splits_path\": splits_path,\n",
    "    \"fold\": 5,\n",
    "    #Training options\n",
    "    \"batch_size\": 16,\n",
    "    \"optim\": \"Adam\",\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"learning_rate_decay_by\": 0.5,\n",
    "    \"learning_rate_decay_every\": 10,\n",
    "    \"epochs\": 100,\n",
    "    \"GPUindex\": 0,\n",
    "    \"kind\":\"incremental\",\n",
    "    #Backend options\n",
    "    \"no_cuda\": False,\n",
    "    \"classifier\": None\n",
    "}\n",
    "opt = argparse.Namespace(**opt)\n",
    "print(opt.iv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c8df9cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from torch.utils.data import DataLoader\n",
    "from data_loader import EEGDataset, Splitter, SplitterWithData\n",
    "from EEG_Encoder.LSTM import classifier_LSTM\n",
    "from EEG_Encoder.LSTM_per_channel import classifier_LSTM_per_channel\n",
    "from EEG_Encoder.CNN import classifier_CNN\n",
    "from EEG_Encoder.EEGNet import classifier_EEGNet\n",
    "from EEG_Encoder.SyncNet import classifier_SyncNet\n",
    "from EEG_Encoder.EEGChannelNet import classifier_EEGChannelNet\n",
    "from EEG_Encoder.net_generator import Classifier\n",
    "from EEG_Encoder.net_trainer import net_trainer\n",
    "from p_values import *\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30bd6700",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(iv,\n",
    "             offset,\n",
    "             eeg_dataset,\n",
    "             splits_path,\n",
    "             split_num, # (0-4) - 5 fold cross validation\n",
    "             total,\n",
    "             classes,\n",
    "             classifier,\n",
    "             batch_size,\n",
    "             GPUindex,\n",
    "             length, # 512\n",
    "             channel, # 96\n",
    "             min_CNN,\n",
    "             opt,\n",
    "             kind):        \n",
    "    # Load dataset\n",
    "    dataset = EEGDataset(iv, eeg_dataset, classifier, map_idx = None)\n",
    "    print(\"DONE: LOAD DATASET\")\n",
    "    # Create loaders for LSTM/MLP/CNN/SCNN/EEGNet/SyncNet/EEGChannelNet\n",
    "    if kind==\"from-scratch\":\n",
    "        relabel = False\n",
    "    if kind==\"incremental\":\n",
    "        relabel = False\n",
    "    if kind==\"no-model-file\":\n",
    "        relabel = True\n",
    "    splitter = {split: SplitterWithData(iv,\n",
    "                    dataset,\n",
    "                    splits_path,\n",
    "                    classes,\n",
    "                    split_num,\n",
    "                    split,\n",
    "                    relabel) for split in [\"train\", \"val\", \"test\"]}\n",
    "    loaders = {split: DataLoader(\n",
    "                        splitter[split],\n",
    "                        batch_size = batch_size,\n",
    "                        drop_last = False,\n",
    "                        shuffle = True)\n",
    "                    for split in [\"train\", \"val\", \"test\"]}\n",
    "    channel_idx = None    \n",
    "    print(\"DONE: Create loaders for model\")            \n",
    "    return dataset, loaders, splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aae9c3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM per channel network\n",
    "opt.classifier = \"LSTM_per_channel\"\n",
    "opt.batch_size = 16\n",
    "opt.kind = \"from-scratch\"\n",
    "opt.run = \"imagenet40-1000\"\n",
    "opt.fold = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8455f252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE: LOAD DATASET\n",
      "DONE: Create loaders for model\n"
     ]
    }
   ],
   "source": [
    "dataset, loaders, splitter = load_dataset(opt.iv,\n",
    "                             opt.offset,\n",
    "                             opt.eeg_dataset,\n",
    "                             opt.splits_path,\n",
    "                             0, #split_num\n",
    "                             n_classes,\n",
    "                             classes,\n",
    "                             opt.classifier,\n",
    "                             opt.batch_size,\n",
    "                             opt.GPUindex,\n",
    "                             length,\n",
    "                             channel,\n",
    "                             min_CNN,\n",
    "                             opt,\n",
    "                             opt.kind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8191cbe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'data_loader.EEGDataset'>\n",
      "<class 'dict'>\n",
      "3 [2000, 250, 250]\n",
      "1: Label val: 0; label train: 0\n",
      "2: Label val: 17; label train: 17\n",
      "3: Label val: 28; label train: 28\n",
      "4: Label val: 7; label train: 7\n",
      "5: Label val: 33; label train: 33\n",
      "6: Label val: 12; label train: 12\n",
      "7: Label val: 21; label train: 21\n",
      "8: Label val: 3; label train: 3\n",
      "9: Label val: 25; label train: 25\n",
      "10: Label val: 36; label train: 36\n",
      "11: Label val: 10; label train: 10\n",
      "12: Label val: 15; label train: 15\n",
      "13: Label val: 19; label train: 19\n",
      "14: Label val: 31; label train: 31\n",
      "15: Label val: 23; label train: 23\n",
      "16: Label val: 5; label train: 5\n",
      "17: Label val: 38; label train: 38\n",
      "18: Label val: 8; label train: 8\n",
      "19: Label val: 1; label train: 1\n",
      "20: Label val: 34; label train: 34\n",
      "21: Label val: 29; label train: 29\n",
      "22: Label val: 26; label train: 26\n",
      "23: Label val: 13; label train: 13\n",
      "24: Label val: 11; label train: 11\n",
      "25: Label val: 22; label train: 22\n",
      "26: Label val: 18; label train: 18\n",
      "27: Label val: 6; label train: 6\n",
      "28: Label val: 16; label train: 16\n",
      "29: Label val: 4; label train: 4\n",
      "30: Label val: 20; label train: 20\n",
      "31: Label val: 32; label train: 32\n",
      "32: Label val: 9; label train: 9\n",
      "33: Label val: 37; label train: 37\n",
      "34: Label val: 24; label train: 24\n",
      "35: Label val: 39; label train: 39\n",
      "36: Label val: 2; label train: 2\n",
      "37: Label val: 35; label train: 35\n",
      "38: Label val: 30; label train: 30\n",
      "39: Label val: 27; label train: 27\n",
      "40: Label val: 14; label train: 14\n"
     ]
    }
   ],
   "source": [
    "# loaders: divide the splits data in each fold with batch_size\n",
    "# Each fold has {train: 32000 idx, val: 4000 idx, test: 4000 idx}\n",
    "# Each loader batch has {train: 2000 idx, val: 250idx, test: 250 idx}\n",
    "print(type(dataset))\n",
    "print(type(loaders))\n",
    "print(len(loaders), [len(loaders[name]) for name in [\"train\", \"val\", \"test\"] ])\n",
    "for i in range(0, 40):\n",
    "    eeg, label_val = splitter[\"val\"][i*100]\n",
    "    eeg, label_train = splitter[\"train\"][i*800]\n",
    "    print(f\"{i+1}: Label val: {label_val}; label train: {label_train}\")\n",
    "# print(splitter[\"val\"].split_idx[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e95cc78d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE: CREATE TORCH CLASSIFIER\n",
      "classifier_LSTM_per_channel(\n",
      "  (lstm_per_channel): LSTM(1, 1, batch_first=True)\n",
      "  (lstm_full1): LSTM(96, 128, batch_first=True)\n",
      "  (lstm_full2): LSTM(128, 64, batch_first=True)\n",
      "  (linear): Linear(in_features=64, out_features=40, bias=True)\n",
      "  (softmax): Softmax(dim=None)\n",
      ")\n",
      "torch.Size([1, 96, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/titan/GithubClonedRepo/EEG-Research/Experiment/EEG_Encoder/LSTM_per_channel.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x_in = torch.tensor(X[:, i, :]) # x_in: (batch_size, 1, timesteps)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X after concat:  torch.Size([1, 512, 96])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/titan/GithubClonedRepo/EEG-Research/Experiment/EEG_Encoder/LSTM_per_channel.py:53: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  X = self.softmax(X)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "classifier_LSTM_per_channel              [1, 40]                   --\n",
       "├─LSTM: 1-1                              [1, 512, 1]               16\n",
       "├─LSTM: 1-2                              [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-3                              [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-4                              [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-5                              [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-6                              [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-7                              [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-8                              [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-9                              [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-10                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-11                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-12                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-13                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-14                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-15                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-16                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-17                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-18                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-19                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-20                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-21                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-22                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-23                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-24                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-25                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-26                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-27                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-28                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-29                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-30                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-31                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-32                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-33                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-34                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-35                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-36                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-37                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-38                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-39                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-40                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-41                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-42                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-43                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-44                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-45                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-46                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-47                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-48                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-49                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-50                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-51                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-52                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-53                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-54                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-55                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-56                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-57                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-58                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-59                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-60                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-61                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-62                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-63                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-64                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-65                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-66                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-67                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-68                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-69                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-70                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-71                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-72                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-73                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-74                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-75                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-76                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-77                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-78                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-79                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-80                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-81                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-82                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-83                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-84                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-85                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-86                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-87                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-88                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-89                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-90                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-91                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-92                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-93                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-94                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-95                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-96                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-97                             [1, 512, 128]             115,712\n",
       "├─LSTM: 1-98                             [1, 512, 64]              49,664\n",
       "├─Linear: 1-99                           [1, 40]                   2,600\n",
       "├─Softmax: 1-100                         [1, 40]                   --\n",
       "==========================================================================================\n",
       "Total params: 167,992\n",
       "Trainable params: 167,992\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 85.46\n",
       "==========================================================================================\n",
       "Input size (MB): 0.20\n",
       "Forward/backward pass size (MB): 0.79\n",
       "Params size (MB): 0.67\n",
       "Estimated Total Size (MB): 1.66\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net, nonclasses = Classifier(\n",
    "                 n_classes,\n",
    "                 classes,\n",
    "                 opt.classifier,\n",
    "                 opt.GPUindex,\n",
    "                 length,\n",
    "                 channel,\n",
    "                 min_CNN,\n",
    "                 opt.kind)\n",
    "# print(len(nonclasses))\n",
    "summary(net, input_size=(1, 96, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9527792e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image-LSTM_per_channel-512-96-0-noshuffle\n"
     ]
    }
   ],
   "source": [
    "model_path = (opt.iv+\n",
    "                  \"-\"+\n",
    "                  opt.classifier+\n",
    "                  \"-\"+\n",
    "                  str(length)+\n",
    "                  \"-\"+\n",
    "                  str(channel)+\n",
    "                  \"-\"+\n",
    "                  str(0)) + \"-noshuffle\"\n",
    "                  \n",
    "channel_idx=None\n",
    "print(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "789e1be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(iv='image', offset=None, results_file='results.pkl', subject=0, run='imagenet40-1000', eeg_dataset='/media/titan/AI Research/Data/CVPR2021-02785/CVPR2021-02785/preprocessed/torch_models/imagenet40-1000-1.pth', splits_path='/media/titan/AI Research/Data/CVPR2021-02785/CVPR2021-02785/preprocessed/torch_models/imagenet40-1000-1_splits.pth', fold=5, batch_size=16, optim='Adam', learning_rate=0.001, learning_rate_decay_by=0.5, learning_rate_decay_every=10, epochs=100, GPUindex=0, kind='from-scratch', no_cuda=False, classifier='LSTM_per_channel')\n"
     ]
    }
   ],
   "source": [
    "print(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d6a7ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/titan/GithubClonedRepo/EEG-Research/Experiment/EEG_Encoder/LSTM_per_channel.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x_in = torch.tensor(X[:, i, :]) # x_in: (batch_size, 1, timesteps)\n",
      "/home/titan/GithubClonedRepo/EEG-Research/Experiment/EEG_Encoder/LSTM_per_channel.py:53: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  X = self.softmax(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1000: Loss=3.6873857975006104; accuracy=0.02537500113248825\n",
      "Batch 2000: Loss=3.6891353130340576; accuracy=0.024625001475214958\n",
      "Validation accuracy: 0.02500000037252903\n",
      "epoch 2\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.687983751296997; accuracy=0.0240625012665987\n",
      "Batch 2000: Loss=3.6889331340789795; accuracy=0.02331250160932541\n",
      "Validation accuracy: 0.02500000037252903\n",
      "epoch 3\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.689671277999878; accuracy=0.024000000208616257\n",
      "Batch 2000: Loss=3.689314126968384; accuracy=0.023000001907348633\n",
      "Validation accuracy: 0.02500000037252903\n",
      "epoch 4\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.6888632774353027; accuracy=0.02550000138580799\n",
      "Batch 2000: Loss=3.6890547275543213; accuracy=0.024562500417232513\n",
      "Validation accuracy: 0.02500000037252903\n",
      "epoch 5\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.6888232231140137; accuracy=0.02393750101327896\n",
      "Batch 2000: Loss=3.6888437271118164; accuracy=0.023500001057982445\n",
      "Validation accuracy: 0.02500000037252903\n",
      "epoch 6\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.689565896987915; accuracy=0.023750001564621925\n",
      "Batch 2000: Loss=3.6891965866088867; accuracy=0.02381250075995922\n",
      "Validation accuracy: 0.02500000037252903\n",
      "epoch 7\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.689566135406494; accuracy=0.02512500062584877\n",
      "Batch 2000: Loss=3.6886911392211914; accuracy=0.02446875162422657\n",
      "Validation accuracy: 0.02500000037252903\n",
      "epoch 8\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.688829183578491; accuracy=0.02187500149011612\n",
      "Batch 2000: Loss=3.688943386077881; accuracy=0.02303125150501728\n",
      "Validation accuracy: 0.02500000037252903\n",
      "epoch 9\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.688673734664917; accuracy=0.023375000804662704\n",
      "Batch 2000: Loss=3.6890549659729004; accuracy=0.023750001564621925\n",
      "Validation accuracy: 0.02500000037252903\n",
      "epoch 10\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.68965482711792; accuracy=0.023625001311302185\n",
      "Batch 2000: Loss=3.688647508621216; accuracy=0.023093750700354576\n",
      "Validation accuracy: 0.02500000037252903\n",
      "epoch 11\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.690310001373291; accuracy=0.027375001460313797\n",
      "Batch 2000: Loss=3.689303159713745; accuracy=0.025312501937150955\n",
      "Validation accuracy: 0.02525000087916851\n",
      "epoch 12\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.688455820083618; accuracy=0.02537500113248825\n",
      "Batch 2000: Loss=3.688398599624634; accuracy=0.024500001221895218\n",
      "Validation accuracy: 0.0247500017285347\n",
      "epoch 13\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.688878297805786; accuracy=0.02356250025331974\n",
      "Batch 2000: Loss=3.6891515254974365; accuracy=0.023250000551342964\n",
      "Validation accuracy: 0.02550000138580799\n",
      "epoch 14\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.687528610229492; accuracy=0.027625001966953278\n",
      "Batch 2000: Loss=3.689973831176758; accuracy=0.025812501087784767\n",
      "Validation accuracy: 0.0247500017285347\n",
      "epoch 15\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.688997983932495; accuracy=0.025937501341104507\n",
      "Batch 2000: Loss=3.688898801803589; accuracy=0.024625001475214958\n",
      "Validation accuracy: 0.02500000037252903\n",
      "epoch 16\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.688981771469116; accuracy=0.024500001221895218\n",
      "Batch 2000: Loss=3.688821792602539; accuracy=0.023593751713633537\n",
      "Validation accuracy: 0.02500000037252903\n",
      "epoch 17\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.688389539718628; accuracy=0.02306250110268593\n",
      "Batch 2000: Loss=3.689079761505127; accuracy=0.02225000038743019\n",
      "Validation accuracy: 0.024250000715255737\n",
      "epoch 18\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.6882851123809814; accuracy=0.02512500062584877\n",
      "Batch 2000: Loss=3.6895313262939453; accuracy=0.023750001564621925\n",
      "Validation accuracy: 0.0247500017285347\n",
      "epoch 19\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.6898579597473145; accuracy=0.024000000208616257\n",
      "Batch 2000: Loss=3.6887967586517334; accuracy=0.023406250402331352\n",
      "Validation accuracy: 0.02525000087916851\n",
      "epoch 20\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.6886048316955566; accuracy=0.02500000037252903\n",
      "Batch 2000: Loss=3.688532590866089; accuracy=0.024562500417232513\n",
      "Validation accuracy: 0.02525000087916851\n",
      "epoch 21\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.6887588500976562; accuracy=0.024187501519918442\n",
      "Batch 2000: Loss=3.689366102218628; accuracy=0.023781251162290573\n",
      "Validation accuracy: 0.02550000138580799\n",
      "epoch 22\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.6906254291534424; accuracy=0.025437500327825546\n",
      "Batch 2000: Loss=3.689114809036255; accuracy=0.024437502026557922\n",
      "Validation accuracy: 0.0247500017285347\n",
      "epoch 23\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.6891794204711914; accuracy=0.02537500113248825\n",
      "Batch 2000: Loss=3.6889712810516357; accuracy=0.025437500327825546\n",
      "Validation accuracy: 0.02525000087916851\n",
      "epoch 24\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.635326623916626; accuracy=0.02512500062584877\n",
      "Batch 2000: Loss=3.688769578933716; accuracy=0.024812500923871994\n",
      "Validation accuracy: 0.02550000138580799\n",
      "epoch 25\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.6832115650177; accuracy=0.025062501430511475\n",
      "Batch 2000: Loss=3.688387155532837; accuracy=0.024687500670552254\n",
      "Validation accuracy: 0.02525000087916851\n",
      "epoch 26\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.6902575492858887; accuracy=0.02787500061094761\n",
      "Batch 2000: Loss=3.687453508377075; accuracy=0.025812501087784767\n",
      "Validation accuracy: 0.024000000208616257\n",
      "epoch 27\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.6896770000457764; accuracy=0.02487500198185444\n",
      "Batch 2000: Loss=3.690063953399658; accuracy=0.02553125098347664\n",
      "Validation accuracy: 0.02525000087916851\n",
      "epoch 28\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.6863505840301514; accuracy=0.027687501162290573\n",
      "Batch 2000: Loss=3.6913444995880127; accuracy=0.02771875075995922\n",
      "Validation accuracy: 0.026250001043081284\n",
      "epoch 29\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1000: Loss=3.6834816932678223; accuracy=0.027375001460313797\n",
      "Batch 2000: Loss=3.692352533340454; accuracy=0.027937501668930054\n",
      "Validation accuracy: 0.023250000551342964\n",
      "epoch 30\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.6792259216308594; accuracy=0.0266875009983778\n",
      "Batch 2000: Loss=3.686769485473633; accuracy=0.026718750596046448\n",
      "Validation accuracy: 0.026250001043081284\n",
      "epoch 31\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.6857948303222656; accuracy=0.029000001028180122\n",
      "Batch 2000: Loss=3.6874165534973145; accuracy=0.028031250461935997\n",
      "Validation accuracy: 0.027750002220273018\n",
      "epoch 32\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.68756365776062; accuracy=0.026250001043081284\n",
      "Batch 2000: Loss=3.681086540222168; accuracy=0.027687501162290573\n",
      "Validation accuracy: 0.02550000138580799\n",
      "epoch 33\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.6896700859069824; accuracy=0.030250001698732376\n",
      "Batch 2000: Loss=3.692352771759033; accuracy=0.02956250123679638\n",
      "Validation accuracy: 0.027250001206994057\n",
      "epoch 34\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.6586806774139404; accuracy=0.03306250274181366\n",
      "Batch 2000: Loss=3.694626808166504; accuracy=0.03109375201165676\n",
      "Validation accuracy: 0.02800000086426735\n",
      "epoch 35\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.6904025077819824; accuracy=0.03231250122189522\n",
      "Batch 2000: Loss=3.684098958969116; accuracy=0.030937502160668373\n",
      "Validation accuracy: 0.02500000037252903\n",
      "epoch 36\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.684521436691284; accuracy=0.03231250122189522\n",
      "Batch 2000: Loss=3.692140579223633; accuracy=0.03212499991059303\n",
      "Validation accuracy: 0.02500000037252903\n",
      "epoch 37\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.6949872970581055; accuracy=0.03500000014901161\n",
      "Batch 2000: Loss=3.695533514022827; accuracy=0.034156251698732376\n",
      "Validation accuracy: 0.023750001564621925\n",
      "epoch 38\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.695291042327881; accuracy=0.03543750196695328\n",
      "Batch 2000: Loss=3.652843475341797; accuracy=0.03462500125169754\n",
      "Validation accuracy: 0.0247500017285347\n",
      "epoch 39\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.6911911964416504; accuracy=0.035875000059604645\n",
      "Batch 2000: Loss=3.646963596343994; accuracy=0.03556250035762787\n",
      "Validation accuracy: 0.023250000551342964\n",
      "epoch 40\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.6890037059783936; accuracy=0.039000000804662704\n",
      "Batch 2000: Loss=3.690978527069092; accuracy=0.03765625134110451\n",
      "Validation accuracy: 0.02550000138580799\n",
      "epoch 41\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.692185401916504; accuracy=0.03956250101327896\n",
      "Batch 2000: Loss=3.69569993019104; accuracy=0.0390625\n",
      "Validation accuracy: 0.023250000551342964\n",
      "epoch 42\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.694103240966797; accuracy=0.03993750363588333\n",
      "Batch 2000: Loss=3.689565896987915; accuracy=0.0390625\n",
      "Validation accuracy: 0.0247500017285347\n",
      "epoch 43\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.687180280685425; accuracy=0.0442500002682209\n",
      "Batch 2000: Loss=3.676900625228882; accuracy=0.04181250184774399\n",
      "Validation accuracy: 0.02200000174343586\n",
      "epoch 44\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.697145938873291; accuracy=0.042625002562999725\n",
      "Batch 2000: Loss=3.6699602603912354; accuracy=0.04240625351667404\n",
      "Validation accuracy: 0.02250000089406967\n",
      "epoch 45\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.676384210586548; accuracy=0.04656250402331352\n",
      "Batch 2000: Loss=3.687877893447876; accuracy=0.045093752443790436\n",
      "Validation accuracy: 0.027000000700354576\n",
      "epoch 46\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.7100305557250977; accuracy=0.045375000685453415\n",
      "Batch 2000: Loss=3.6916494369506836; accuracy=0.045500002801418304\n",
      "Validation accuracy: 0.024000000208616257\n",
      "epoch 47\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.6839663982391357; accuracy=0.0507500022649765\n",
      "Batch 2000: Loss=3.6435956954956055; accuracy=0.0481875017285347\n",
      "Validation accuracy: 0.02825000137090683\n",
      "epoch 48\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.7029030323028564; accuracy=0.05425000190734863\n",
      "Batch 2000: Loss=3.6932082176208496; accuracy=0.05178125202655792\n",
      "Validation accuracy: 0.022750001400709152\n",
      "epoch 49\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.6998450756073; accuracy=0.05562500283122063\n",
      "Batch 2000: Loss=3.7067203521728516; accuracy=0.0546875037252903\n",
      "Validation accuracy: 0.026500001549720764\n",
      "epoch 50\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.675121784210205; accuracy=0.06000000238418579\n",
      "Batch 2000: Loss=3.702357292175293; accuracy=0.05640625208616257\n",
      "Validation accuracy: 0.026250001043081284\n",
      "epoch 51\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.6619632244110107; accuracy=0.0585625022649765\n",
      "Batch 2000: Loss=3.712458610534668; accuracy=0.060187503695487976\n",
      "Validation accuracy: 0.024500001221895218\n",
      "epoch 52\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.6166014671325684; accuracy=0.06493750214576721\n",
      "Batch 2000: Loss=3.70261812210083; accuracy=0.0625\n",
      "Validation accuracy: 0.02500000037252903\n",
      "epoch 53\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.643791437149048; accuracy=0.06531250476837158\n",
      "Batch 2000: Loss=3.69710636138916; accuracy=0.06493750214576721\n",
      "Validation accuracy: 0.024000000208616257\n",
      "epoch 54\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.703526020050049; accuracy=0.07262500375509262\n",
      "Batch 2000: Loss=3.6520514488220215; accuracy=0.06559375673532486\n",
      "Validation accuracy: 0.021000001579523087\n",
      "epoch 55\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.634742021560669; accuracy=0.07175000011920929\n",
      "Batch 2000: Loss=3.6328418254852295; accuracy=0.07043750584125519\n",
      "Validation accuracy: 0.024500001221895218\n",
      "epoch 56\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.6998178958892822; accuracy=0.07343750447034836\n",
      "Batch 2000: Loss=3.5255954265594482; accuracy=0.07328125089406967\n",
      "Validation accuracy: 0.026250001043081284\n",
      "epoch 57\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1000: Loss=3.69341778755188; accuracy=0.07443750649690628\n",
      "Batch 2000: Loss=3.644908905029297; accuracy=0.07518750429153442\n",
      "Validation accuracy: 0.024250000715255737\n",
      "epoch 58\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.670081615447998; accuracy=0.08162500709295273\n",
      "Batch 2000: Loss=3.651620388031006; accuracy=0.078125\n",
      "Validation accuracy: 0.020750001072883606\n",
      "epoch 59\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.6886260509490967; accuracy=0.08275000751018524\n",
      "Batch 2000: Loss=3.6537511348724365; accuracy=0.08125000447034836\n",
      "Validation accuracy: 0.02225000038743019\n",
      "epoch 60\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.6445529460906982; accuracy=0.08362500369548798\n",
      "Batch 2000: Loss=3.6698694229125977; accuracy=0.08281250298023224\n",
      "Validation accuracy: 0.023250000551342964\n",
      "epoch 61\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.669342041015625; accuracy=0.08912500739097595\n",
      "Batch 2000: Loss=3.6377336978912354; accuracy=0.08668750524520874\n",
      "Validation accuracy: 0.020500000566244125\n",
      "epoch 62\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.699587821960449; accuracy=0.08743750303983688\n",
      "Batch 2000: Loss=3.6695287227630615; accuracy=0.08578125387430191\n",
      "Validation accuracy: 0.0247500017285347\n",
      "epoch 63\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.654536485671997; accuracy=0.093687504529953\n",
      "Batch 2000: Loss=3.6445465087890625; accuracy=0.09156250208616257\n",
      "Validation accuracy: 0.020250000059604645\n",
      "epoch 64\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.6399943828582764; accuracy=0.09618750214576721\n",
      "Batch 2000: Loss=3.700856924057007; accuracy=0.0923437550663948\n",
      "Validation accuracy: 0.022750001400709152\n",
      "epoch 65\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.712364912033081; accuracy=0.10000000149011612\n",
      "Batch 2000: Loss=3.6491799354553223; accuracy=0.09725000709295273\n",
      "Validation accuracy: 0.024000000208616257\n",
      "epoch 66\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.6029133796691895; accuracy=0.10056250542402267\n",
      "Batch 2000: Loss=3.637258291244507; accuracy=0.09978125244379044\n",
      "Validation accuracy: 0.023750001564621925\n",
      "epoch 67\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.6327319145202637; accuracy=0.10443750768899918\n",
      "Batch 2000: Loss=3.549010753631592; accuracy=0.1015625074505806\n",
      "Validation accuracy: 0.024250000715255737\n",
      "epoch 68\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.556149959564209; accuracy=0.10206250846385956\n",
      "Batch 2000: Loss=3.5670366287231445; accuracy=0.10359375178813934\n",
      "Validation accuracy: 0.02175000123679638\n",
      "epoch 69\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.6248741149902344; accuracy=0.11000000685453415\n",
      "Batch 2000: Loss=3.416131019592285; accuracy=0.10878125578165054\n",
      "Validation accuracy: 0.02800000086426735\n",
      "epoch 70\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.7212562561035156; accuracy=0.11381250619888306\n",
      "Batch 2000: Loss=3.6594061851501465; accuracy=0.11037500202655792\n",
      "Validation accuracy: 0.026000000536441803\n",
      "epoch 71\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.6108617782592773; accuracy=0.11506250500679016\n",
      "Batch 2000: Loss=3.640495777130127; accuracy=0.11221875250339508\n",
      "Validation accuracy: 0.0247500017285347\n",
      "epoch 72\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.6104259490966797; accuracy=0.11856250464916229\n",
      "Batch 2000: Loss=3.718412160873413; accuracy=0.11637500673532486\n",
      "Validation accuracy: 0.024000000208616257\n",
      "epoch 73\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.678619146347046; accuracy=0.11625000834465027\n",
      "Batch 2000: Loss=3.7226855754852295; accuracy=0.11475000530481339\n",
      "Validation accuracy: 0.0247500017285347\n",
      "epoch 74\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.542372941970825; accuracy=0.12175000458955765\n",
      "Batch 2000: Loss=3.718229293823242; accuracy=0.12015625834465027\n",
      "Validation accuracy: 0.024000000208616257\n",
      "epoch 75\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.663628339767456; accuracy=0.1303125023841858\n",
      "Batch 2000: Loss=3.6654558181762695; accuracy=0.12356250733137131\n",
      "Validation accuracy: 0.02500000037252903\n",
      "epoch 76\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.6768603324890137; accuracy=0.13125000894069672\n",
      "Batch 2000: Loss=3.5868723392486572; accuracy=0.12556250393390656\n",
      "Validation accuracy: 0.024500001221895218\n",
      "epoch 77\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.635432004928589; accuracy=0.13043750822544098\n",
      "Batch 2000: Loss=3.6067514419555664; accuracy=0.1276562511920929\n",
      "Validation accuracy: 0.024250000715255737\n",
      "epoch 78\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.5122385025024414; accuracy=0.1368125081062317\n",
      "Batch 2000: Loss=3.601862668991089; accuracy=0.12840625643730164\n",
      "Validation accuracy: 0.02250000089406967\n",
      "epoch 79\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.704555034637451; accuracy=0.13168750703334808\n",
      "Batch 2000: Loss=3.6361467838287354; accuracy=0.13109375536441803\n",
      "Validation accuracy: 0.023500001057982445\n",
      "epoch 80\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.408628463745117; accuracy=0.13831250369548798\n",
      "Batch 2000: Loss=3.6643121242523193; accuracy=0.13246876001358032\n",
      "Validation accuracy: 0.026250001043081284\n",
      "epoch 81\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.601839780807495; accuracy=0.13887500762939453\n",
      "Batch 2000: Loss=3.556178569793701; accuracy=0.13571876287460327\n",
      "Validation accuracy: 0.023750001564621925\n",
      "epoch 82\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.595458507537842; accuracy=0.1432500034570694\n",
      "Batch 2000: Loss=3.5757880210876465; accuracy=0.13753125071525574\n",
      "Validation accuracy: 0.024250000715255737\n",
      "epoch 83\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.448381185531616; accuracy=0.14031250774860382\n",
      "Batch 2000: Loss=3.5056071281433105; accuracy=0.13946875929832458\n",
      "Validation accuracy: 0.029250001534819603\n",
      "epoch 84\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.603285551071167; accuracy=0.14012500643730164\n",
      "Batch 2000: Loss=3.716045618057251; accuracy=0.1392812579870224\n",
      "Validation accuracy: 0.0247500017285347\n",
      "epoch 85\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1000: Loss=3.5722265243530273; accuracy=0.1420625001192093\n",
      "Batch 2000: Loss=3.536834478378296; accuracy=0.14034375548362732\n",
      "Validation accuracy: 0.02500000037252903\n",
      "epoch 86\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.6639950275421143; accuracy=0.15037500858306885\n",
      "Batch 2000: Loss=3.582749128341675; accuracy=0.14665625989437103\n",
      "Validation accuracy: 0.02500000037252903\n",
      "epoch 87\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.565037965774536; accuracy=0.14787501096725464\n",
      "Batch 2000: Loss=3.5544605255126953; accuracy=0.1472500115633011\n",
      "Validation accuracy: 0.024250000715255737\n",
      "epoch 88\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.6433093547821045; accuracy=0.15031251311302185\n",
      "Batch 2000: Loss=3.669513702392578; accuracy=0.1498437523841858\n",
      "Validation accuracy: 0.024250000715255737\n",
      "epoch 89\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.695549964904785; accuracy=0.15512500703334808\n",
      "Batch 2000: Loss=3.6194980144500732; accuracy=0.1511250138282776\n",
      "Validation accuracy: 0.026250001043081284\n",
      "epoch 90\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.709775447845459; accuracy=0.15206250548362732\n",
      "Batch 2000: Loss=3.7229435443878174; accuracy=0.1508750021457672\n",
      "Validation accuracy: 0.026250001043081284\n",
      "epoch 91\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.607374906539917; accuracy=0.15793751180171967\n",
      "Batch 2000: Loss=3.6501870155334473; accuracy=0.15328125655651093\n",
      "Validation accuracy: 0.024500001221895218\n",
      "epoch 92\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.640787124633789; accuracy=0.1574375033378601\n",
      "Batch 2000: Loss=3.6783764362335205; accuracy=0.15440626442432404\n",
      "Validation accuracy: 0.024250000715255737\n",
      "epoch 93\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.714012861251831; accuracy=0.15856251120567322\n",
      "Batch 2000: Loss=3.599658489227295; accuracy=0.15409375727176666\n",
      "Validation accuracy: 0.026000000536441803\n",
      "epoch 94\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.5081281661987305; accuracy=0.1575000137090683\n",
      "Batch 2000: Loss=3.561126708984375; accuracy=0.15571875870227814\n",
      "Validation accuracy: 0.028750000521540642\n",
      "epoch 95\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.492093563079834; accuracy=0.15531250834465027\n",
      "Batch 2000: Loss=3.5418732166290283; accuracy=0.15684375166893005\n",
      "Validation accuracy: 0.02525000087916851\n",
      "epoch 96\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.491492986679077; accuracy=0.1626250147819519\n",
      "Batch 2000: Loss=3.64367413520813; accuracy=0.16093750298023224\n",
      "Validation accuracy: 0.02525000087916851\n",
      "epoch 97\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.600409507751465; accuracy=0.16900001466274261\n",
      "Batch 2000: Loss=3.6571829319000244; accuracy=0.16359375417232513\n",
      "Validation accuracy: 0.026500001549720764\n",
      "epoch 98\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.722064971923828; accuracy=0.16437500715255737\n",
      "Batch 2000: Loss=3.6069583892822266; accuracy=0.16362500190734863\n",
      "Validation accuracy: 0.027500001713633537\n",
      "epoch 99\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.662933349609375; accuracy=0.16700001060962677\n",
      "Batch 2000: Loss=3.5434632301330566; accuracy=0.16300000250339508\n",
      "Validation accuracy: 0.02550000138580799\n",
      "epoch 100\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.536541223526001; accuracy=0.16681250929832458\n",
      "Batch 2000: Loss=3.720935344696045; accuracy=0.16550001502037048\n",
      "Validation accuracy: 0.024000000208616257\n"
     ]
    }
   ],
   "source": [
    "if opt.kind==\"from-scratch\":\n",
    "    loss_history, accuracy_val, accuracy_test = net_trainer(\n",
    "            net,\n",
    "            loaders,\n",
    "            opt,\n",
    "            channel_idx,\n",
    "            nonclasses,\n",
    "            None,\n",
    "            True,\n",
    "            model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "52ac79d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy:  0.024000000208616257\n",
      "Test accuracy:  0\n"
     ]
    }
   ],
   "source": [
    "val =accuracy_val\n",
    "test = accuracy_test\n",
    "\n",
    "print(\"Validation accuracy: \", val)\n",
    "print(\"Test accuracy: \", test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0931fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfe0373",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c3beab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab45327",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2179d69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ed6c4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2060d560",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb54c13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6467f813",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d16c15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45955f5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52331151",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca94e7f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfe619b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a58f0c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8236ccbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44249203",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f168b18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edd8a18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63556efb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6b09c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9eb88b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
