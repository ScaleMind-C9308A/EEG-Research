{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3675927f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from analysis import *\n",
    "import argparse\n",
    "from sys import platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e2301c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(12)\n",
    "torch.cuda.manual_seed(12)\n",
    "np.random.seed(12)\n",
    "torch.backends.cudnn.deterministics = True\n",
    "torch.set_num_threads(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7454d60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "0\n",
      "<torch.cuda.device object at 0x7ff9e1b48b80>\n",
      "NVIDIA TITAN V\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.current_device())\n",
    "\n",
    "print(torch.cuda.device(0))\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "499dbec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iv: image option\n",
    "length = 512\n",
    "channel = 96\n",
    "min_CNN = 200\n",
    "n_classes = 40\n",
    "classes = range(n_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cef3bc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "if platform == \"linux\" or platform == \"linux2\":\n",
    "    torch_models_dir = r\"/media/titan/AI Research/Data/CVPR2021-02785/CVPR2021-02785/preprocessed/torch_models\"\n",
    "elif platform == \"win32\":\n",
    "    torch_models_dir = r\"D:\\Data\\CVPR2021-02785\\CVPR2021-02785\\preprocessed\\torch_models\"\n",
    "eeg_dataset, splits_path, splits_shuffled_path = os.listdir(torch_models_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37e239e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/titan/AI Research/Data/CVPR2021-02785/CVPR2021-02785/preprocessed/torch_models/imagenet40-1000-1.pth \n",
      " /media/titan/AI Research/Data/CVPR2021-02785/CVPR2021-02785/preprocessed/torch_models/imagenet40-1000-1_splits.pth\n"
     ]
    }
   ],
   "source": [
    "eeg_dataset = os.path.join(torch_models_dir, eeg_dataset)\n",
    "splits_path = os.path.join(torch_models_dir, splits_path)\n",
    "# splits_path = os.path.join(torch_models_dir, splits_shuffled_path)\n",
    "print(eeg_dataset,'\\n', splits_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "009ff0e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image\n"
     ]
    }
   ],
   "source": [
    "opt = {\n",
    "    # Dataset options\n",
    "    \"iv\": \"image\",\n",
    "    \"offset\": None,\n",
    "    \"results_file\": \"results.pkl\",\n",
    "    \"subject\": 0,\n",
    "    \"run\": \"none\",\n",
    "    \"eeg_dataset\": eeg_dataset,\n",
    "    \"splits_path\": splits_path,\n",
    "    \"fold\": 5,\n",
    "    #Training options\n",
    "    \"batch_size\": 16,\n",
    "    \"optim\": \"Adam\",\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"learning_rate_decay_by\": 0.5,\n",
    "    \"learning_rate_decay_every\": 10,\n",
    "    \"epochs\": 100,\n",
    "    \"GPUindex\": 0,\n",
    "    \"kind\":\"incremental\",\n",
    "    #Backend options\n",
    "    \"no_cuda\": False,\n",
    "    \"classifier\": None\n",
    "}\n",
    "opt = argparse.Namespace(**opt)\n",
    "print(opt.iv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c8df9cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from torch.utils.data import DataLoader\n",
    "from data_loader import EEGDataset, Splitter, SplitterWithData\n",
    "from EEG_Encoder.LSTM import classifier_LSTM\n",
    "from EEG_Encoder.LSTM_per_channel import classifier_LSTM_per_channel\n",
    "from EEG_Encoder.CNN import classifier_CNN\n",
    "from EEG_Encoder.EEGNet import classifier_EEGNet\n",
    "from EEG_Encoder.SyncNet import classifier_SyncNet\n",
    "from EEG_Encoder.EEGChannelNet import classifier_EEGChannelNet\n",
    "from EEG_Encoder.net_generator import Classifier\n",
    "from EEG_Encoder.net_trainer import net_trainer\n",
    "from p_values import *\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30bd6700",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(iv,\n",
    "             offset,\n",
    "             eeg_dataset,\n",
    "             splits_path,\n",
    "             split_num, # (0-4) - 5 fold cross validation\n",
    "             total,\n",
    "             classes,\n",
    "             classifier,\n",
    "             batch_size,\n",
    "             GPUindex,\n",
    "             length, # 512\n",
    "             channel, # 96\n",
    "             min_CNN,\n",
    "             opt,\n",
    "             kind):        \n",
    "    # Load dataset\n",
    "    dataset = EEGDataset(iv, eeg_dataset, classifier, map_idx = None)\n",
    "    print(\"DONE: LOAD DATASET\")\n",
    "    # Create loaders for LSTM/MLP/CNN/SCNN/EEGNet/SyncNet/EEGChannelNet\n",
    "    if kind==\"from-scratch\":\n",
    "        relabel = False\n",
    "    if kind==\"incremental\":\n",
    "        relabel = False\n",
    "    if kind==\"no-model-file\":\n",
    "        relabel = True\n",
    "    splitter = {split: SplitterWithData(iv,\n",
    "                    dataset,\n",
    "                    splits_path,\n",
    "                    classes,\n",
    "                    split_num,\n",
    "                    split,\n",
    "                    relabel) for split in [\"train\", \"val\", \"test\"]}\n",
    "    loaders = {split: DataLoader(\n",
    "                        splitter[split],\n",
    "                        batch_size = batch_size,\n",
    "                        drop_last = False,\n",
    "                        shuffle = True)\n",
    "                    for split in [\"train\", \"val\", \"test\"]}\n",
    "    channel_idx = None    \n",
    "    print(\"DONE: Create loaders for model\")            \n",
    "    return dataset, loaders, splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aae9c3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM per channel network\n",
    "opt.classifier = \"LSTM_per_channel\"\n",
    "opt.batch_size = 16\n",
    "opt.kind = \"from-scratch\"\n",
    "opt.run = \"imagenet40-1000\"\n",
    "opt.fold = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8455f252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE: LOAD DATASET\n",
      "DONE: Create loaders for model\n"
     ]
    }
   ],
   "source": [
    "dataset, loaders, splitter = load_dataset(opt.iv,\n",
    "                             opt.offset,\n",
    "                             opt.eeg_dataset,\n",
    "                             opt.splits_path,\n",
    "                             0, #split_num\n",
    "                             n_classes,\n",
    "                             classes,\n",
    "                             opt.classifier,\n",
    "                             opt.batch_size,\n",
    "                             opt.GPUindex,\n",
    "                             length,\n",
    "                             channel,\n",
    "                             min_CNN,\n",
    "                             opt,\n",
    "                             opt.kind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8191cbe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'data_loader.EEGDataset'>\n",
      "<class 'dict'>\n",
      "3 [2000, 250, 250]\n",
      "1: Label val: 0; label train: 0\n",
      "2: Label val: 17; label train: 17\n",
      "3: Label val: 28; label train: 28\n",
      "4: Label val: 7; label train: 7\n",
      "5: Label val: 33; label train: 33\n",
      "6: Label val: 12; label train: 12\n",
      "7: Label val: 21; label train: 21\n",
      "8: Label val: 3; label train: 3\n",
      "9: Label val: 25; label train: 25\n",
      "10: Label val: 36; label train: 36\n",
      "11: Label val: 10; label train: 10\n",
      "12: Label val: 15; label train: 15\n",
      "13: Label val: 19; label train: 19\n",
      "14: Label val: 31; label train: 31\n",
      "15: Label val: 23; label train: 23\n",
      "16: Label val: 5; label train: 5\n",
      "17: Label val: 38; label train: 38\n",
      "18: Label val: 8; label train: 8\n",
      "19: Label val: 1; label train: 1\n",
      "20: Label val: 34; label train: 34\n",
      "21: Label val: 29; label train: 29\n",
      "22: Label val: 26; label train: 26\n",
      "23: Label val: 13; label train: 13\n",
      "24: Label val: 11; label train: 11\n",
      "25: Label val: 22; label train: 22\n",
      "26: Label val: 18; label train: 18\n",
      "27: Label val: 6; label train: 6\n",
      "28: Label val: 16; label train: 16\n",
      "29: Label val: 4; label train: 4\n",
      "30: Label val: 20; label train: 20\n",
      "31: Label val: 32; label train: 32\n",
      "32: Label val: 9; label train: 9\n",
      "33: Label val: 37; label train: 37\n",
      "34: Label val: 24; label train: 24\n",
      "35: Label val: 39; label train: 39\n",
      "36: Label val: 2; label train: 2\n",
      "37: Label val: 35; label train: 35\n",
      "38: Label val: 30; label train: 30\n",
      "39: Label val: 27; label train: 27\n",
      "40: Label val: 14; label train: 14\n"
     ]
    }
   ],
   "source": [
    "# loaders: divide the splits data in each fold with batch_size\n",
    "# Each fold has {train: 32000 idx, val: 4000 idx, test: 4000 idx}\n",
    "# Each loader batch has {train: 2000 idx, val: 250idx, test: 250 idx}\n",
    "print(type(dataset))\n",
    "print(type(loaders))\n",
    "print(len(loaders), [len(loaders[name]) for name in [\"train\", \"val\", \"test\"] ])\n",
    "for i in range(0, 40):\n",
    "    eeg, label_val = splitter[\"val\"][i*100]\n",
    "    eeg, label_train = splitter[\"train\"][i*800]\n",
    "    print(f\"{i+1}: Label val: {label_val}; label train: {label_train}\")\n",
    "# print(splitter[\"val\"].split_idx[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e95cc78d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE: CREATE TORCH CLASSIFIER\n",
      "classifier_LSTM_per_channel(\n",
      "  (lstm_per_channel): LSTM(1, 1, batch_first=True)\n",
      "  (lstm_full1): LSTM(96, 128, batch_first=True)\n",
      "  (lstm_full2): LSTM(128, 64, batch_first=True)\n",
      "  (linear): Linear(in_features=64, out_features=40, bias=True)\n",
      "  (softmax): Softmax(dim=None)\n",
      ")\n",
      "torch.Size([1, 96, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/titan/GithubClonedRepo/EEG-Research/Experiment/EEG_Encoder/LSTM_per_channel.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x_in = torch.tensor(X[:, i, :]) # x_in: (batch_size, 1, timesteps)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X after concat:  torch.Size([1, 512, 96])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/titan/GithubClonedRepo/EEG-Research/Experiment/EEG_Encoder/LSTM_per_channel.py:53: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  X = self.softmax(X)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "classifier_LSTM_per_channel              [1, 40]                   --\n",
       "├─LSTM: 1-1                              [1, 512, 1]               16\n",
       "├─LSTM: 1-2                              [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-3                              [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-4                              [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-5                              [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-6                              [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-7                              [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-8                              [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-9                              [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-10                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-11                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-12                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-13                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-14                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-15                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-16                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-17                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-18                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-19                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-20                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-21                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-22                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-23                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-24                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-25                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-26                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-27                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-28                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-29                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-30                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-31                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-32                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-33                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-34                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-35                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-36                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-37                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-38                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-39                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-40                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-41                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-42                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-43                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-44                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-45                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-46                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-47                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-48                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-49                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-50                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-51                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-52                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-53                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-54                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-55                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-56                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-57                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-58                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-59                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-60                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-61                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-62                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-63                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-64                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-65                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-66                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-67                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-68                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-69                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-70                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-71                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-72                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-73                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-74                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-75                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-76                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-77                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-78                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-79                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-80                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-81                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-82                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-83                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-84                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-85                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-86                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-87                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-88                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-89                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-90                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-91                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-92                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-93                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-94                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-95                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-96                             [1, 512, 1]               (recursive)\n",
       "├─LSTM: 1-97                             [1, 512, 128]             115,712\n",
       "├─LSTM: 1-98                             [1, 512, 64]              49,664\n",
       "├─Linear: 1-99                           [1, 40]                   2,600\n",
       "├─Softmax: 1-100                         [1, 40]                   --\n",
       "==========================================================================================\n",
       "Total params: 167,992\n",
       "Trainable params: 167,992\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 85.46\n",
       "==========================================================================================\n",
       "Input size (MB): 0.20\n",
       "Forward/backward pass size (MB): 0.79\n",
       "Params size (MB): 0.67\n",
       "Estimated Total Size (MB): 1.66\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net, nonclasses = Classifier(\n",
    "                 n_classes,\n",
    "                 classes,\n",
    "                 opt.classifier,\n",
    "                 opt.GPUindex,\n",
    "                 length,\n",
    "                 channel,\n",
    "                 min_CNN,\n",
    "                 opt.kind)\n",
    "# print(len(nonclasses))\n",
    "summary(net, input_size=(1, 96, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9527792e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image-LSTM_per_channel-512-96-0-noshuffle\n"
     ]
    }
   ],
   "source": [
    "model_path = (opt.iv+\n",
    "                  \"-\"+\n",
    "                  opt.classifier+\n",
    "                  \"-\"+\n",
    "                  str(length)+\n",
    "                  \"-\"+\n",
    "                  str(channel)+\n",
    "                  \"-\"+\n",
    "                  str(0)) + \"-noshuffle\"\n",
    "                  \n",
    "channel_idx=None\n",
    "print(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "789e1be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(iv='image', offset=None, results_file='results.pkl', subject=0, run='imagenet40-1000', eeg_dataset='/media/titan/AI Research/Data/CVPR2021-02785/CVPR2021-02785/preprocessed/torch_models/imagenet40-1000-1.pth', splits_path='/media/titan/AI Research/Data/CVPR2021-02785/CVPR2021-02785/preprocessed/torch_models/imagenet40-1000-1_splits.pth', fold=5, batch_size=16, optim='Adam', learning_rate=0.001, learning_rate_decay_by=0.5, learning_rate_decay_every=10, epochs=100, GPUindex=0, kind='from-scratch', no_cuda=False, classifier='LSTM_per_channel')\n"
     ]
    }
   ],
   "source": [
    "print(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6a7ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/titan/GithubClonedRepo/EEG-Research/Experiment/EEG_Encoder/LSTM_per_channel.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x_in = torch.tensor(X[:, i, :]) # x_in: (batch_size, 1, timesteps)\n",
      "/home/titan/GithubClonedRepo/EEG-Research/Experiment/EEG_Encoder/LSTM_per_channel.py:53: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  X = self.softmax(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1000: Loss=3.6873857975006104; accuracy=0.02537500113248825\n",
      "Batch 2000: Loss=3.6891353130340576; accuracy=0.024625001475214958\n",
      "Validation accuracy: 0.02500000037252903\n",
      "epoch 2\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.687983751296997; accuracy=0.0240625012665987\n",
      "Batch 2000: Loss=3.6889331340789795; accuracy=0.02331250160932541\n",
      "Validation accuracy: 0.02500000037252903\n",
      "epoch 3\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.689671277999878; accuracy=0.024000000208616257\n",
      "Batch 2000: Loss=3.689314126968384; accuracy=0.023000001907348633\n",
      "Validation accuracy: 0.02500000037252903\n",
      "epoch 4\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.6888632774353027; accuracy=0.02550000138580799\n",
      "Batch 2000: Loss=3.6890547275543213; accuracy=0.024562500417232513\n",
      "Validation accuracy: 0.02500000037252903\n",
      "epoch 5\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.6888232231140137; accuracy=0.02393750101327896\n",
      "Batch 2000: Loss=3.6888437271118164; accuracy=0.023500001057982445\n",
      "Validation accuracy: 0.02500000037252903\n",
      "epoch 6\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.689565896987915; accuracy=0.023750001564621925\n",
      "Batch 2000: Loss=3.6891965866088867; accuracy=0.02381250075995922\n",
      "Validation accuracy: 0.02500000037252903\n",
      "epoch 7\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.689566135406494; accuracy=0.02512500062584877\n",
      "Batch 2000: Loss=3.6886911392211914; accuracy=0.02446875162422657\n",
      "Validation accuracy: 0.02500000037252903\n",
      "epoch 8\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.688829183578491; accuracy=0.02187500149011612\n",
      "Batch 2000: Loss=3.688943386077881; accuracy=0.02303125150501728\n",
      "Validation accuracy: 0.02500000037252903\n",
      "epoch 9\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.688673734664917; accuracy=0.023375000804662704\n"
     ]
    }
   ],
   "source": [
    "if opt.kind==\"from-scratch\":\n",
    "    loss_history, accuracy_val, accuracy_test = net_trainer(\n",
    "            net,\n",
    "            loaders,\n",
    "            opt,\n",
    "            channel_idx,\n",
    "            nonclasses,\n",
    "            None,\n",
    "            True,\n",
    "            model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ac79d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "val =accuracy_val\n",
    "test = accuracy_test\n",
    "\n",
    "print(\"Validation accuracy: \", val)\n",
    "print(\"Test accuracy: \", test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0931fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfe0373",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c3beab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab45327",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2179d69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ed6c4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2060d560",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb54c13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6467f813",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d16c15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45955f5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52331151",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca94e7f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfe619b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a58f0c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8236ccbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44249203",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f168b18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edd8a18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63556efb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6b09c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9eb88b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
