{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ea7f6401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from analysis import *\n",
    "import argparse\n",
    "from sys import platform\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c192d33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(12)\n",
    "torch.cuda.manual_seed(12)\n",
    "np.random.seed(12)\n",
    "torch.backends.cudnn.deterministics = True\n",
    "torch.set_num_threads(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "daf1a8a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "2\n",
      "0\n",
      "<torch.cuda.device object at 0x7f61056c4ca0>\n",
      "NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.current_device())\n",
    "\n",
    "\n",
    "print(torch.cuda.device(0))\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "ff733115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iv: image option\n",
    "length = 440\n",
    "channel = 128\n",
    "min_CNN = 200\n",
    "n_classes = 40\n",
    "classes = range(n_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "3b68db2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if platform == \"linux\" or platform == \"linux2\":\n",
    "    torch_models_dir = r\"/media/mountHDD1/LanxHuyen/CVPR2017\"\n",
    "elif platform == \"win32\":\n",
    "    torch_models_dir = r\"D:\\Data\\CVPR2021-02785\\CVPR2021-02785\\preprocessed\\torch_models\"\n",
    "block_splits_all = '/media/mountHDD1/LanxHuyen/CVPR2017/block_splits_by_image_all.pth' \n",
    "eeg_raw = '/media/mountHDD1/LanxHuyen/CVPR2017/eeg_55_95_std.pth'\n",
    "# block_splits_all, block_splits_single, eeg_14_70, eeg_55_95, eeg_5_95, eeg_raw = os.listdir(torch_models_dir)\n",
    "# print(os.listdir(torch_models_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "bd3ad4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/mountHDD1/LanxHuyen/CVPR2017/eeg_55_95_std.pth \n",
      " /media/mountHDD1/LanxHuyen/CVPR2017/block_splits_by_image_all.pth\n"
     ]
    }
   ],
   "source": [
    "# eeg_dataset = os.path.join(torch_models_dir, eeg_5_95)\n",
    "# splits_all_path = os.path.join(torch_models_dir, block_splits_all)\n",
    "eeg_dataset = eeg_raw\n",
    "splits_all_path = block_splits_all\n",
    "# splits_single_path = os.path.join(torch_models_dir, block_splits_single)\n",
    "# splits_path = os.path.join(torch_models_dir, splits_shuffled_path)\n",
    "# print(eeg_dataset,'\\n', splits_all_path, '\\n', splits_single_path)\n",
    "print(eeg_dataset,'\\n', splits_all_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "659d4a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits_all = torch.load(splits_all_path)\n",
    "# splits_single = torch.load(splits_single_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "8f3ef344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "3\n",
      "7984\n",
      "1996\n",
      "1985\n",
      "[0, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 27, 29, 33, 35, 36, 37, 38, 39, 42, 43, 44, 45, 46, 47, 48, 51, 52, 54, 55]\n",
      "[1, 2, 3, 4, 6, 8, 9, 12, 13, 20, 25, 26, 27, 28, 30, 32, 33, 35, 37, 38, 39, 40, 44, 45, 46, 50, 52, 54, 56, 58, 59, 60, 62, 65, 68, 72, 73, 74, 76, 81]\n",
      "[2, 3, 4, 5, 6, 7, 8, 10, 11, 13]\n",
      "[1, 2, 4, 7, 9, 10, 12, 13, 14, 15]\n"
     ]
    }
   ],
   "source": [
    "print(len(splits_all['splits']))\n",
    "print(len(splits_all['splits'][0]))\n",
    "\n",
    "print(len(splits_all['splits'][5]['train']))\n",
    "print(len(splits_all['splits'][5]['val']))\n",
    "print(len(splits_all['splits'][5]['test']))\n",
    "print(splits_all['splits'][0]['train'][:40])\n",
    "print(splits_all['splits'][1]['train'][:40])\n",
    "print(splits_all['splits'][2]['train'][:10])\n",
    "print(splits_all['splits'][3]['train'][:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b27b3181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print(splits_single)\n",
    "# # print(splits_single['splits'])\n",
    "# print(len(splits_single['splits'][0]['train']))\n",
    "# print(len(splits_single['splits'][0]['val']))\n",
    "# print(len(splits_single['splits'][0]['test']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ed58c00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_loaded = torch.load(eeg_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "89460bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "dict_keys(['dataset', 'labels', 'images'])\n",
      "40\n",
      "1996\n",
      "11965\n",
      "128\n",
      "128\n",
      "n02389026 n03888257 n03584829 n02607072 n03297495 n03063599 n03792782 n04086273 n02510455 n11939491 n02951358 n02281787 n02106662 n04120489 n03590841 n02992529 n03445777 n03180011 n02906734 n07873807 n03773504 n02492035 n03982430 n03709823 n03100240 n03376595 n03877472 n03775071 n03272010 n04069434 n03452741 n03792972 n07753592 n13054560 n03197337 n02504458 n02690373 n03272562 n04044716 n02124075\n",
      "n02951358_31190\n",
      "torch.Size([128, 500])\n",
      "{'eeg': tensor([[-1.8615e-02, -2.2027e-01, -3.8487e-01,  ...,  5.3082e-01,\n",
      "          3.0621e-01,  2.6092e-02],\n",
      "        [-3.1586e-02, -2.2723e-01, -3.8992e-01,  ...,  5.4794e-01,\n",
      "          3.0803e-01,  1.7300e-02],\n",
      "        [ 3.8073e-02,  4.0159e-01,  7.0329e-01,  ..., -7.8495e-01,\n",
      "         -4.3544e-01, -2.3261e-02],\n",
      "        ...,\n",
      "        [-2.1302e-02,  1.1708e-01,  2.2351e-01,  ...,  3.8769e-01,\n",
      "          2.0366e-01, -2.0062e-02],\n",
      "        [-8.4068e-04, -5.9282e-03, -1.0319e-02,  ...,  3.1338e-02,\n",
      "          1.7288e-02, -7.0365e-05],\n",
      "        [-7.9558e-03, -4.3303e-02, -7.0963e-02,  ...,  2.0703e-01,\n",
      "          1.1458e-01, -1.3777e-03]]), 'image': 2, 'label': 29, 'subject': 4}\n"
     ]
    }
   ],
   "source": [
    "print(len(eeg_loaded))\n",
    "print(eeg_loaded.keys())\n",
    "dataset, labels, images = [eeg_loaded[k] for k in eeg_loaded.keys()]\n",
    "print(len(labels))\n",
    "print(len(images))\n",
    "print(len(dataset))\n",
    "print(len(means))\n",
    "print(len(stddevs))\n",
    "# print(means)\n",
    "# print(stddevs)\n",
    "print(*labels)\n",
    "print(images[0])\n",
    "print(dataset[0]['eeg'].shape)\n",
    "print(dataset[2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d0622bed-e601-403e-9922-1092184143c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "eeg_length = np.zeros(len(dataset))\n",
    "for i in range(len(dataset)):\n",
    "    eeg_length[i] = list(dataset[i]['eeg'].size())[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "cfd3e149-a140-4fe7-9511-b2b9ba7285ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[501. 499. 531. 499. 509. 500. 499. 529. 516. 514. 498. 500. 494. 508.\n",
      " 516. 505. 498. 497. 531. 500. 497. 500. 530. 528. 500. 498. 506. 513.\n",
      " 499. 536. 502. 521. 528. 520. 528. 513. 515. 598. 501. 497. 499. 499.\n",
      " 494. 502. 530. 535. 546. 529. 497. 514. 529. 528. 516. 516. 514. 499.\n",
      " 500. 514. 517. 498. 496. 494. 517. 500. 513. 502. 498. 514. 499. 497.\n",
      " 504. 515. 499. 509. 496. 498. 502. 498. 534. 503. 531. 496. 496. 516.\n",
      " 500. 498. 530. 514. 499. 529. 492. 544. 499. 514. 512. 504. 499. 517.\n",
      " 495. 498. 546. 498. 518. 540. 498. 500. 500. 504. 543. 501. 499. 524.\n",
      " 515. 504. 495. 496. 544. 500. 499. 496. 498. 516. 515. 526. 513. 499.\n",
      " 502. 516. 544. 501. 648. 529. 497. 517. 515. 519. 516. 531. 494. 530.\n",
      " 532. 529. 496. 499. 496. 502. 519. 514. 499. 499. 531. 545. 498. 498.\n",
      " 517. 493. 499. 499. 502. 504. 518. 500. 529. 499. 496. 498. 501. 533.\n",
      " 511. 517. 514. 512. 498. 530. 507. 499. 546. 514. 514. 531. 501. 501.\n",
      " 501. 500. 499. 496. 500. 502. 527. 515. 497. 497. 528. 530. 515. 512.\n",
      " 518. 500. 513. 514.]\n"
     ]
    }
   ],
   "source": [
    "np.min(eeg_length)\n",
    "print(eeg_length[1000:1200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d20c958c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(results_file='results.pkl', subject=0, time_low=20, time_high=460, eeg_dataset='/media/mountHDD1/LanxHuyen/CVPR2017/eeg_55_95_std.pth', model_type='model10', splits_path='/media/mountHDD1/LanxHuyen/CVPR2017/block_splits_by_image_all.pth', split_num=0, split_name='train', batch_size=16, optim='Adam', learning_rate=0.001, learning_rate_decay_by=0.5, learning_rate_decay_every=10, epochs=100, GPUindex=0, kind='from-scratch', no_cuda=False, classifier=None)\n"
     ]
    }
   ],
   "source": [
    "opt = {\n",
    "    # Dataset options\n",
    "#     \"iv\": \"image\",\n",
    "#     \"offset\": None,\n",
    "    \"results_file\": \"results.pkl\",\n",
    "    \"subject\": 0,\n",
    "    \"time_low\": 20,\n",
    "    \"time_high\": 460,\n",
    "#     \"run\": \"none\",\n",
    "    \"eeg_dataset\": eeg_dataset,\n",
    "    \"model_type\": \"model10\",\n",
    "    \"splits_path\": splits_all_path,\n",
    "    \"split_num\": 0,\n",
    "    \"split_name\": \"train\",\n",
    "#     \"fold\": 5,\n",
    "    #Training options\n",
    "    \"batch_size\": 16,\n",
    "    \"optim\": \"Adam\",\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"learning_rate_decay_by\": 0.5,\n",
    "    \"learning_rate_decay_every\": 10,\n",
    "    \"epochs\": 100,\n",
    "    \"GPUindex\": 0,\n",
    "    \"kind\":\"from-scratch\",\n",
    "    #Backend options\n",
    "    \"no_cuda\": False,\n",
    "    \"classifier\": None\n",
    "}\n",
    "opt = argparse.Namespace(**opt)\n",
    "print(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "ce8d6e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from torch.utils.data import DataLoader\n",
    "# from data_loader import EEGDataset, Splitter, SplitterWithData\n",
    "from data_loader_CVPR2017 import EEGDataset, Splitter\n",
    "from EEG_Encoder.LSTM import classifier_LSTM\n",
    "from EEG_Encoder.CNN import classifier_CNN\n",
    "from EEG_Encoder.EEGNet import classifier_EEGNet\n",
    "from EEG_Encoder.SyncNet import classifier_SyncNet\n",
    "from EEG_Encoder.EEGChannelNet import classifier_EEGChannelNet\n",
    "from EEG_Encoder.net_generator import Classifier\n",
    "from EEG_Encoder.net_trainer import net_trainer\n",
    "from p_values import *\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "0a5b475c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(\n",
    "#              offset,\n",
    "             eeg_dataset,\n",
    "             splits_path,\n",
    "             split_num, # (0-5) - 6 fold cross validation\n",
    "#              total, \n",
    "#              classes,\n",
    "#              classifier,\n",
    "             batch_size,\n",
    "#              GPUindex,\n",
    "#              length, # 500\n",
    "#              channel, # 128\n",
    "#              min_CNN,\n",
    "             opt,\n",
    "             kind=\"from-scratch\"):        \n",
    "    # Load dataset\n",
    "    dataset = EEGDataset(opt, eeg_dataset)\n",
    "    print(\"DONE: LOAD DATASET\")\n",
    "#     # Create loaders for LSTM/MLP/CNN/SCNN/EEGNet/SyncNet/EEGChannelNet\n",
    "#     if kind==\"from-scratch\":\n",
    "#         relabel = False\n",
    "#     if kind==\"incremental\":\n",
    "#         relabel = False\n",
    "#     if kind==\"no-model-file\":\n",
    "#         relabel = True\n",
    "    splitter = {split: Splitter(dataset,\n",
    "                    splits_path,\n",
    "                    split_num,\n",
    "                    split_name=split) for split in [\"train\", \"val\", \"test\"]}\n",
    "    loaders = {split: DataLoader(\n",
    "                        splitter[split],\n",
    "                        batch_size = batch_size,\n",
    "                        drop_last = False,\n",
    "                        shuffle = True)\n",
    "                    for split in [\"train\", \"val\", \"test\"]}\n",
    "    channel_idx = None    \n",
    "    print(\"DONE: Create loaders for model\")            \n",
    "    return dataset, loaders, splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a242cae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Options\n",
    "opt.classifier = \"LSTM4\"\n",
    "opt.batch_size = 64\n",
    "# opt.kind = \"from-scratch\"\n",
    "# opt.run = \"imagenet40-1000\"\n",
    "# opt.fold = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "633488a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE: LOAD DATASET\n",
      "DONE: Create loaders for model\n"
     ]
    }
   ],
   "source": [
    "dataset, loaders, splitter = load_dataset(\n",
    "#              offset,\n",
    "             opt.eeg_dataset,\n",
    "             opt.splits_path,\n",
    "             opt.split_num, # (0-5) - 6 fold cross validation\n",
    "#              total, \n",
    "#              classes,\n",
    "#              classifier,\n",
    "             opt.batch_size,\n",
    "#              GPUindex,\n",
    "#              length, # 500\n",
    "#              channel, # 128\n",
    "#              min_CNN,\n",
    "             opt,\n",
    "             opt.kind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e99fc973",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'data_loader_CVPR2017.EEGDataset'>\n",
      "<class 'dict'>\n",
      "3 [125, 32, 32]\n",
      "1: Label val: 37; label train: 10\n",
      "2: Label val: 38; label train: 10\n",
      "3: Label val: 11; label train: 30\n",
      "4: Label val: 10; label train: 25\n",
      "5: Label val: 7; label train: 18\n",
      "6: Label val: 35; label train: 3\n",
      "7: Label val: 13; label train: 8\n",
      "8: Label val: 2; label train: 11\n",
      "9: Label val: 14; label train: 18\n",
      "10: Label val: 2; label train: 28\n",
      "11: Label val: 33; label train: 38\n",
      "12: Label val: 26; label train: 20\n",
      "13: Label val: 34; label train: 3\n",
      "14: Label val: 18; label train: 28\n",
      "15: Label val: 11; label train: 23\n",
      "16: Label val: 32; label train: 0\n",
      "17: Label val: 6; label train: 34\n",
      "18: Label val: 22; label train: 20\n",
      "19: Label val: 24; label train: 23\n",
      "20: Label val: 24; label train: 39\n",
      "21: Label val: 29; label train: 0\n",
      "22: Label val: 3; label train: 34\n",
      "23: Label val: 25; label train: 21\n",
      "24: Label val: 11; label train: 39\n",
      "25: Label val: 22; label train: 6\n",
      "26: Label val: 36; label train: 26\n",
      "27: Label val: 30; label train: 20\n",
      "28: Label val: 32; label train: 1\n",
      "29: Label val: 22; label train: 27\n",
      "30: Label val: 39; label train: 37\n",
      "31: Label val: 23; label train: 19\n",
      "32: Label val: 4; label train: 9\n",
      "33: Label val: 10; label train: 12\n",
      "34: Label val: 3; label train: 18\n",
      "35: Label val: 24; label train: 25\n",
      "36: Label val: 27; label train: 27\n",
      "37: Label val: 20; label train: 34\n",
      "38: Label val: 1; label train: 35\n",
      "39: Label val: 38; label train: 8\n",
      "40: Label val: 15; label train: 29\n"
     ]
    }
   ],
   "source": [
    "# loaders: divide the splits data in each fold with batch_size\n",
    "# Each fold has {train: 8000 idx, val: 2000 idx, test: 2000 idx}\n",
    "# Each loader batch has {train: 2000 idx, val: 250 idx, test: 250 idx}\n",
    "print(type(dataset))\n",
    "print(type(loaders))\n",
    "print(len(loaders), [len(loaders[name]) for name in [\"train\", \"val\", \"test\"] ])\n",
    "# for i, (input, target) in enumerate(loaders[\"train\"]):\n",
    "#     if i<20:\n",
    "#         print(f\"{i+1}: Target size: {target.size()}; input size: {input.size()}\")\n",
    "for i in range(0, 40):\n",
    "    eeg, label_val = splitter[\"val\"][i]\n",
    "    eeg, label_train = splitter[\"train\"][i]\n",
    "    print(f\"{i+1}: Label val: {label_val}; label train: {label_train}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "39a07cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE: CREATE TORCH CLASSIFIER\n",
      "classifier_LSTM(\n",
      "  (lstm): LSTM(128, 128, batch_first=True)\n",
      "  (output1): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (output2): Linear(in_features=128, out_features=40, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "classifier_LSTM                          [1, 40]                   --\n",
       "├─LSTM: 1-1                              [1, 440, 128]             132,096\n",
       "├─Linear: 1-2                            [1, 128]                  16,512\n",
       "├─ReLU: 1-3                              [1, 128]                  --\n",
       "├─Linear: 1-4                            [1, 40]                   5,160\n",
       "==========================================================================================\n",
       "Total params: 153,768\n",
       "Trainable params: 153,768\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 58.14\n",
       "==========================================================================================\n",
       "Input size (MB): 0.23\n",
       "Forward/backward pass size (MB): 0.45\n",
       "Params size (MB): 0.62\n",
       "Estimated Total Size (MB): 1.29\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net, nonclasses = Classifier(\n",
    "                 n_classes,\n",
    "                 classes,\n",
    "                 opt.classifier,\n",
    "                 opt.GPUindex,\n",
    "                 length,\n",
    "                 channel,\n",
    "                 min_CNN,\n",
    "                 opt.kind)\n",
    "# print(len(nonclasses))\n",
    "summary(net, input_size=(1,128, 440))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "8a8d6995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CVPR2017-LSTM4-440-128-55_95\n"
     ]
    }
   ],
   "source": [
    "model_path = (   f\"CVPR2017-{opt.classifier}-{length}-{channel}-55_95\")\n",
    "print(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "4b753db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(results_file='results.pkl', subject=0, time_low=20, time_high=460, eeg_dataset='/media/mountHDD1/LanxHuyen/CVPR2017/eeg_55_95_std.pth', model_type='model10', splits_path='/media/mountHDD1/LanxHuyen/CVPR2017/block_splits_by_image_all.pth', split_num=0, split_name='train', batch_size=64, optim='Adam', learning_rate=0.001, learning_rate_decay_by=0.5, learning_rate_decay_every=10, epochs=100, GPUindex=0, kind='from-scratch', no_cuda=False, classifier='LSTM4')\n"
     ]
    }
   ],
   "source": [
    "print(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "5334cb84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Train Batch 100 (every 100 batch): Loss=3.6049; accuracy=0.0427\n",
      "Epoch 1 summary: train_loss: 3.6567 | train_acc: 0.0448 | val_loss: 3.5636 | val_acc: 0.0547\n",
      "Epoch 2\n",
      "Train Batch 100 (every 100 batch): Loss=3.2222; accuracy=0.0733\n",
      "Epoch 2 summary: train_loss: 3.3790 | train_acc: 0.0742 | val_loss: 3.3075 | val_acc: 0.0713\n",
      "Epoch 3\n",
      "Train Batch 100 (every 100 batch): Loss=3.0810; accuracy=0.0978\n",
      "Epoch 3 summary: train_loss: 3.2074 | train_acc: 0.0985 | val_loss: 3.1985 | val_acc: 0.0954\n",
      "Epoch 4\n",
      "Train Batch 100 (every 100 batch): Loss=2.7935; accuracy=0.1267\n",
      "Epoch 4 summary: train_loss: 2.9133 | train_acc: 0.1282 | val_loss: 2.9966 | val_acc: 0.0962\n",
      "Epoch 5\n",
      "Train Batch 100 (every 100 batch): Loss=2.9182; accuracy=0.1187\n",
      "Epoch 5 summary: train_loss: 3.0469 | train_acc: 0.1215 | val_loss: 3.0266 | val_acc: 0.1018\n",
      "Epoch 6\n",
      "Train Batch 100 (every 100 batch): Loss=2.7205; accuracy=0.1514\n",
      "Epoch 6 summary: train_loss: 2.7690 | train_acc: 0.1499 | val_loss: 2.8514 | val_acc: 0.1184\n",
      "Epoch 7\n",
      "Train Batch 100 (every 100 batch): Loss=2.5696; accuracy=0.1794\n",
      "Epoch 7 summary: train_loss: 2.6291 | train_acc: 0.1755 | val_loss: 2.7650 | val_acc: 0.1245\n",
      "Epoch 8\n",
      "Train Batch 100 (every 100 batch): Loss=2.3193; accuracy=0.1955\n",
      "Epoch 8 summary: train_loss: 2.4899 | train_acc: 0.1949 | val_loss: 2.6192 | val_acc: 0.1481\n",
      "Epoch 9\n",
      "Train Batch 100 (every 100 batch): Loss=2.4377; accuracy=0.2105\n",
      "Epoch 9 summary: train_loss: 2.4600 | train_acc: 0.2074 | val_loss: 2.7060 | val_acc: 0.1627\n",
      "Epoch 10\n",
      "Train Batch 100 (every 100 batch): Loss=2.4456; accuracy=0.2312\n",
      "Epoch 10 summary: train_loss: 2.3346 | train_acc: 0.2298 | val_loss: 2.5421 | val_acc: 0.1569\n",
      "Epoch 11\n",
      "Train Batch 100 (every 100 batch): Loss=2.1676; accuracy=0.2573\n",
      "Epoch 11 summary: train_loss: 2.2367 | train_acc: 0.2579 | val_loss: 2.4306 | val_acc: 0.1911\n",
      "Epoch 12\n",
      "Train Batch 100 (every 100 batch): Loss=2.4168; accuracy=0.2480\n",
      "Epoch 12 summary: train_loss: 2.3189 | train_acc: 0.2458 | val_loss: 2.4930 | val_acc: 0.1941\n",
      "Epoch 13\n",
      "Train Batch 100 (every 100 batch): Loss=2.4165; accuracy=0.2855\n",
      "Epoch 13 summary: train_loss: 2.1087 | train_acc: 0.2847 | val_loss: 2.4143 | val_acc: 0.1791\n",
      "Epoch 14\n",
      "Train Batch 100 (every 100 batch): Loss=2.0288; accuracy=0.3034\n",
      "Epoch 14 summary: train_loss: 2.0278 | train_acc: 0.3036 | val_loss: 2.4002 | val_acc: 0.1896\n",
      "Epoch 15\n",
      "Train Batch 100 (every 100 batch): Loss=1.9545; accuracy=0.3214\n",
      "Epoch 15 summary: train_loss: 1.9696 | train_acc: 0.3196 | val_loss: 2.3504 | val_acc: 0.2011\n",
      "Epoch 16\n",
      "Train Batch 100 (every 100 batch): Loss=1.7567; accuracy=0.3483\n",
      "Epoch 16 summary: train_loss: 1.8900 | train_acc: 0.3449 | val_loss: 2.3600 | val_acc: 0.1960\n",
      "Epoch 17\n",
      "Train Batch 100 (every 100 batch): Loss=1.6191; accuracy=0.3589\n",
      "Epoch 17 summary: train_loss: 1.8849 | train_acc: 0.3571 | val_loss: 2.3893 | val_acc: 0.2038\n",
      "Epoch 18\n",
      "Train Batch 100 (every 100 batch): Loss=2.1275; accuracy=0.3656\n",
      "Epoch 18 summary: train_loss: 1.8763 | train_acc: 0.3640 | val_loss: 2.3565 | val_acc: 0.2112\n",
      "Epoch 19\n",
      "Train Batch 100 (every 100 batch): Loss=1.7585; accuracy=0.4017\n",
      "Epoch 19 summary: train_loss: 1.7875 | train_acc: 0.3925 | val_loss: 2.5426 | val_acc: 0.2027\n",
      "Epoch 20\n",
      "Train Batch 100 (every 100 batch): Loss=1.8898; accuracy=0.4156\n",
      "Epoch 20 summary: train_loss: 1.7126 | train_acc: 0.4079 | val_loss: 2.3457 | val_acc: 0.2189\n",
      "Epoch 21\n",
      "Train Batch 100 (every 100 batch): Loss=1.6129; accuracy=0.4395\n",
      "Epoch 21 summary: train_loss: 1.6326 | train_acc: 0.4354 | val_loss: 2.3539 | val_acc: 0.2121\n",
      "Epoch 22\n",
      "Train Batch 100 (every 100 batch): Loss=1.5551; accuracy=0.4673\n",
      "Epoch 22 summary: train_loss: 1.5709 | train_acc: 0.4635 | val_loss: 2.3784 | val_acc: 0.2188\n",
      "Epoch 23\n",
      "Train Batch 100 (every 100 batch): Loss=1.4785; accuracy=0.4780\n",
      "Epoch 23 summary: train_loss: 1.5328 | train_acc: 0.4737 | val_loss: 2.3946 | val_acc: 0.2321\n",
      "Epoch 24\n",
      "Train Batch 100 (every 100 batch): Loss=1.4092; accuracy=0.4942\n",
      "Epoch 24 summary: train_loss: 1.4754 | train_acc: 0.4945 | val_loss: 2.4022 | val_acc: 0.2223\n",
      "Epoch 25\n",
      "Train Batch 100 (every 100 batch): Loss=1.5809; accuracy=0.5188\n",
      "Epoch 25 summary: train_loss: 1.3962 | train_acc: 0.5161 | val_loss: 2.2911 | val_acc: 0.2522\n",
      "Epoch 26\n",
      "Train Batch 100 (every 100 batch): Loss=1.6391; accuracy=0.5428\n",
      "Epoch 26 summary: train_loss: 1.3335 | train_acc: 0.5400 | val_loss: 2.3587 | val_acc: 0.2321\n",
      "Epoch 27\n",
      "Train Batch 100 (every 100 batch): Loss=1.3565; accuracy=0.5509\n",
      "Epoch 27 summary: train_loss: 1.3374 | train_acc: 0.5435 | val_loss: 2.4006 | val_acc: 0.2450\n",
      "Epoch 28\n",
      "Train Batch 100 (every 100 batch): Loss=1.3570; accuracy=0.5836\n",
      "Epoch 28 summary: train_loss: 1.2637 | train_acc: 0.5757 | val_loss: 2.4038 | val_acc: 0.2403\n",
      "Epoch 29\n",
      "Train Batch 100 (every 100 batch): Loss=1.2912; accuracy=0.6008\n",
      "Epoch 29 summary: train_loss: 1.1968 | train_acc: 0.5936 | val_loss: 2.4162 | val_acc: 0.2649\n",
      "Epoch 30\n",
      "Train Batch 100 (every 100 batch): Loss=1.2649; accuracy=0.6294\n",
      "Epoch 30 summary: train_loss: 1.1369 | train_acc: 0.6182 | val_loss: 2.5367 | val_acc: 0.2571\n",
      "Epoch 31\n",
      "Train Batch 100 (every 100 batch): Loss=1.2977; accuracy=0.5466\n",
      "Epoch 31 summary: train_loss: 1.3972 | train_acc: 0.5508 | val_loss: 2.5400 | val_acc: 0.2491\n",
      "Epoch 32\n",
      "Train Batch 100 (every 100 batch): Loss=1.1254; accuracy=0.6206\n",
      "Epoch 32 summary: train_loss: 1.1409 | train_acc: 0.6147 | val_loss: 2.5855 | val_acc: 0.2525\n",
      "Epoch 33\n",
      "Train Batch 100 (every 100 batch): Loss=1.1730; accuracy=0.6397\n",
      "Epoch 33 summary: train_loss: 1.0464 | train_acc: 0.6419 | val_loss: 2.5119 | val_acc: 0.2664\n",
      "Epoch 34\n",
      "Train Batch 100 (every 100 batch): Loss=0.9872; accuracy=0.6897\n",
      "Epoch 34 summary: train_loss: 0.9577 | train_acc: 0.6816 | val_loss: 2.5826 | val_acc: 0.2504\n",
      "Epoch 35\n",
      "Train Batch 100 (every 100 batch): Loss=0.7985; accuracy=0.7088\n",
      "Epoch 35 summary: train_loss: 0.9113 | train_acc: 0.6987 | val_loss: 2.6487 | val_acc: 0.2638\n",
      "Epoch 36\n",
      "Train Batch 100 (every 100 batch): Loss=1.0311; accuracy=0.7094\n",
      "Epoch 36 summary: train_loss: 0.8878 | train_acc: 0.7065 | val_loss: 2.6489 | val_acc: 0.2652\n",
      "Epoch 37\n",
      "Train Batch 100 (every 100 batch): Loss=1.1139; accuracy=0.7253\n",
      "Epoch 37 summary: train_loss: 0.8613 | train_acc: 0.7131 | val_loss: 2.8003 | val_acc: 0.2478\n",
      "Epoch 38\n",
      "Train Batch 100 (every 100 batch): Loss=1.5937; accuracy=0.6994\n",
      "Epoch 38 summary: train_loss: 0.9556 | train_acc: 0.6874 | val_loss: 2.7793 | val_acc: 0.2299\n",
      "Epoch 39\n",
      "Train Batch 100 (every 100 batch): Loss=0.9406; accuracy=0.7119\n",
      "Epoch 39 summary: train_loss: 0.8780 | train_acc: 0.7106 | val_loss: 2.7359 | val_acc: 0.2555\n",
      "Epoch 40\n",
      "Train Batch 100 (every 100 batch): Loss=0.8941; accuracy=0.7481\n",
      "Epoch 40 summary: train_loss: 0.8143 | train_acc: 0.7382 | val_loss: 2.7944 | val_acc: 0.2612\n",
      "Epoch 41\n",
      "Train Batch 100 (every 100 batch): Loss=0.8427; accuracy=0.7716\n",
      "Epoch 41 summary: train_loss: 0.7064 | train_acc: 0.7713 | val_loss: 2.9095 | val_acc: 0.2542\n",
      "Epoch 42\n",
      "Train Batch 100 (every 100 batch): Loss=0.7135; accuracy=0.7925\n",
      "Epoch 42 summary: train_loss: 0.6657 | train_acc: 0.7872 | val_loss: 3.0336 | val_acc: 0.2458\n",
      "Epoch 43\n",
      "Train Batch 100 (every 100 batch): Loss=0.5676; accuracy=0.8066\n",
      "Epoch 43 summary: train_loss: 0.6395 | train_acc: 0.7969 | val_loss: 3.0055 | val_acc: 0.2498\n",
      "Epoch 44\n",
      "Train Batch 100 (every 100 batch): Loss=0.6398; accuracy=0.8080\n",
      "Epoch 44 summary: train_loss: 0.6214 | train_acc: 0.8019 | val_loss: 3.1075 | val_acc: 0.2506\n",
      "Epoch 45\n",
      "Train Batch 100 (every 100 batch): Loss=0.6235; accuracy=0.8198\n",
      "Epoch 45 summary: train_loss: 0.5963 | train_acc: 0.8145 | val_loss: 3.1521 | val_acc: 0.2416\n",
      "Epoch 46\n",
      "Train Batch 100 (every 100 batch): Loss=0.7376; accuracy=0.7817\n",
      "Epoch 46 summary: train_loss: 0.6944 | train_acc: 0.7763 | val_loss: 3.2181 | val_acc: 0.2361\n",
      "Epoch 47\n",
      "Train Batch 100 (every 100 batch): Loss=0.6768; accuracy=0.8077\n",
      "Epoch 47 summary: train_loss: 0.6002 | train_acc: 0.8026 | val_loss: 3.2314 | val_acc: 0.2436\n",
      "Epoch 48\n",
      "Train Batch 100 (every 100 batch): Loss=0.4517; accuracy=0.8289\n",
      "Epoch 48 summary: train_loss: 0.5473 | train_acc: 0.8255 | val_loss: 3.2520 | val_acc: 0.2534\n",
      "Epoch 49\n",
      "Train Batch 100 (every 100 batch): Loss=0.7913; accuracy=0.8312\n",
      "Epoch 49 summary: train_loss: 0.5703 | train_acc: 0.8226 | val_loss: 3.3169 | val_acc: 0.2433\n",
      "Epoch 50\n",
      "Train Batch 100 (every 100 batch): Loss=0.7454; accuracy=0.8439\n",
      "Epoch 50 summary: train_loss: 0.5123 | train_acc: 0.8430 | val_loss: 3.4213 | val_acc: 0.2562\n",
      "Epoch 51\n",
      "Train Batch 100 (every 100 batch): Loss=0.5597; accuracy=0.8689\n",
      "Epoch 51 summary: train_loss: 0.5069 | train_acc: 0.8525 | val_loss: 3.5859 | val_acc: 0.2351\n",
      "Epoch 52\n",
      "Train Batch 100 (every 100 batch): Loss=0.4367; accuracy=0.8438\n",
      "Epoch 52 summary: train_loss: 0.4899 | train_acc: 0.8488 | val_loss: 3.4599 | val_acc: 0.2457\n",
      "Epoch 53\n",
      "Train Batch 100 (every 100 batch): Loss=0.6383; accuracy=0.8777\n",
      "Epoch 53 summary: train_loss: 0.4223 | train_acc: 0.8713 | val_loss: 3.6000 | val_acc: 0.2326\n",
      "Epoch 54\n",
      "Train Batch 100 (every 100 batch): Loss=0.4183; accuracy=0.8742\n",
      "Epoch 54 summary: train_loss: 0.4019 | train_acc: 0.8783 | val_loss: 3.5239 | val_acc: 0.2516\n",
      "Epoch 55\n",
      "Train Batch 100 (every 100 batch): Loss=0.2910; accuracy=0.9017\n",
      "Epoch 55 summary: train_loss: 0.3518 | train_acc: 0.8997 | val_loss: 3.6000 | val_acc: 0.2553\n",
      "Epoch 56\n",
      "Train Batch 100 (every 100 batch): Loss=0.2993; accuracy=0.9034\n",
      "Epoch 56 summary: train_loss: 0.3466 | train_acc: 0.8979 | val_loss: 3.6857 | val_acc: 0.2601\n",
      "Epoch 57\n",
      "Train Batch 100 (every 100 batch): Loss=0.5391; accuracy=0.8877\n",
      "Epoch 57 summary: train_loss: 0.4021 | train_acc: 0.8754 | val_loss: 3.8676 | val_acc: 0.2357\n",
      "Epoch 58\n",
      "Train Batch 100 (every 100 batch): Loss=0.4007; accuracy=0.8572\n",
      "Epoch 58 summary: train_loss: 0.4784 | train_acc: 0.8488 | val_loss: 3.8957 | val_acc: 0.2403\n",
      "Epoch 59\n",
      "Train Batch 100 (every 100 batch): Loss=0.5739; accuracy=0.8725\n",
      "Epoch 59 summary: train_loss: 0.4161 | train_acc: 0.8711 | val_loss: 3.8722 | val_acc: 0.2547\n",
      "Epoch 60\n",
      "Train Batch 100 (every 100 batch): Loss=0.4787; accuracy=0.8792\n",
      "Epoch 60 summary: train_loss: 0.3942 | train_acc: 0.8763 | val_loss: 4.0065 | val_acc: 0.2263\n",
      "Epoch 61\n",
      "Train Batch 100 (every 100 batch): Loss=0.2607; accuracy=0.9038\n",
      "Epoch 61 summary: train_loss: 0.3217 | train_acc: 0.9050 | val_loss: 4.0097 | val_acc: 0.2538\n",
      "Epoch 62\n",
      "Train Batch 100 (every 100 batch): Loss=0.2059; accuracy=0.9152\n",
      "Epoch 62 summary: train_loss: 0.2974 | train_acc: 0.9128 | val_loss: 4.1454 | val_acc: 0.2523\n",
      "Epoch 63\n",
      "Train Batch 100 (every 100 batch): Loss=0.2270; accuracy=0.9287\n",
      "Epoch 63 summary: train_loss: 0.2632 | train_acc: 0.9269 | val_loss: 4.0069 | val_acc: 0.2661\n",
      "Epoch 64\n",
      "Train Batch 100 (every 100 batch): Loss=0.1896; accuracy=0.9444\n",
      "Epoch 64 summary: train_loss: 0.2177 | train_acc: 0.9407 | val_loss: 4.1216 | val_acc: 0.2543\n",
      "Epoch 65\n",
      "Train Batch 100 (every 100 batch): Loss=0.3482; accuracy=0.9289\n",
      "Epoch 65 summary: train_loss: 0.2612 | train_acc: 0.9256 | val_loss: 4.4229 | val_acc: 0.2416\n",
      "Epoch 66\n",
      "Train Batch 100 (every 100 batch): Loss=0.6857; accuracy=0.8598\n",
      "Epoch 66 summary: train_loss: 0.4654 | train_acc: 0.8593 | val_loss: 4.2003 | val_acc: 0.2407\n",
      "Epoch 67\n",
      "Train Batch 100 (every 100 batch): Loss=0.2661; accuracy=0.8787\n",
      "Epoch 67 summary: train_loss: 0.3860 | train_acc: 0.8759 | val_loss: 4.3933 | val_acc: 0.2369\n",
      "Epoch 68\n",
      "Train Batch 100 (every 100 batch): Loss=0.1841; accuracy=0.9122\n",
      "Epoch 68 summary: train_loss: 0.2954 | train_acc: 0.9145 | val_loss: 4.2871 | val_acc: 0.2346\n",
      "Epoch 69\n",
      "Train Batch 100 (every 100 batch): Loss=0.2274; accuracy=0.9117\n",
      "Epoch 69 summary: train_loss: 0.3023 | train_acc: 0.9100 | val_loss: 4.3933 | val_acc: 0.2509\n",
      "Epoch 70\n",
      "Train Batch 100 (every 100 batch): Loss=0.3551; accuracy=0.9297\n",
      "Epoch 70 summary: train_loss: 0.2282 | train_acc: 0.9330 | val_loss: 4.2476 | val_acc: 0.2448\n",
      "Epoch 71\n",
      "Train Batch 100 (every 100 batch): Loss=0.1237; accuracy=0.9712\n",
      "Epoch 71 summary: train_loss: 0.1379 | train_acc: 0.9696 | val_loss: 4.3230 | val_acc: 0.2494\n",
      "Epoch 72\n",
      "Train Batch 100 (every 100 batch): Loss=0.1481; accuracy=0.9764\n",
      "Epoch 72 summary: train_loss: 0.1198 | train_acc: 0.9736 | val_loss: 4.3775 | val_acc: 0.2453\n",
      "Epoch 73\n",
      "Train Batch 100 (every 100 batch): Loss=0.1101; accuracy=0.9433\n",
      "Epoch 73 summary: train_loss: 0.2089 | train_acc: 0.9444 | val_loss: 4.5717 | val_acc: 0.2434\n",
      "Epoch 74\n",
      "Train Batch 100 (every 100 batch): Loss=0.1298; accuracy=0.9544\n",
      "Epoch 74 summary: train_loss: 0.1744 | train_acc: 0.9522 | val_loss: 4.5137 | val_acc: 0.2566\n",
      "Epoch 75\n",
      "Train Batch 100 (every 100 batch): Loss=0.1259; accuracy=0.9564\n",
      "Epoch 75 summary: train_loss: 0.1622 | train_acc: 0.9574 | val_loss: 4.5358 | val_acc: 0.2401\n",
      "Epoch 76\n",
      "Train Batch 100 (every 100 batch): Loss=0.2173; accuracy=0.9503\n",
      "Epoch 76 summary: train_loss: 0.1901 | train_acc: 0.9464 | val_loss: 4.8672 | val_acc: 0.2309\n",
      "Epoch 77\n",
      "Train Batch 100 (every 100 batch): Loss=0.6364; accuracy=0.8450\n",
      "Epoch 77 summary: train_loss: 0.5017 | train_acc: 0.8475 | val_loss: 4.7809 | val_acc: 0.2204\n",
      "Epoch 78\n",
      "Train Batch 100 (every 100 batch): Loss=0.4681; accuracy=0.8652\n",
      "Epoch 78 summary: train_loss: 0.4210 | train_acc: 0.8673 | val_loss: 4.6551 | val_acc: 0.2311\n",
      "Epoch 79\n",
      "Train Batch 100 (every 100 batch): Loss=0.1895; accuracy=0.9325\n",
      "Epoch 79 summary: train_loss: 0.2272 | train_acc: 0.9380 | val_loss: 4.4862 | val_acc: 0.2579\n",
      "Epoch 80\n",
      "Train Batch 100 (every 100 batch): Loss=0.1455; accuracy=0.9755\n",
      "Epoch 80 summary: train_loss: 0.1210 | train_acc: 0.9740 | val_loss: 4.4905 | val_acc: 0.2534\n",
      "Epoch 81\n",
      "Train Batch 100 (every 100 batch): Loss=0.0674; accuracy=0.9850\n",
      "Epoch 81 summary: train_loss: 0.0896 | train_acc: 0.9850 | val_loss: 4.5735 | val_acc: 0.2609\n",
      "Epoch 82\n",
      "Train Batch 100 (every 100 batch): Loss=0.0586; accuracy=0.9908\n",
      "Epoch 82 summary: train_loss: 0.0607 | train_acc: 0.9908 | val_loss: 4.6875 | val_acc: 0.2581\n",
      "Epoch 83\n",
      "Train Batch 100 (every 100 batch): Loss=0.0385; accuracy=0.9909\n",
      "Epoch 83 summary: train_loss: 0.0556 | train_acc: 0.9911 | val_loss: 4.7202 | val_acc: 0.2432\n",
      "Epoch 84\n",
      "Train Batch 100 (every 100 batch): Loss=0.0960; accuracy=0.9930\n",
      "Epoch 84 summary: train_loss: 0.0492 | train_acc: 0.9930 | val_loss: 4.7169 | val_acc: 0.2496\n",
      "Epoch 85\n",
      "Train Batch 100 (every 100 batch): Loss=0.0328; accuracy=0.9945\n",
      "Epoch 85 summary: train_loss: 0.0420 | train_acc: 0.9945 | val_loss: 4.8421 | val_acc: 0.2499\n",
      "Epoch 86\n",
      "Train Batch 100 (every 100 batch): Loss=0.0225; accuracy=0.9947\n",
      "Epoch 86 summary: train_loss: 0.0415 | train_acc: 0.9940 | val_loss: 5.0274 | val_acc: 0.2445\n",
      "Epoch 87\n",
      "Train Batch 100 (every 100 batch): Loss=0.0277; accuracy=0.9922\n",
      "Epoch 87 summary: train_loss: 0.0471 | train_acc: 0.9911 | val_loss: 5.0214 | val_acc: 0.2516\n",
      "Epoch 88\n",
      "Train Batch 100 (every 100 batch): Loss=0.8835; accuracy=0.9278\n",
      "Epoch 88 summary: train_loss: 0.3447 | train_acc: 0.9018 | val_loss: 5.6701 | val_acc: 0.2082\n",
      "Epoch 89\n",
      "Train Batch 100 (every 100 batch): Loss=0.5649; accuracy=0.7212\n",
      "Epoch 89 summary: train_loss: 0.9552 | train_acc: 0.7214 | val_loss: 5.0617 | val_acc: 0.2045\n",
      "Epoch 90\n",
      "Train Batch 100 (every 100 batch): Loss=0.4046; accuracy=0.8312\n",
      "Epoch 90 summary: train_loss: 0.5098 | train_acc: 0.8401 | val_loss: 4.7363 | val_acc: 0.2452\n",
      "Epoch 91\n",
      "Train Batch 100 (every 100 batch): Loss=0.1575; accuracy=0.9239\n",
      "Epoch 91 summary: train_loss: 0.2346 | train_acc: 0.9304 | val_loss: 4.6259 | val_acc: 0.2310\n",
      "Epoch 92\n",
      "Train Batch 100 (every 100 batch): Loss=0.0705; accuracy=0.9825\n",
      "Epoch 92 summary: train_loss: 0.0940 | train_acc: 0.9840 | val_loss: 4.6897 | val_acc: 0.2465\n",
      "Epoch 93\n",
      "Train Batch 100 (every 100 batch): Loss=0.0738; accuracy=0.9961\n",
      "Epoch 93 summary: train_loss: 0.0489 | train_acc: 0.9961 | val_loss: 4.7584 | val_acc: 0.2478\n",
      "Epoch 94\n",
      "Train Batch 100 (every 100 batch): Loss=0.0410; accuracy=0.9975\n",
      "Epoch 94 summary: train_loss: 0.0366 | train_acc: 0.9978 | val_loss: 4.8520 | val_acc: 0.2409\n",
      "Epoch 95\n",
      "Train Batch 100 (every 100 batch): Loss=0.0234; accuracy=0.9986\n",
      "Epoch 95 summary: train_loss: 0.0302 | train_acc: 0.9984 | val_loss: 4.8799 | val_acc: 0.2489\n",
      "Epoch 96\n",
      "Train Batch 100 (every 100 batch): Loss=0.0276; accuracy=0.9981\n",
      "Epoch 96 summary: train_loss: 0.0281 | train_acc: 0.9981 | val_loss: 4.9997 | val_acc: 0.2486\n",
      "Epoch 97\n",
      "Train Batch 100 (every 100 batch): Loss=0.0424; accuracy=0.9975\n",
      "Epoch 97 summary: train_loss: 0.0274 | train_acc: 0.9975 | val_loss: 5.0216 | val_acc: 0.2460\n",
      "Epoch 98\n",
      "Train Batch 100 (every 100 batch): Loss=0.0199; accuracy=0.9970\n",
      "Epoch 98 summary: train_loss: 0.0271 | train_acc: 0.9970 | val_loss: 5.0419 | val_acc: 0.2489\n",
      "Epoch 99\n",
      "Train Batch 100 (every 100 batch): Loss=0.0761; accuracy=0.9950\n",
      "Epoch 99 summary: train_loss: 0.0314 | train_acc: 0.9955 | val_loss: 5.0227 | val_acc: 0.2503\n",
      "Epoch 100\n",
      "Train Batch 100 (every 100 batch): Loss=0.0221; accuracy=0.9970\n",
      "Epoch 100 summary: train_loss: 0.0286 | train_acc: 0.9961 | val_loss: 5.1903 | val_acc: 0.2518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Batch 100 (every 100 batch): Loss=0.4704; accuracy=0.8187\n",
      "Train Batch 200 (every 100 batch): Loss=0.2372; accuracy=0.8181\n",
      "Train Batch 300 (every 100 batch): Loss=0.2904; accuracy=0.8152\n",
      "Train Batch 400 (every 100 batch): Loss=0.2112; accuracy=0.8194\n",
      "Epoch 70 summary: train_loss: 0.5636 | train_acc: 0.8289 | val_loss: 5.8814 | val_acc: 0.2016\n",
      "Epoch 71\n",
      "Train Batch 100 (every 100 batch): Loss=0.3092; accuracy=0.9256\n",
      "Train Batch 200 (every 100 batch): Loss=0.3137; accuracy=0.9300\n",
      "Train Batch 300 (every 100 batch): Loss=0.0731; accuracy=0.9383\n",
      "Train Batch 400 (every 100 batch): Loss=0.2065; accuracy=0.9442\n",
      "Epoch 71 summary: train_loss: 0.1714 | train_acc: 0.9450 | val_loss: 5.7815 | val_acc: 0.2046\n",
      "Epoch 72\n",
      "Train Batch 100 (every 100 batch): Loss=0.0299; accuracy=0.9656\n",
      "Train Batch 200 (every 100 batch): Loss=0.0485; accuracy=0.9716\n",
      "Train Batch 300 (every 100 batch): Loss=0.0297; accuracy=0.9727\n",
      "Train Batch 400 (every 100 batch): Loss=0.0633; accuracy=0.9722\n",
      "Epoch 72 summary: train_loss: 0.1059 | train_acc: 0.9728 | val_loss: 5.8607 | val_acc: 0.2068\n",
      "Epoch 73\n",
      "Train Batch 100 (every 100 batch): Loss=0.1674; accuracy=0.9856\n",
      "Train Batch 200 (every 100 batch): Loss=0.0576; accuracy=0.9822\n",
      "Train Batch 300 (every 100 batch): Loss=0.1496; accuracy=0.9740\n",
      "Train Batch 400 (every 100 batch): Loss=0.1042; accuracy=0.9613\n",
      "Epoch 73 summary: train_loss: 0.1769 | train_acc: 0.9513 | val_loss: 6.1453 | val_acc: 0.1968\n",
      "Epoch 74\n",
      "Train Batch 100 (every 100 batch): Loss=0.1332; accuracy=0.9369\n",
      "Train Batch 200 (every 100 batch): Loss=0.0408; accuracy=0.9441\n",
      "Train Batch 300 (every 100 batch): Loss=0.1920; accuracy=0.9454\n",
      "Train Batch 400 (every 100 batch): Loss=0.0821; accuracy=0.9428\n",
      "Epoch 74 summary: train_loss: 0.2238 | train_acc: 0.9345 | val_loss: 6.4008 | val_acc: 0.2032\n",
      "Epoch 75\n",
      "Train Batch 100 (every 100 batch): Loss=0.0670; accuracy=0.9013\n",
      "Train Batch 200 (every 100 batch): Loss=0.0943; accuracy=0.9122\n",
      "Train Batch 300 (every 100 batch): Loss=0.5064; accuracy=0.9160\n",
      "Train Batch 400 (every 100 batch): Loss=0.4433; accuracy=0.9169\n",
      "Epoch 75 summary: train_loss: 0.2601 | train_acc: 0.9174 | val_loss: 6.1680 | val_acc: 0.2108\n",
      "Epoch 76\n",
      "Train Batch 100 (every 100 batch): Loss=0.5522; accuracy=0.9406\n",
      "Train Batch 200 (every 100 batch): Loss=0.0830; accuracy=0.9422\n",
      "Train Batch 300 (every 100 batch): Loss=0.2059; accuracy=0.9456\n",
      "Train Batch 400 (every 100 batch): Loss=0.1494; accuracy=0.9481\n",
      "Epoch 76 summary: train_loss: 0.1725 | train_acc: 0.9490 | val_loss: 6.2391 | val_acc: 0.2104\n",
      "Epoch 77\n",
      "Train Batch 100 (every 100 batch): Loss=0.0123; accuracy=0.9775\n",
      "Train Batch 200 (every 100 batch): Loss=0.1031; accuracy=0.9787\n",
      "Train Batch 300 (every 100 batch): Loss=0.1087; accuracy=0.9804\n",
      "Train Batch 400 (every 100 batch): Loss=0.0051; accuracy=0.9822\n",
      "Epoch 77 summary: train_loss: 0.0727 | train_acc: 0.9827 | val_loss: 6.1805 | val_acc: 0.2136\n",
      "Epoch 78\n",
      "Train Batch 100 (every 100 batch): Loss=0.0259; accuracy=0.9962\n",
      "Train Batch 200 (every 100 batch): Loss=0.0048; accuracy=0.9941\n",
      "Train Batch 300 (every 100 batch): Loss=0.1042; accuracy=0.9898\n",
      "Train Batch 400 (every 100 batch): Loss=0.3761; accuracy=0.9839\n",
      "Epoch 78 summary: train_loss: 0.0957 | train_acc: 0.9765 | val_loss: 6.3829 | val_acc: 0.2166\n",
      "Epoch 79\n",
      "Train Batch 100 (every 100 batch): Loss=0.0476; accuracy=0.9494\n",
      "Train Batch 200 (every 100 batch): Loss=0.0863; accuracy=0.9406\n",
      "Train Batch 300 (every 100 batch): Loss=0.5194; accuracy=0.9265\n",
      "Train Batch 400 (every 100 batch): Loss=0.2511; accuracy=0.9161\n",
      "Epoch 79 summary: train_loss: 0.2952 | train_acc: 0.9086 | val_loss: 6.4372 | val_acc: 0.1929\n",
      "Epoch 80\n",
      "Train Batch 100 (every 100 batch): Loss=0.3009; accuracy=0.9231\n",
      "Train Batch 200 (every 100 batch): Loss=0.8426; accuracy=0.9297\n",
      "Train Batch 300 (every 100 batch): Loss=0.0989; accuracy=0.9350\n",
      "Train Batch 400 (every 100 batch): Loss=0.1911; accuracy=0.9431\n",
      "Epoch 80 summary: train_loss: 0.1667 | train_acc: 0.9470 | val_loss: 6.1436 | val_acc: 0.2205\n",
      "Epoch 81\n",
      "Train Batch 100 (every 100 batch): Loss=0.1189; accuracy=0.9762\n",
      "Train Batch 200 (every 100 batch): Loss=0.0650; accuracy=0.9731\n",
      "Train Batch 300 (every 100 batch): Loss=0.5903; accuracy=0.9704\n",
      "Train Batch 400 (every 100 batch): Loss=0.0171; accuracy=0.9716\n",
      "Epoch 81 summary: train_loss: 0.0958 | train_acc: 0.9728 | val_loss: 6.3541 | val_acc: 0.2189\n",
      "Epoch 82\n",
      "Train Batch 100 (every 100 batch): Loss=0.0107; accuracy=0.9912\n",
      "Train Batch 200 (every 100 batch): Loss=0.0069; accuracy=0.9909\n",
      "Train Batch 300 (every 100 batch): Loss=0.1075; accuracy=0.9894\n",
      "Train Batch 400 (every 100 batch): Loss=0.0393; accuracy=0.9898\n",
      "Epoch 82 summary: train_loss: 0.0501 | train_acc: 0.9900 | val_loss: 6.4340 | val_acc: 0.2126\n",
      "Epoch 83\n",
      "Train Batch 100 (every 100 batch): Loss=0.4039; accuracy=0.9688\n",
      "Train Batch 200 (every 100 batch): Loss=0.4312; accuracy=0.9562\n",
      "Train Batch 300 (every 100 batch): Loss=0.8420; accuracy=0.9467\n",
      "Train Batch 400 (every 100 batch): Loss=0.0620; accuracy=0.9392\n",
      "Epoch 83 summary: train_loss: 0.2241 | train_acc: 0.9345 | val_loss: 6.5672 | val_acc: 0.2089\n",
      "Epoch 84\n",
      "Train Batch 100 (every 100 batch): Loss=0.0556; accuracy=0.9437\n",
      "Train Batch 200 (every 100 batch): Loss=0.5811; accuracy=0.9459\n",
      "Train Batch 300 (every 100 batch): Loss=0.0830; accuracy=0.9431\n",
      "Train Batch 400 (every 100 batch): Loss=0.5820; accuracy=0.9425\n",
      "Epoch 84 summary: train_loss: 0.2122 | train_acc: 0.9410 | val_loss: 6.7640 | val_acc: 0.2051\n",
      "Epoch 85\n",
      "Train Batch 100 (every 100 batch): Loss=0.0090; accuracy=0.9450\n",
      "Train Batch 200 (every 100 batch): Loss=0.0513; accuracy=0.9481\n",
      "Train Batch 300 (every 100 batch): Loss=0.6732; accuracy=0.9473\n",
      "Train Batch 400 (every 100 batch): Loss=0.1261; accuracy=0.9458\n",
      "Epoch 85 summary: train_loss: 0.1820 | train_acc: 0.9472 | val_loss: 6.4420 | val_acc: 0.2113\n",
      "Epoch 86\n",
      "Train Batch 100 (every 100 batch): Loss=0.1977; accuracy=0.9675\n",
      "Train Batch 200 (every 100 batch): Loss=0.1729; accuracy=0.9734\n",
      "Train Batch 300 (every 100 batch): Loss=0.1911; accuracy=0.9740\n",
      "Train Batch 400 (every 100 batch): Loss=0.0706; accuracy=0.9711\n",
      "Epoch 86 summary: train_loss: 0.1143 | train_acc: 0.9666 | val_loss: 6.6352 | val_acc: 0.2068\n",
      "Epoch 87\n",
      "Train Batch 100 (every 100 batch): Loss=0.0083; accuracy=0.9462\n",
      "Train Batch 200 (every 100 batch): Loss=0.0944; accuracy=0.9428\n",
      "Train Batch 300 (every 100 batch): Loss=0.0730; accuracy=0.9433\n",
      "Train Batch 400 (every 100 batch): Loss=0.1450; accuracy=0.9442\n",
      "Epoch 87 summary: train_loss: 0.2343 | train_acc: 0.9340 | val_loss: 6.8772 | val_acc: 0.1967\n",
      "Epoch 88\n",
      "Train Batch 100 (every 100 batch): Loss=0.9291; accuracy=0.9156\n",
      "Train Batch 200 (every 100 batch): Loss=0.2178; accuracy=0.9269\n",
      "Train Batch 300 (every 100 batch): Loss=0.2513; accuracy=0.9306\n",
      "Train Batch 400 (every 100 batch): Loss=0.1489; accuracy=0.9330\n",
      "Epoch 88 summary: train_loss: 0.2173 | train_acc: 0.9339 | val_loss: 6.5242 | val_acc: 0.2088\n",
      "Epoch 89\n",
      "Train Batch 100 (every 100 batch): Loss=0.0903; accuracy=0.9525\n",
      "Train Batch 200 (every 100 batch): Loss=0.0224; accuracy=0.9572\n",
      "Train Batch 300 (every 100 batch): Loss=0.0232; accuracy=0.9617\n",
      "Train Batch 400 (every 100 batch): Loss=0.0123; accuracy=0.9647\n",
      "Epoch 89 summary: train_loss: 0.1196 | train_acc: 0.9647 | val_loss: 6.6734 | val_acc: 0.2048\n",
      "Epoch 90\n",
      "Train Batch 100 (every 100 batch): Loss=0.0483; accuracy=0.9837\n",
      "Train Batch 200 (every 100 batch): Loss=0.4387; accuracy=0.9797\n",
      "Train Batch 300 (every 100 batch): Loss=0.0913; accuracy=0.9750\n",
      "Train Batch 400 (every 100 batch): Loss=0.1115; accuracy=0.9745\n",
      "Epoch 90 summary: train_loss: 0.0939 | train_acc: 0.9757 | val_loss: 6.5623 | val_acc: 0.2161\n",
      "Epoch 91\n",
      "Train Batch 100 (every 100 batch): Loss=0.0096; accuracy=0.9875\n",
      "Train Batch 200 (every 100 batch): Loss=0.0181; accuracy=0.9812\n",
      "Train Batch 300 (every 100 batch): Loss=0.0100; accuracy=0.9771\n",
      "Train Batch 400 (every 100 batch): Loss=0.5675; accuracy=0.9680\n",
      "Epoch 91 summary: train_loss: 0.1254 | train_acc: 0.9632 | val_loss: 6.8066 | val_acc: 0.1958\n",
      "Epoch 92\n",
      "Train Batch 100 (every 100 batch): Loss=0.0471; accuracy=0.9556\n",
      "Train Batch 200 (every 100 batch): Loss=0.2074; accuracy=0.9584\n",
      "Train Batch 300 (every 100 batch): Loss=0.0609; accuracy=0.9604\n",
      "Train Batch 400 (every 100 batch): Loss=0.0365; accuracy=0.9627\n",
      "Epoch 92 summary: train_loss: 0.1159 | train_acc: 0.9657 | val_loss: 6.7797 | val_acc: 0.1991\n",
      "Epoch 93\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Batch 100 (every 100 batch): Loss=0.0293; accuracy=0.9712\n",
      "Train Batch 200 (every 100 batch): Loss=0.0162; accuracy=0.9678\n",
      "Train Batch 300 (every 100 batch): Loss=0.1756; accuracy=0.9677\n",
      "Train Batch 400 (every 100 batch): Loss=0.0787; accuracy=0.9627\n",
      "Epoch 93 summary: train_loss: 0.1430 | train_acc: 0.9585 | val_loss: 6.7716 | val_acc: 0.2149\n",
      "Epoch 94\n",
      "Train Batch 100 (every 100 batch): Loss=0.0577; accuracy=0.9700\n",
      "Train Batch 200 (every 100 batch): Loss=0.1885; accuracy=0.9656\n",
      "Train Batch 300 (every 100 batch): Loss=0.1342; accuracy=0.9652\n",
      "Train Batch 400 (every 100 batch): Loss=0.3027; accuracy=0.9586\n",
      "Epoch 94 summary: train_loss: 0.1505 | train_acc: 0.9534 | val_loss: 7.1981 | val_acc: 0.1959\n",
      "Epoch 95\n",
      "Train Batch 100 (every 100 batch): Loss=0.1803; accuracy=0.9500\n",
      "Train Batch 200 (every 100 batch): Loss=0.0802; accuracy=0.9528\n",
      "Train Batch 300 (every 100 batch): Loss=0.0852; accuracy=0.9508\n",
      "Train Batch 400 (every 100 batch): Loss=0.0628; accuracy=0.9506\n",
      "Epoch 95 summary: train_loss: 0.1587 | train_acc: 0.9488 | val_loss: 7.1388 | val_acc: 0.1926\n",
      "Epoch 96\n",
      "Train Batch 100 (every 100 batch): Loss=0.1918; accuracy=0.9544\n",
      "Train Batch 200 (every 100 batch): Loss=0.1283; accuracy=0.9578\n",
      "Train Batch 300 (every 100 batch): Loss=0.2446; accuracy=0.9588\n",
      "Train Batch 400 (every 100 batch): Loss=0.0393; accuracy=0.9608\n",
      "Epoch 96 summary: train_loss: 0.1340 | train_acc: 0.9603 | val_loss: 7.0312 | val_acc: 0.2090\n",
      "Epoch 97\n",
      "Train Batch 100 (every 100 batch): Loss=0.0522; accuracy=0.9731\n",
      "Train Batch 200 (every 100 batch): Loss=0.0236; accuracy=0.9706\n",
      "Train Batch 300 (every 100 batch): Loss=0.0979; accuracy=0.9679\n",
      "Train Batch 400 (every 100 batch): Loss=0.7926; accuracy=0.9623\n",
      "Epoch 97 summary: train_loss: 0.1438 | train_acc: 0.9568 | val_loss: 7.1946 | val_acc: 0.1921\n",
      "Epoch 98\n",
      "Train Batch 100 (every 100 batch): Loss=0.4918; accuracy=0.9519\n",
      "Train Batch 200 (every 100 batch): Loss=0.0569; accuracy=0.9387\n",
      "Train Batch 300 (every 100 batch): Loss=0.0466; accuracy=0.9367\n",
      "Train Batch 400 (every 100 batch): Loss=0.0864; accuracy=0.9406\n",
      "Epoch 98 summary: train_loss: 0.2108 | train_acc: 0.9428 | val_loss: 7.0276 | val_acc: 0.1993\n",
      "Epoch 99\n",
      "Train Batch 100 (every 100 batch): Loss=0.0502; accuracy=0.9688\n",
      "Train Batch 200 (every 100 batch): Loss=0.0421; accuracy=0.9728\n",
      "Train Batch 300 (every 100 batch): Loss=0.0701; accuracy=0.9750\n",
      "Train Batch 400 (every 100 batch): Loss=0.0578; accuracy=0.9773\n",
      "Epoch 99 summary: train_loss: 0.0749 | train_acc: 0.9798 | val_loss: 6.8324 | val_acc: 0.2206\n",
      "Epoch 100\n",
      "Train Batch 100 (every 100 batch): Loss=0.0073; accuracy=0.9981\n",
      "Train Batch 200 (every 100 batch): Loss=0.0032; accuracy=0.9987\n",
      "Train Batch 300 (every 100 batch): Loss=0.0147; accuracy=0.9979\n",
      "Train Batch 400 (every 100 batch): Loss=0.0330; accuracy=0.9970\n",
      "Epoch 100 summary: train_loss: 0.0286 | train_acc: 0.9951 | val_loss: 7.0001 | val_acc: 0.2003\n"
     ]
    }
   ],
   "source": [
    "channel_idx=None\n",
    "non_classes=None\n",
    "if opt.kind==\"from-scratch\":\n",
    "    results = net_trainer(\n",
    "            net,\n",
    "            loaders,\n",
    "            opt,\n",
    "            channel_idx,\n",
    "            nonclasses,\n",
    "            None,\n",
    "            True,\n",
    "            model_path,\n",
    "            print_every_train = 100,\n",
    "            print_every_val = 125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0199dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# val = results[\"val_acc\"]\n",
    "# # test = results[\"test_acc\"]\n",
    "\n",
    "# print(\"Validation accuracy: \", val)\n",
    "# # print(\"Test accuracy: \", test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c56b086",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913f370e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9a7d31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2334ae6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b77fc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3080e706",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17823cb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8b650c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdb911b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b43930",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28237288",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ded073",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfcbdda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1fb11a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b75470",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8939417",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a5c258",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e7de01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597563e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d74a8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db30ed4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1544e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
