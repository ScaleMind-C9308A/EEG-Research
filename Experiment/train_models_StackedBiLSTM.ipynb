{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3675927f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from analysis import *\n",
    "import argparse\n",
    "from sys import platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e2301c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(12)\n",
    "torch.cuda.manual_seed(12)\n",
    "np.random.seed(12)\n",
    "torch.backends.cudnn.deterministics = True\n",
    "torch.set_num_threads(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7454d60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "0\n",
      "<torch.cuda.device object at 0x7fdfa0669400>\n",
      "NVIDIA TITAN V\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.current_device())\n",
    "\n",
    "print(torch.cuda.device(0))\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "499dbec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iv: image option\n",
    "length = 512\n",
    "channel = 96\n",
    "min_CNN = 200\n",
    "n_classes = 40\n",
    "classes = range(n_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cef3bc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "if platform == \"linux\" or platform == \"linux2\":\n",
    "    torch_models_dir = r\"/media/titan/AI Research/Data/CVPR2021-02785/CVPR2021-02785/preprocessed/torch_models\"\n",
    "elif platform == \"win32\":\n",
    "    torch_models_dir = r\"D:\\Data\\CVPR2021-02785\\CVPR2021-02785\\preprocessed\\torch_models\"\n",
    "eeg_dataset, splits_path, splits_shuffled_path = os.listdir(torch_models_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37e239e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/titan/AI Research/Data/CVPR2021-02785/CVPR2021-02785/preprocessed/torch_models/imagenet40-1000-1.pth \n",
      " /media/titan/AI Research/Data/CVPR2021-02785/CVPR2021-02785/preprocessed/torch_models/imagenet40-1000-1_splits.pth\n"
     ]
    }
   ],
   "source": [
    "eeg_dataset = os.path.join(torch_models_dir, eeg_dataset)\n",
    "splits_path = os.path.join(torch_models_dir, splits_path)\n",
    "# splits_path = os.path.join(torch_models_dir, splits_shuffled_path)\n",
    "print(eeg_dataset,'\\n', splits_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "009ff0e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image\n"
     ]
    }
   ],
   "source": [
    "opt = {\n",
    "    # Dataset options\n",
    "    \"iv\": \"image\",\n",
    "    \"offset\": None,\n",
    "    \"results_file\": \"results.pkl\",\n",
    "    \"subject\": 0,\n",
    "    \"run\": \"none\",\n",
    "    \"eeg_dataset\": eeg_dataset,\n",
    "    \"splits_path\": splits_path,\n",
    "    \"fold\": 5,\n",
    "    #Training options\n",
    "    \"batch_size\": 16,\n",
    "    \"optim\": \"Adam\",\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"learning_rate_decay_by\": 0.5,\n",
    "    \"learning_rate_decay_every\": 10,\n",
    "    \"epochs\": 100,\n",
    "    \"GPUindex\": 0,\n",
    "    \"kind\":\"incremental\",\n",
    "    #Backend options\n",
    "    \"no_cuda\": False,\n",
    "    \"classifier\": None\n",
    "}\n",
    "opt = argparse.Namespace(**opt)\n",
    "print(opt.iv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c8df9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from torch.utils.data import DataLoader\n",
    "from data_loader import EEGDataset, Splitter, SplitterWithData\n",
    "from EEG_Encoder.LSTM import classifier_LSTM\n",
    "from EEG_Encoder.CNN import classifier_CNN\n",
    "from EEG_Encoder.EEGNet import classifier_EEGNet\n",
    "from EEG_Encoder.SyncNet import classifier_SyncNet\n",
    "from EEG_Encoder.EEGChannelNet import classifier_EEGChannelNet\n",
    "from EEG_Encoder.net_generator import Classifier\n",
    "from EEG_Encoder.net_trainer import net_trainer\n",
    "from p_values import *\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30bd6700",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(iv,\n",
    "             offset,\n",
    "             eeg_dataset,\n",
    "             splits_path,\n",
    "             split_num, # (0-4) - 5 fold cross validation\n",
    "             total,\n",
    "             classes,\n",
    "             classifier,\n",
    "             batch_size,\n",
    "             GPUindex,\n",
    "             length, # 512\n",
    "             channel, # 96\n",
    "             min_CNN,\n",
    "             opt,\n",
    "             kind):        \n",
    "    # Load dataset\n",
    "    dataset = EEGDataset(iv, eeg_dataset, classifier, map_idx = None)\n",
    "    print(\"DONE: LOAD DATASET\")\n",
    "    # Create loaders for LSTM/MLP/CNN/SCNN/EEGNet/SyncNet/EEGChannelNet\n",
    "    if kind==\"from-scratch\":\n",
    "        relabel = False\n",
    "    if kind==\"incremental\":\n",
    "        relabel = False\n",
    "    if kind==\"no-model-file\":\n",
    "        relabel = True\n",
    "    splitter = {split: SplitterWithData(iv,\n",
    "                    dataset,\n",
    "                    splits_path,\n",
    "                    classes,\n",
    "                    split_num,\n",
    "                    split,\n",
    "                    relabel) for split in [\"train\", \"val\", \"test\"]}\n",
    "    loaders = {split: DataLoader(\n",
    "                        splitter[split],\n",
    "                        batch_size = batch_size,\n",
    "                        drop_last = False,\n",
    "                        shuffle = True)\n",
    "                    for split in [\"train\", \"val\", \"test\"]}\n",
    "    channel_idx = None    \n",
    "    print(\"DONE: Create loaders for model\")            \n",
    "    return dataset, loaders, splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aae9c3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacked BiLSTM network\n",
    "opt.classifier = \"Stacked_BiLSTM\"\n",
    "opt.batch_size = 16\n",
    "opt.kind = \"from-scratch\"\n",
    "opt.run = \"imagenet40-1000\"\n",
    "opt.fold = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8455f252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE: LOAD DATASET\n",
      "DONE: Create loaders for model\n"
     ]
    }
   ],
   "source": [
    "dataset, loaders, splitter = load_dataset(opt.iv,\n",
    "                             opt.offset,\n",
    "                             opt.eeg_dataset,\n",
    "                             opt.splits_path,\n",
    "                             0, #split_num\n",
    "                             n_classes,\n",
    "                             classes,\n",
    "                             opt.classifier,\n",
    "                             opt.batch_size,\n",
    "                             opt.GPUindex,\n",
    "                             length,\n",
    "                             channel,\n",
    "                             min_CNN,\n",
    "                             opt,\n",
    "                             opt.kind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8191cbe4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'data_loader.EEGDataset'>\n",
      "<class 'dict'>\n",
      "3 [2000, 250, 250]\n",
      "1: Label val: 0; label train: 0\n",
      "2: Label val: 17; label train: 17\n",
      "3: Label val: 28; label train: 28\n",
      "4: Label val: 7; label train: 7\n",
      "5: Label val: 33; label train: 33\n",
      "6: Label val: 12; label train: 12\n",
      "7: Label val: 21; label train: 21\n",
      "8: Label val: 3; label train: 3\n",
      "9: Label val: 25; label train: 25\n",
      "10: Label val: 36; label train: 36\n",
      "11: Label val: 10; label train: 10\n",
      "12: Label val: 15; label train: 15\n",
      "13: Label val: 19; label train: 19\n",
      "14: Label val: 31; label train: 31\n",
      "15: Label val: 23; label train: 23\n",
      "16: Label val: 5; label train: 5\n",
      "17: Label val: 38; label train: 38\n",
      "18: Label val: 8; label train: 8\n",
      "19: Label val: 1; label train: 1\n",
      "20: Label val: 34; label train: 34\n",
      "21: Label val: 29; label train: 29\n",
      "22: Label val: 26; label train: 26\n",
      "23: Label val: 13; label train: 13\n",
      "24: Label val: 11; label train: 11\n",
      "25: Label val: 22; label train: 22\n",
      "26: Label val: 18; label train: 18\n",
      "27: Label val: 6; label train: 6\n",
      "28: Label val: 16; label train: 16\n",
      "29: Label val: 4; label train: 4\n",
      "30: Label val: 20; label train: 20\n",
      "31: Label val: 32; label train: 32\n",
      "32: Label val: 9; label train: 9\n",
      "33: Label val: 37; label train: 37\n",
      "34: Label val: 24; label train: 24\n",
      "35: Label val: 39; label train: 39\n",
      "36: Label val: 2; label train: 2\n",
      "37: Label val: 35; label train: 35\n",
      "38: Label val: 30; label train: 30\n",
      "39: Label val: 27; label train: 27\n",
      "40: Label val: 14; label train: 14\n"
     ]
    }
   ],
   "source": [
    "# loaders: divide the splits data in each fold with batch_size\n",
    "# Each fold has {train: 32000 idx, val: 4000 idx, test: 4000 idx}\n",
    "# Each loader batch has {train: 2000 idx, val: 250idx, test: 250 idx}\n",
    "print(type(dataset))\n",
    "print(type(loaders))\n",
    "print(len(loaders), [len(loaders[name]) for name in [\"train\", \"val\", \"test\"] ])\n",
    "for i in range(0, 40):\n",
    "    eeg, label_val = splitter[\"val\"][i*100]\n",
    "    eeg, label_train = splitter[\"train\"][i*800]\n",
    "    print(f\"{i+1}: Label val: {label_val}; label train: {label_train}\")\n",
    "# print(splitter[\"val\"].split_idx[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e95cc78d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE: CREATE TORCH CLASSIFIER\n",
      "classifier_Stacked_BiLSTM(\n",
      "  (stacked_bilstm): LSTM(96, 128, num_layers=2, batch_first=True, bidirectional=True)\n",
      "  (output1): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (output2): Linear(in_features=128, out_features=40, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "classifier_Stacked_BiLSTM                [1, 40]                   --\n",
       "├─LSTM: 1-1                              [1, 512, 256]             626,688\n",
       "├─Linear: 1-2                            [1, 128]                  32,896\n",
       "├─ReLU: 1-3                              [1, 128]                  --\n",
       "├─Linear: 1-4                            [1, 40]                   5,160\n",
       "==========================================================================================\n",
       "Total params: 664,744\n",
       "Trainable params: 664,744\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 320.90\n",
       "==========================================================================================\n",
       "Input size (MB): 0.20\n",
       "Forward/backward pass size (MB): 1.05\n",
       "Params size (MB): 2.66\n",
       "Estimated Total Size (MB): 3.91\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net, nonclasses = Classifier(\n",
    "                 n_classes,\n",
    "                 classes,\n",
    "                 opt.classifier,\n",
    "                 opt.GPUindex,\n",
    "                 length,\n",
    "                 channel,\n",
    "                 min_CNN,\n",
    "                 opt.kind)\n",
    "# print(len(nonclasses))\n",
    "summary(net, input_size=(1,96, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9527792e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image-Stacked_BiLSTM-512-96-0-noshuffle\n"
     ]
    }
   ],
   "source": [
    "model_path = (opt.iv+\n",
    "                  \"-\"+\n",
    "                  opt.classifier+\n",
    "                  \"-\"+\n",
    "                  str(length)+\n",
    "                  \"-\"+\n",
    "                  str(channel)+\n",
    "                  \"-\"+\n",
    "                  str(0)) + \"-noshuffle\"\n",
    "                  \n",
    "channel_idx=None\n",
    "print(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "789e1be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(iv='image', offset=None, results_file='results.pkl', subject=0, run='imagenet40-1000', eeg_dataset='/media/titan/AI Research/Data/CVPR2021-02785/CVPR2021-02785/preprocessed/torch_models/imagenet40-1000-1.pth', splits_path='/media/titan/AI Research/Data/CVPR2021-02785/CVPR2021-02785/preprocessed/torch_models/imagenet40-1000-1_splits.pth', fold=5, batch_size=16, optim='Adam', learning_rate=0.001, learning_rate_decay_by=0.5, learning_rate_decay_every=10, epochs=100, GPUindex=0, kind='from-scratch', no_cuda=False, classifier='Stacked_BiLSTM')\n"
     ]
    }
   ],
   "source": [
    "print(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d6a7ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.701542615890503; accuracy=0.021437501534819603\n",
      "Batch 2000: Loss=3.7104787826538086; accuracy=0.022093750536441803\n",
      "Validation accuracy: 0.0247500017285347\n",
      "epoch 2\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.686978340148926; accuracy=0.024812500923871994\n",
      "Batch 2000: Loss=3.6926369667053223; accuracy=0.024281250312924385\n",
      "Validation accuracy: 0.02500000037252903\n",
      "epoch 3\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.691617727279663; accuracy=0.02562500163912773\n",
      "Batch 2000: Loss=3.7041683197021484; accuracy=0.02459375187754631\n",
      "Validation accuracy: 0.027250001206994057\n",
      "epoch 4\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.6860268115997314; accuracy=0.02381250075995922\n",
      "Batch 2000: Loss=3.6800918579101562; accuracy=0.02409375086426735\n",
      "Validation accuracy: 0.024250000715255737\n",
      "epoch 5\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.6946561336517334; accuracy=0.0266875009983778\n",
      "Batch 2000: Loss=3.686418056488037; accuracy=0.026125000789761543\n",
      "Validation accuracy: 0.028750000521540642\n",
      "epoch 6\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.683934211730957; accuracy=0.030562501400709152\n",
      "Batch 2000: Loss=3.6707160472869873; accuracy=0.029062502086162567\n",
      "Validation accuracy: 0.02575000189244747\n",
      "epoch 7\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.677016258239746; accuracy=0.030562501400709152\n",
      "Batch 2000: Loss=3.667562484741211; accuracy=0.028968751430511475\n",
      "Validation accuracy: 0.02850000187754631\n",
      "epoch 8\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.675060987472534; accuracy=0.03306250274181366\n",
      "Batch 2000: Loss=3.714365005493164; accuracy=0.03134375065565109\n",
      "Validation accuracy: 0.02525000087916851\n",
      "epoch 9\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.676603317260742; accuracy=0.034062501043081284\n",
      "Batch 2000: Loss=3.679011344909668; accuracy=0.03437500074505806\n",
      "Validation accuracy: 0.027500001713633537\n",
      "epoch 10\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.6344921588897705; accuracy=0.041187502443790436\n",
      "Batch 2000: Loss=3.6721248626708984; accuracy=0.03968750312924385\n",
      "Validation accuracy: 0.023500001057982445\n",
      "epoch 11\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.6383590698242188; accuracy=0.050437502562999725\n",
      "Batch 2000: Loss=3.615783452987671; accuracy=0.04909375309944153\n",
      "Validation accuracy: 0.023750001564621925\n",
      "epoch 12\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.6690616607666016; accuracy=0.06650000065565109\n",
      "Batch 2000: Loss=3.7678234577178955; accuracy=0.06353124976158142\n",
      "Validation accuracy: 0.02250000089406967\n",
      "epoch 13\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.4894940853118896; accuracy=0.0871875062584877\n",
      "Batch 2000: Loss=3.1086769104003906; accuracy=0.08425000309944153\n",
      "Validation accuracy: 0.02250000089406967\n",
      "epoch 14\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.108764171600342; accuracy=0.11212500184774399\n",
      "Batch 2000: Loss=3.3687288761138916; accuracy=0.10875000804662704\n",
      "Validation accuracy: 0.024500001221895218\n",
      "epoch 15\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=3.1152701377868652; accuracy=0.15293750166893005\n",
      "Batch 2000: Loss=3.3755338191986084; accuracy=0.1459687501192093\n",
      "Validation accuracy: 0.02550000138580799\n",
      "epoch 16\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=2.7037692070007324; accuracy=0.1885625123977661\n",
      "Batch 2000: Loss=3.4357547760009766; accuracy=0.18653126060962677\n",
      "Validation accuracy: 0.02175000123679638\n",
      "epoch 17\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=2.8986055850982666; accuracy=0.2356875091791153\n",
      "Batch 2000: Loss=2.3199031352996826; accuracy=0.22596876323223114\n",
      "Validation accuracy: 0.027750002220273018\n",
      "epoch 18\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=2.427924871444702; accuracy=0.2891875207424164\n",
      "Batch 2000: Loss=2.4543278217315674; accuracy=0.277218759059906\n",
      "Validation accuracy: 0.024500001221895218\n",
      "epoch 19\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=2.0955464839935303; accuracy=0.34062501788139343\n",
      "Batch 2000: Loss=2.6220362186431885; accuracy=0.3218125104904175\n",
      "Validation accuracy: 0.02500000037252903\n",
      "epoch 20\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=2.266873359680176; accuracy=0.38587501645088196\n",
      "Batch 2000: Loss=2.3035800457000732; accuracy=0.36884376406669617\n",
      "Validation accuracy: 0.024500001221895218\n",
      "epoch 21\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=2.052377939224243; accuracy=0.429312527179718\n",
      "Batch 2000: Loss=2.2905311584472656; accuracy=0.409968763589859\n",
      "Validation accuracy: 0.022750001400709152\n",
      "epoch 22\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=2.218236207962036; accuracy=0.4644375145435333\n",
      "Batch 2000: Loss=1.5102511644363403; accuracy=0.4513437747955322\n",
      "Validation accuracy: 0.0247500017285347\n",
      "epoch 23\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=2.3705272674560547; accuracy=0.5041249990463257\n",
      "Batch 2000: Loss=1.9625300168991089; accuracy=0.4868125319480896\n",
      "Validation accuracy: 0.0247500017285347\n",
      "epoch 24\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=1.8641681671142578; accuracy=0.5426250100135803\n",
      "Batch 2000: Loss=1.6170355081558228; accuracy=0.526187539100647\n",
      "Validation accuracy: 0.02850000187754631\n",
      "epoch 25\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=2.1239233016967773; accuracy=0.5790625214576721\n",
      "Batch 2000: Loss=1.8707914352416992; accuracy=0.5570625066757202\n",
      "Validation accuracy: 0.024250000715255737\n",
      "epoch 26\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=0.8907668590545654; accuracy=0.6041250228881836\n",
      "Batch 2000: Loss=1.3893297910690308; accuracy=0.5815625190734863\n",
      "Validation accuracy: 0.026500001549720764\n",
      "epoch 27\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=1.8617568016052246; accuracy=0.6300625205039978\n",
      "Batch 2000: Loss=2.441603660583496; accuracy=0.6098125576972961\n",
      "Validation accuracy: 0.0215000007301569\n",
      "epoch 28\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=1.6979079246520996; accuracy=0.6508750319480896\n",
      "Batch 2000: Loss=1.2991091012954712; accuracy=0.6299062967300415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.030000001192092896\n",
      "epoch 29\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=0.8207628726959229; accuracy=0.6750625371932983\n",
      "Batch 2000: Loss=1.155935287475586; accuracy=0.6568125486373901\n",
      "Validation accuracy: 0.026750002056360245\n",
      "epoch 30\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=1.1611584424972534; accuracy=0.6928750276565552\n",
      "Batch 2000: Loss=0.676348865032196; accuracy=0.6739687919616699\n",
      "Validation accuracy: 0.02800000086426735\n",
      "epoch 31\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=2.15395450592041; accuracy=0.7117500305175781\n",
      "Batch 2000: Loss=0.9057379961013794; accuracy=0.6940625309944153\n",
      "Validation accuracy: 0.030000001192092896\n",
      "epoch 32\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=0.8624036908149719; accuracy=0.7285000085830688\n",
      "Batch 2000: Loss=1.0956329107284546; accuracy=0.7080000042915344\n",
      "Validation accuracy: 0.03175000101327896\n",
      "epoch 33\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=0.4575207233428955; accuracy=0.7466250061988831\n",
      "Batch 2000: Loss=0.9034737348556519; accuracy=0.7259063124656677\n",
      "Validation accuracy: 0.026000000536441803\n",
      "epoch 34\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=0.670536458492279; accuracy=0.7570000290870667\n",
      "Batch 2000: Loss=0.7962013483047485; accuracy=0.737000048160553\n",
      "Validation accuracy: 0.027000000700354576\n",
      "epoch 35\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=1.5685980319976807; accuracy=0.7684375643730164\n",
      "Batch 2000: Loss=0.8519546985626221; accuracy=0.7439062595367432\n",
      "Validation accuracy: 0.028750000521540642\n",
      "epoch 36\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=0.6078318953514099; accuracy=0.7826875448226929\n",
      "Batch 2000: Loss=0.64797443151474; accuracy=0.760687530040741\n",
      "Validation accuracy: 0.026750002056360245\n",
      "epoch 37\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=0.6132386922836304; accuracy=0.792062520980835\n",
      "Batch 2000: Loss=0.3801082372665405; accuracy=0.772156298160553\n",
      "Validation accuracy: 0.029000001028180122\n",
      "epoch 38\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=0.8743078708648682; accuracy=0.8026875257492065\n",
      "Batch 2000: Loss=1.0263019800186157; accuracy=0.7814688086509705\n",
      "Validation accuracy: 0.02850000187754631\n",
      "epoch 39\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=0.6066490411758423; accuracy=0.8113750219345093\n",
      "Batch 2000: Loss=1.2074159383773804; accuracy=0.7843125462532043\n",
      "Validation accuracy: 0.029000001028180122\n",
      "epoch 40\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=0.9600695371627808; accuracy=0.8138125538825989\n",
      "Batch 2000: Loss=0.7035170793533325; accuracy=0.7992187738418579\n",
      "Validation accuracy: 0.02575000189244747\n",
      "epoch 41\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=0.35500437021255493; accuracy=0.8224375247955322\n",
      "Batch 2000: Loss=0.6957141160964966; accuracy=0.796125054359436\n",
      "Validation accuracy: 0.026500001549720764\n",
      "epoch 42\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=0.661738395690918; accuracy=0.8323750495910645\n",
      "Batch 2000: Loss=0.8244157433509827; accuracy=0.8102500438690186\n",
      "Validation accuracy: 0.029500002041459084\n",
      "epoch 43\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=0.2552277147769928; accuracy=0.8426250219345093\n",
      "Batch 2000: Loss=0.43847107887268066; accuracy=0.8207187652587891\n",
      "Validation accuracy: 0.026250001043081284\n",
      "epoch 44\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=0.48366671800613403; accuracy=0.8468125462532043\n",
      "Batch 2000: Loss=0.9690865278244019; accuracy=0.8185312747955322\n",
      "Validation accuracy: 0.02825000137090683\n",
      "epoch 45\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=0.9593786597251892; accuracy=0.846750020980835\n",
      "Batch 2000: Loss=0.16300450265407562; accuracy=0.8316875100135803\n",
      "Validation accuracy: 0.02575000189244747\n",
      "epoch 46\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=0.39581409096717834; accuracy=0.8505000472068787\n",
      "Batch 2000: Loss=0.783023476600647; accuracy=0.8302813172340393\n",
      "Validation accuracy: 0.02550000138580799\n",
      "epoch 47\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=0.3285793364048004; accuracy=0.8538125157356262\n",
      "Batch 2000: Loss=0.4823310673236847; accuracy=0.8322187662124634\n",
      "Validation accuracy: 0.027750002220273018\n",
      "epoch 48\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=1.02520751953125; accuracy=0.8563125133514404\n",
      "Batch 2000: Loss=0.3196224868297577; accuracy=0.8411250114440918\n",
      "Validation accuracy: 0.026500001549720764\n",
      "epoch 49\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=0.9179291725158691; accuracy=0.8633125424385071\n",
      "Batch 2000: Loss=0.9067735075950623; accuracy=0.8426875472068787\n",
      "Validation accuracy: 0.030500002205371857\n",
      "epoch 50\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=0.2896125912666321; accuracy=0.8700000643730164\n",
      "Batch 2000: Loss=0.7451344728469849; accuracy=0.8491563200950623\n",
      "Validation accuracy: 0.030000001192092896\n",
      "epoch 51\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=0.3650006949901581; accuracy=0.8698750138282776\n",
      "Batch 2000: Loss=0.5868715047836304; accuracy=0.8511562943458557\n",
      "Validation accuracy: 0.02850000187754631\n",
      "epoch 52\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=0.264538437128067; accuracy=0.8630625605583191\n",
      "Batch 2000: Loss=0.36720526218414307; accuracy=0.8492187857627869\n",
      "Validation accuracy: 0.026750002056360245\n",
      "epoch 53\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=0.3428736925125122; accuracy=0.877375066280365\n",
      "Batch 2000: Loss=0.8908838629722595; accuracy=0.8556875586509705\n",
      "Validation accuracy: 0.02800000086426735\n",
      "epoch 54\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=0.6679647564888; accuracy=0.866937518119812\n",
      "Batch 2000: Loss=0.4523545205593109; accuracy=0.8576250672340393\n",
      "Validation accuracy: 0.029250001534819603\n",
      "epoch 55\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=0.22952836751937866; accuracy=0.8744375705718994\n",
      "Batch 2000: Loss=0.24045509099960327; accuracy=0.8593750596046448\n",
      "Validation accuracy: 0.026750002056360245\n",
      "epoch 56\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=0.5792416334152222; accuracy=0.8808750510215759\n",
      "Batch 2000: Loss=0.4128789007663727; accuracy=0.8639375567436218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.02850000187754631\n",
      "epoch 57\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=0.9046136140823364; accuracy=0.8820000290870667\n",
      "Batch 2000: Loss=0.8923779726028442; accuracy=0.8634375333786011\n",
      "Validation accuracy: 0.026500001549720764\n",
      "epoch 58\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=0.19030234217643738; accuracy=0.8735000491142273\n",
      "Batch 2000: Loss=0.5411105155944824; accuracy=0.8636875152587891\n",
      "Validation accuracy: 0.026000000536441803\n",
      "epoch 59\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=0.56320720911026; accuracy=0.8861875534057617\n",
      "Batch 2000: Loss=1.3177130222320557; accuracy=0.8733437657356262\n",
      "Validation accuracy: 0.027500001713633537\n",
      "epoch 60\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=0.590433657169342; accuracy=0.8871250152587891\n",
      "Batch 2000: Loss=0.2540140748023987; accuracy=0.8774062991142273\n",
      "Validation accuracy: 0.026250001043081284\n",
      "epoch 61\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=0.40965691208839417; accuracy=0.8871875405311584\n",
      "Batch 2000: Loss=0.10939020663499832; accuracy=0.8706563115119934\n",
      "Validation accuracy: 0.0247500017285347\n",
      "epoch 62\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=0.1571102887392044; accuracy=0.8923750519752502\n",
      "Batch 2000: Loss=0.16469734907150269; accuracy=0.8724687695503235\n",
      "Validation accuracy: 0.029250001534819603\n",
      "epoch 63\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=0.5287653803825378; accuracy=0.9027500152587891\n",
      "Batch 2000: Loss=0.2629276514053345; accuracy=0.8809375166893005\n",
      "Validation accuracy: 0.029750000685453415\n",
      "epoch 64\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=0.532812774181366; accuracy=0.889875054359436\n",
      "Batch 2000: Loss=0.120418980717659; accuracy=0.8746563196182251\n",
      "Validation accuracy: 0.027750002220273018\n",
      "epoch 65\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=0.8517153263092041; accuracy=0.8912500143051147\n",
      "Batch 2000: Loss=0.8758885860443115; accuracy=0.8803125619888306\n",
      "Validation accuracy: 0.030750000849366188\n",
      "epoch 66\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=0.4963573217391968; accuracy=0.8983750343322754\n",
      "Batch 2000: Loss=0.929109513759613; accuracy=0.8830937743186951\n",
      "Validation accuracy: 0.027000000700354576\n",
      "epoch 67\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=0.31159597635269165; accuracy=0.9019375443458557\n",
      "Batch 2000: Loss=1.028306484222412; accuracy=0.8827812671661377\n",
      "Validation accuracy: 0.028750000521540642\n",
      "epoch 68\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=0.37820005416870117; accuracy=0.8958750367164612\n",
      "Batch 2000: Loss=0.21313732862472534; accuracy=0.882562518119812\n",
      "Validation accuracy: 0.029250001534819603\n",
      "epoch 69\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=0.749318540096283; accuracy=0.893125057220459\n",
      "Batch 2000: Loss=0.4704517722129822; accuracy=0.8866250514984131\n",
      "Validation accuracy: 0.02575000189244747\n",
      "epoch 70\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=0.34869101643562317; accuracy=0.8951250314712524\n",
      "Batch 2000: Loss=0.8932274580001831; accuracy=0.8841562867164612\n",
      "Validation accuracy: 0.027750002220273018\n",
      "epoch 71\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=0.5716896653175354; accuracy=0.8978750705718994\n",
      "Batch 2000: Loss=0.957362174987793; accuracy=0.8864063024520874\n",
      "Validation accuracy: 0.027500001713633537\n",
      "epoch 72\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=0.4680456817150116; accuracy=0.8964375257492065\n",
      "Batch 2000: Loss=0.10162303596735; accuracy=0.8850000500679016\n",
      "Validation accuracy: 0.029250001534819603\n",
      "epoch 73\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=0.0899553969502449; accuracy=0.9030000567436218\n",
      "Batch 2000: Loss=0.37908220291137695; accuracy=0.8933438062667847\n",
      "Validation accuracy: 0.027000000700354576\n",
      "epoch 74\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=0.3695121705532074; accuracy=0.9005625247955322\n",
      "Batch 2000: Loss=0.1662675440311432; accuracy=0.8880313038825989\n",
      "Validation accuracy: 0.029750000685453415\n",
      "epoch 75\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=0.555371105670929; accuracy=0.9103750586509705\n",
      "Batch 2000: Loss=0.4885498583316803; accuracy=0.8945313096046448\n",
      "Validation accuracy: 0.02825000137090683\n",
      "epoch 76\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=0.08442709594964981; accuracy=0.9095625281333923\n",
      "Batch 2000: Loss=0.35637742280960083; accuracy=0.8978437781333923\n",
      "Validation accuracy: 0.027250001206994057\n",
      "epoch 77\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=0.1548556387424469; accuracy=0.897937536239624\n",
      "Batch 2000: Loss=0.021358920261263847; accuracy=0.8839687705039978\n",
      "Validation accuracy: 0.026500001549720764\n",
      "epoch 78\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=0.4452635645866394; accuracy=0.9040625691413879\n",
      "Batch 2000: Loss=0.9633784890174866; accuracy=0.8951250314712524\n",
      "Validation accuracy: 0.02850000187754631\n",
      "epoch 79\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=0.10961276292800903; accuracy=0.8996250629425049\n",
      "Batch 2000: Loss=0.21349744498729706; accuracy=0.8863125443458557\n",
      "Validation accuracy: 0.027000000700354576\n",
      "epoch 80\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=0.1363331377506256; accuracy=0.916937530040741\n",
      "Batch 2000: Loss=0.30661290884017944; accuracy=0.8995937705039978\n",
      "Validation accuracy: 0.03100000135600567\n",
      "epoch 81\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=0.06035814806818962; accuracy=0.9116250276565552\n",
      "Batch 2000: Loss=0.4588618874549866; accuracy=0.901437520980835\n",
      "Validation accuracy: 0.026250001043081284\n",
      "epoch 82\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=0.5457326173782349; accuracy=0.9076875448226929\n",
      "Batch 2000: Loss=0.29275575280189514; accuracy=0.8983125686645508\n",
      "Validation accuracy: 0.029500002041459084\n",
      "epoch 83\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=0.04970452934503555; accuracy=0.9058125615119934\n",
      "Batch 2000: Loss=0.05695534124970436; accuracy=0.8912187814712524\n",
      "Validation accuracy: 0.029500002041459084\n",
      "epoch 84\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=0.7181146144866943; accuracy=0.9094375371932983\n",
      "Batch 2000: Loss=0.285125195980072; accuracy=0.9012187719345093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.030250001698732376\n",
      "epoch 85\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=1.1378132104873657; accuracy=0.9161250591278076\n",
      "Batch 2000: Loss=0.2987479269504547; accuracy=0.9023438096046448\n",
      "Validation accuracy: 0.026250001043081284\n",
      "epoch 86\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=0.40077680349349976; accuracy=0.908875048160553\n",
      "Batch 2000: Loss=0.3096345365047455; accuracy=0.8939688205718994\n",
      "Validation accuracy: 0.026500001549720764\n",
      "epoch 87\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=0.10238569974899292; accuracy=0.9105625152587891\n",
      "Batch 2000: Loss=0.7748597860336304; accuracy=0.8992187976837158\n",
      "Validation accuracy: 0.02525000087916851\n",
      "epoch 88\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=0.0636528879404068; accuracy=0.9176875352859497\n",
      "Batch 2000: Loss=0.24795658886432648; accuracy=0.9040000438690186\n",
      "Validation accuracy: 0.030000001192092896\n",
      "epoch 89\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=1.043603539466858; accuracy=0.9070000648498535\n",
      "Batch 2000: Loss=0.3619104027748108; accuracy=0.8970000147819519\n",
      "Validation accuracy: 0.02800000086426735\n",
      "epoch 90\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=0.7459027171134949; accuracy=0.909125030040741\n",
      "Batch 2000: Loss=0.055250365287065506; accuracy=0.902093768119812\n",
      "Validation accuracy: 0.02550000138580799\n",
      "epoch 91\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=0.5979733467102051; accuracy=0.9177500605583191\n",
      "Batch 2000: Loss=0.4683682918548584; accuracy=0.9044063091278076\n",
      "Validation accuracy: 0.03350000083446503\n",
      "epoch 92\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=0.644818127155304; accuracy=0.9100625514984131\n",
      "Batch 2000: Loss=0.48901209235191345; accuracy=0.9007500410079956\n",
      "Validation accuracy: 0.026500001549720764\n",
      "epoch 93\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=0.05925538018345833; accuracy=0.9094375371932983\n",
      "Batch 2000: Loss=0.22497563064098358; accuracy=0.8998750448226929\n",
      "Validation accuracy: 0.0247500017285347\n",
      "epoch 94\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=0.07304449379444122; accuracy=0.901437520980835\n",
      "Batch 2000: Loss=0.5158985257148743; accuracy=0.8973125219345093\n",
      "Validation accuracy: 0.02525000087916851\n",
      "epoch 95\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=0.5296962857246399; accuracy=0.9149375557899475\n",
      "Batch 2000: Loss=0.31968173384666443; accuracy=0.9032500386238098\n",
      "Validation accuracy: 0.029500002041459084\n",
      "epoch 96\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=0.2419605553150177; accuracy=0.917062520980835\n",
      "Batch 2000: Loss=0.552590012550354; accuracy=0.900937557220459\n",
      "Validation accuracy: 0.030750000849366188\n",
      "epoch 97\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=0.031054725870490074; accuracy=0.913062572479248\n",
      "Batch 2000: Loss=0.10914922505617142; accuracy=0.9079062938690186\n",
      "Validation accuracy: 0.028750000521540642\n",
      "epoch 98\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=0.21715711057186127; accuracy=0.9079375267028809\n",
      "Batch 2000: Loss=0.4951678514480591; accuracy=0.9007500410079956\n",
      "Validation accuracy: 0.0247500017285347\n",
      "epoch 99\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=0.23687979578971863; accuracy=0.9140000343322754\n",
      "Batch 2000: Loss=0.9639214873313904; accuracy=0.909281313419342\n",
      "Validation accuracy: 0.026000000536441803\n",
      "epoch 100\n",
      "Size of input:  torch.Size([16, 96, 512])\n",
      "Size of target:  torch.Size([16])\n",
      "Size of output:  torch.Size([16, 40])\n",
      "Batch 1000: Loss=0.49748456478118896; accuracy=0.9140000343322754\n",
      "Batch 2000: Loss=0.40525487065315247; accuracy=0.906000018119812\n",
      "Validation accuracy: 0.024000000208616257\n"
     ]
    }
   ],
   "source": [
    "if opt.kind==\"from-scratch\":\n",
    "    loss_history, accuracy_val, accuracy_test = net_trainer(\n",
    "            net,\n",
    "            loaders,\n",
    "            opt,\n",
    "            channel_idx,\n",
    "            nonclasses,\n",
    "            None,\n",
    "            True,\n",
    "            model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "52ac79d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy:  0.024000000208616257\n",
      "Test accuracy:  0\n"
     ]
    }
   ],
   "source": [
    "val =accuracy_val\n",
    "test = accuracy_test\n",
    "\n",
    "print(\"Validation accuracy: \", val)\n",
    "print(\"Test accuracy: \", test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0931fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c3beab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2179d69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ed6c4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2060d560",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb54c13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6467f813",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d16c15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45955f5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52331151",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca94e7f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfe619b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a58f0c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8236ccbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44249203",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f168b18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
